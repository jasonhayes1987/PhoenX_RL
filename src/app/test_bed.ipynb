{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import umap\n",
    "import pynndescent\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Numba version:\", numba.__version__)\n",
    "print(\"UMAP version:\", umap.__version__)\n",
    "print(\"PyNNDescent version:\", pynndescent.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ale_py\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# from umap import UMAP\n",
    "\n",
    "\n",
    "import torch_utils\n",
    "from torch import distributions\n",
    "\n",
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "from gymnasium.vector import VectorEnv, SyncVectorEnv\n",
    "# import models\n",
    "from models import ValueModel, StochasticContinuousPolicy, ActorModel, CriticModel, StochasticDiscretePolicy\n",
    "from rl_agents import PPO, DDPG, Reinforce, ActorCritic, TD3, HER\n",
    "import rl_callbacks\n",
    "from rl_callbacks import WandbCallback\n",
    "# from helper import Normalizer\n",
    "from buffer import ReplayBuffer\n",
    "from noise import NormalNoise\n",
    "import gym_helper\n",
    "import wandb_support\n",
    "import wandb\n",
    "import gym_helper\n",
    "import dash_utils\n",
    "from env_wrapper import EnvWrapper, GymnasiumWrapper\n",
    "from schedulers import ScheduleWrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mujoco version: {mujoco.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchReach-v4')\n",
    "env_spec = env.spec\n",
    "wrap_env = GymnasiumWrapper(env_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env.env.env.initial_qpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_env.env = wrap_env._initialize_env(num_envs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, _ = wrap_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.MjModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_robo.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cuda():\n",
    "    cuda_available = T.cuda.is_available()\n",
    "    if cuda_available:\n",
    "        print(\"CUDA is available.\")\n",
    "        num_gpus = T.cuda.device_count()\n",
    "        print(f\"Number of GPUs detected: {num_gpus}\")\n",
    "        \n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = T.cuda.get_device_name(i)\n",
    "            gpu_memory = T.cuda.get_device_properties(i).total_memory / (1024 ** 3)  # Convert bytes to GB\n",
    "            print(f\"GPU {i}: {gpu_name}\")\n",
    "            print(f\"Total memory: {gpu_memory:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Returns the default device for computations, GPU if available, otherwise CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_robo.register_robotics_envs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register_envs(gymnasium_robotics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.registration.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key='758ac5ba01e12a3df504d2db2fec8ba4f391f7e6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2', max_episode_steps=100, render_mode='rgb_array')\n",
    "env = gym.wrappers.RecordVideo(env, 'test/', episode_trigger=lambda i: i%1==0)\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "    while not done:\n",
    "        obs, r, term, trunc, dict = env.step(env.action_space.sample())\n",
    "        if term or trunc:\n",
    "            done = True\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v2\")\n",
    "env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "\n",
    "# The following always has to hold:\n",
    "assert reward == env.compute_reward(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n",
    "assert truncated == env.compute_truncated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n",
    "assert terminated == env.compute_terminated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.compute_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(env, \"distance_threshold\"):\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env.get_wrapper_attr(\"distance_threshold\"):\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(env))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('BipedalWalker-v3')\n",
    "env = gym.make('Pendulum-v1')\n",
    "env_spec = env.spec\n",
    "env_wrap = GymnasiumWrapper(env_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in env_wrap.env.envs:\n",
    "    print(e.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "device = 'cuda'\n",
    "optimizer = {'type': 'Adam','params': { 'lr': 0.001 }}\n",
    "\n",
    "layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 400, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "    {'type': 'dense', 'params': {'units': 300, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "]\n",
    "output_layer_config = [{'type': 'dense', 'params': {'kernel': 'default', 'kernel params':{}}}]\n",
    "\n",
    "actor = ActorModel(env_wrap, layer_config, output_layer_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 400, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'}\n",
    "]\n",
    "\n",
    "merged_layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 300, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "]\n",
    "# output_layer_config = {'type': 'dense', 'params': {'kernel': 'default', 'kernel params':{}}},\n",
    "\n",
    "critic = CriticModel(env_wrap, state_layers=state_layer_config, merged_layers=merged_layer_config,\n",
    "                    output_layer_kernel=output_layer_config, optimizer_params=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(env_wrap, 100000, device=device)\n",
    "noise = NormalNoise(shape=env_wrap.action_space.shape, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = DDPG(env=env_wrap,\n",
    "                actor_model=actor,\n",
    "                critic_model=critic,\n",
    "                replay_buffer=replay_buffer,\n",
    "                discount=0.99,\n",
    "                tau=0.005,\n",
    "                action_epsilon=0.2,\n",
    "                noise=noise,\n",
    "                callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')],\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.target_critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.train(1000, 8, 42, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = '/workspaces/RL_Agents/src/app/models/ddpg/config.json'\n",
    "with open(config_file_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg = DDPG.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg.test(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('BipedalWalker-v3')\n",
    "env = gym.make('Pendulum-v1')\n",
    "env_spec = env.spec\n",
    "env_wrap = GymnasiumWrapper(env_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "device = 'cuda'\n",
    "optimizer = {'type': 'Adam','params': { 'lr': 0.001 }}\n",
    "\n",
    "layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 400, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "    {'type': 'dense', 'params': {'units': 300, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "]\n",
    "output_layer_config = [{'type': 'dense', 'params': {'kernel': 'default', 'kernel params':{}}}]\n",
    "\n",
    "actor = ActorModel(env_wrap, layer_config, output_layer_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 400, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'}\n",
    "]\n",
    "\n",
    "merged_layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 300, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "]\n",
    "# output_layer_config = {'type': 'dense', 'params': {'kernel': 'default', 'kernel params':{}}},\n",
    "\n",
    "critic = CriticModel(env_wrap, state_layers=state_layer_config, merged_layers=merged_layer_config,\n",
    "                    output_layer_kernel=output_layer_config, optimizer_params=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(env_wrap, 100000, device=device)\n",
    "noise = NormalNoise(shape=env_wrap.action_space.shape, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td3 = TD3(\n",
    "    env=env_wrap,\n",
    "    actor_model=actor,\n",
    "    critic_model=critic,\n",
    "    discount=0.99,\n",
    "    tau=0.005,\n",
    "    action_epsilon=0.2,\n",
    "    replay_buffer=replay_buffer,\n",
    "    noise=noise,\n",
    "    callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')],\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td3.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td3.train(200, 8, 42, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(td3.env.action_space.low[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER/DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'gym robotics version: {gym_robo.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make('FetchPickAndPlace-v4', render_mode='human')\n",
    "env_spec = env.spec\n",
    "env = GymnasiumWrapper(env_spec)\n",
    "env.env = env._initialize_env(1, 2)\n",
    "\n",
    "# Reset the environment and get initial observation\n",
    "obs, _ = env.reset()  # Use no seed for randomness\n",
    "for i in range(env.env.num_envs):\n",
    "    initial_block_pos = obs['achieved_goal'][i]\n",
    "    print(f\"Environment {i} initial block position: {initial_block_pos}\")\n",
    "\n",
    "# Step through the environment with random actions\n",
    "for step in range(1000):  # Test 50 steps or until episode ends\n",
    "    action = env.action_space.sample()  # Random action in [-1, 1]\n",
    "    action = env.format_actions(action)\n",
    "    next_obs, reward, term, trunc, info = env.step(action)\n",
    "    done = np.logical_or(term, trunc)\n",
    "\n",
    "    for i in range(env.env.num_envs):\n",
    "        # Print current state\n",
    "        # print(f\"Environment {i} Step {step}, Action: {action[i]}\")\n",
    "        # print(f\"Environment {i} Gripper position: {next_obs['observation'][i][3:5]}\")  # Gripper finger positions\n",
    "        # print(f\"Environment {i} Block position (achieved_goal): {next_obs['achieved_goal'][i]}\")\n",
    "        # print(f\"Environment {i} Target position (desired_goal): {next_obs['desired_goal'][i]}\")\n",
    "        # print(f\"Environment {i} Reward: {reward[i]}, Done: {done[i]}\")\n",
    "\n",
    "        # Check if the block moved and episode isn’t done\n",
    "        if not done[i] and not np.allclose(obs['achieved_goal'][i], next_obs['achieved_goal'][i], atol=0.001):\n",
    "            print(f\"Block moved at step {step}! Previous position: {obs['achieved_goal'][i]}; New position: {next_obs['achieved_goal'][i]}\")\n",
    "            print(f\"Gripper action (control): {action[i][3]}\")  # Check gripper control\n",
    "        \n",
    "        # if episode ends\n",
    "        if done[i]:\n",
    "            print(f\"Episode ended at step {step}, Reason: Terminated={term}, Truncated={trunc}\")\n",
    "\n",
    "    # Render the environment\n",
    "    env.env.envs[0].render()\n",
    "\n",
    "    # Update observation for next step\n",
    "    obs = next_obs\n",
    "\n",
    "# Close the environment\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPickAndPlace-v4')\n",
    "env_spec = env.spec\n",
    "env_wrap = GymnasiumWrapper(env_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "device = 'cuda'\n",
    "optimizer = {'type': 'Adam','params': { 'lr': 0.001 }}\n",
    "\n",
    "layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 256, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "    {'type': 'dense', 'params': {'units': 256, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "    {'type': 'dense', 'params': {'units': 256, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "]\n",
    "output_layer_config = [{'type': 'dense', 'params': {'kernel': 'uniform', 'kernel params':{'a':-3e-3, 'b':3e-3}}}]\n",
    "\n",
    "actor = ActorModel(env_wrap, layer_config, output_layer_config, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 256, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'}\n",
    "]\n",
    "\n",
    "merged_layer_config = [\n",
    "    {'type': 'dense', 'params': {'units': 256, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "    {'type': 'dense', 'params': {'units': 256, 'kernel': 'variance_scaling', 'kernel params':{\"scale\": 1.0, \"mode\": \"fan_in\", \"distribution\": \"uniform\"}}},\n",
    "    {'type': 'relu'},\n",
    "]\n",
    "# output_layer_config = {'type': 'dense', 'params': {'kernel': 'default', 'kernel params':{}}},\n",
    "\n",
    "critic = CriticModel(env_wrap, state_layers=state_layer_config, merged_layers=merged_layer_config,\n",
    "                    output_layer_kernel=output_layer_config, optimizer_params=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(env_wrap, 100000, goal_shape=env.observation_space['desired_goal'].shape, device=device)\n",
    "noise = NormalNoise(shape=env_wrap.action_space.shape, mean=0.0, stddev=0.05, device=device)\n",
    "schedule_config = {'type':'Linear', 'params':{'start_factor':1.0, 'end_factor':0.1, 'total_iters':5000}}\n",
    "# noise_schedule = ScheduleWrapper(schedule_config)\n",
    "noise_schedule = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = DDPG(env=env_wrap,\n",
    "                actor_model=actor,\n",
    "                critic_model=critic,\n",
    "                replay_buffer=replay_buffer,\n",
    "                discount=0.99,\n",
    "                tau=0.05,\n",
    "                action_epsilon=0.2,\n",
    "                batch_size=256,\n",
    "                noise=noise,\n",
    "                noise_schedule=noise_schedule,\n",
    "                warmup=1000,\n",
    "                callbacks=[rl_callbacks.WandbCallback('FetchPickAndPlace-v4')],\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='future',\n",
    "    tolerance=0.05,\n",
    "    num_goals=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolerance: 0.05\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(her.agent.env.env.envs)):\n",
    "    base = her.agent.env.get_base_env(i)\n",
    "    print(f'tolerance: {base.distance_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjasonhayes1987\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/src/app/wandb/run-20250226_033547-xszmti40</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4/runs/xszmti40' target=\"_blank\">train-14</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4/runs/xszmti40' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4/runs/xszmti40</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 0: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 2: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 3: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 4: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 5: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 6: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 7: episode 1, score -50.0, avg_score -50.0\n",
      "Environment 0: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 2: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 3: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 4: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 5: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 6: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 7: episode 2, score -50.0, avg_score -50.0\n",
      "Environment 0: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 2: episode 3, score -50.0, avg_score -50.0\n",
      "Rendering episode 20.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_20.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_20.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_20.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 4: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 5: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 6: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 7: episode 3, score -50.0, avg_score -50.0\n",
      "Environment 0: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 2: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 3: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 4: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 5: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 6: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 7: episode 4, score -50.0, avg_score -50.0\n",
      "Environment 0: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 2: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 3: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 4: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 5: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 6: episode 5, score -50.0, avg_score -50.0\n",
      "Rendering episode 40.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_40.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_40.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_40.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: 0.0 Avg Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 5, score -50.0, avg_score -50.0\n",
      "Environment 0: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 2: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 3: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 4: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 5: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 6: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 7: episode 6, score -50.0, avg_score -50.0\n",
      "Environment 0: episode 7, score -50.0, avg_score -50.0\n",
      "Environment 1: episode 7, score 0.0, avg_score -49.0\n",
      "Environment 2: episode 7, score -50.0, avg_score -49.01960784313726\n",
      "Environment 3: episode 7, score -50.0, avg_score -49.03846153846154\n",
      "Environment 4: episode 7, score -50.0, avg_score -49.056603773584904\n",
      "Environment 5: episode 7, score -50.0, avg_score -49.074074074074076\n",
      "Environment 6: episode 7, score -50.0, avg_score -49.09090909090909\n",
      "Environment 7: episode 7, score -50.0, avg_score -49.107142857142854\n",
      "Environment 0: episode 8, score -50.0, avg_score -49.12280701754386\n",
      "Environment 1: episode 8, score -50.0, avg_score -49.13793103448276\n",
      "Environment 2: episode 8, score -50.0, avg_score -49.152542372881356\n",
      "Rendering episode 60.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_60.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_60.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_60.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 8, score -50.0, avg_score -49.166666666666664\n",
      "Environment 4: episode 8, score -50.0, avg_score -49.18032786885246\n",
      "Environment 5: episode 8, score -50.0, avg_score -49.193548387096776\n",
      "Environment 6: episode 8, score -50.0, avg_score -49.20634920634921\n",
      "Environment 7: episode 8, score 0.0, avg_score -48.4375\n",
      "Environment 0: episode 9, score -50.0, avg_score -48.46153846153846\n",
      "Environment 1: episode 9, score -50.0, avg_score -48.484848484848484\n",
      "Environment 2: episode 9, score -50.0, avg_score -48.507462686567166\n",
      "Environment 3: episode 9, score -50.0, avg_score -48.529411764705884\n",
      "Environment 4: episode 9, score -50.0, avg_score -48.55072463768116\n",
      "Environment 5: episode 9, score -50.0, avg_score -48.57142857142857\n",
      "Environment 6: episode 9, score -50.0, avg_score -48.59154929577465\n",
      "Environment 7: episode 9, score -50.0, avg_score -48.611111111111114\n",
      "Environment 0: episode 10, score -50.0, avg_score -48.63013698630137\n",
      "Environment 1: episode 10, score -50.0, avg_score -48.648648648648646\n",
      "Environment 2: episode 10, score -50.0, avg_score -48.666666666666664\n",
      "Environment 3: episode 10, score -50.0, avg_score -48.68421052631579\n",
      "Environment 4: episode 10, score -50.0, avg_score -48.701298701298704\n",
      "Environment 5: episode 10, score -50.0, avg_score -48.717948717948715\n",
      "Environment 6: episode 10, score -50.0, avg_score -48.734177215189874\n",
      "Rendering episode 80.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_80.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_80.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_80.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 10, score 0.0, avg_score -48.125\n",
      "Environment 0: episode 11, score -50.0, avg_score -48.148148148148145\n",
      "Environment 1: episode 11, score -50.0, avg_score -48.170731707317074\n",
      "Environment 2: episode 11, score -50.0, avg_score -48.19277108433735\n",
      "Environment 3: episode 11, score 0.0, avg_score -47.61904761904762\n",
      "Environment 4: episode 11, score -50.0, avg_score -47.64705882352941\n",
      "Environment 5: episode 11, score -50.0, avg_score -47.674418604651166\n",
      "Environment 6: episode 11, score -46.0, avg_score -47.6551724137931\n",
      "Environment 7: episode 11, score -50.0, avg_score -47.68181818181818\n",
      "Environment 0: episode 12, score -50.0, avg_score -47.70786516853933\n",
      "Environment 1: episode 12, score -50.0, avg_score -47.733333333333334\n",
      "Environment 2: episode 12, score -50.0, avg_score -47.75824175824176\n",
      "Environment 3: episode 12, score -50.0, avg_score -47.78260869565217\n",
      "Environment 4: episode 12, score -50.0, avg_score -47.806451612903224\n",
      "Environment 5: episode 12, score -50.0, avg_score -47.829787234042556\n",
      "Environment 6: episode 12, score -50.0, avg_score -47.85263157894737\n",
      "Environment 7: episode 12, score -50.0, avg_score -47.875\n",
      "Environment 0: episode 13, score -50.0, avg_score -47.896907216494846\n",
      "Environment 1: episode 13, score 0.0, avg_score -47.40816326530612\n",
      "Environment 2: episode 13, score -50.0, avg_score -47.43434343434343\n",
      "Rendering episode 100.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_100.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_100.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_100.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 13, score -50.0, avg_score -47.46\n",
      "Environment 4: episode 13, score -50.0, avg_score -47.46\n",
      "Environment 5: episode 13, score -50.0, avg_score -47.46\n",
      "Environment 6: episode 13, score -50.0, avg_score -47.46\n",
      "Environment 7: episode 13, score 0.0, avg_score -46.96\n",
      "Environment 0: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 1: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 2: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 3: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 4: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 5: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 6: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 7: episode 14, score -50.0, avg_score -46.96\n",
      "Environment 0: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 1: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 2: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 3: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 4: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 5: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 6: episode 15, score -50.0, avg_score -46.96\n",
      "Rendering episode 120.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_120.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_120.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_120.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 15, score -50.0, avg_score -46.96\n",
      "Environment 0: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 1: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 2: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 3: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 4: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 5: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 6: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 7: episode 16, score -50.0, avg_score -46.96\n",
      "Environment 0: episode 17, score -50.0, avg_score -46.96\n",
      "Environment 1: episode 17, score 0.0, avg_score -46.46\n",
      "Environment 2: episode 17, score -50.0, avg_score -46.46\n",
      "Environment 3: episode 17, score -50.0, avg_score -46.46\n",
      "Environment 4: episode 17, score -50.0, avg_score -46.46\n",
      "Environment 5: episode 17, score -50.0, avg_score -46.46\n",
      "Environment 6: episode 17, score -50.0, avg_score -46.46\n",
      "Environment 7: episode 17, score -50.0, avg_score -46.46\n",
      "Environment 0: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 1: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 2: episode 18, score -50.0, avg_score -46.46\n",
      "Rendering episode 140.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_140.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_140.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_140.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 4: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 5: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 6: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 7: episode 18, score -50.0, avg_score -46.46\n",
      "Environment 0: episode 19, score -50.0, avg_score -46.46\n",
      "Environment 1: episode 19, score -50.0, avg_score -46.46\n",
      "Environment 2: episode 19, score -50.0, avg_score -46.46\n",
      "Environment 3: episode 19, score -50.0, avg_score -46.46\n",
      "Environment 4: episode 19, score -50.0, avg_score -46.46\n",
      "Environment 5: episode 19, score -50.0, avg_score -46.96\n",
      "Environment 6: episode 19, score -50.0, avg_score -46.96\n",
      "Environment 7: episode 19, score 0.0, avg_score -46.46\n",
      "Environment 0: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 1: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 2: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 3: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 4: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 5: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 6: episode 20, score -50.0, avg_score -46.46\n",
      "Rendering episode 160.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_160.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_160.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_160.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 20, score -50.0, avg_score -46.46\n",
      "Environment 0: episode 21, score -50.0, avg_score -46.46\n",
      "Environment 1: episode 21, score -50.0, avg_score -46.46\n",
      "Environment 2: episode 21, score -50.0, avg_score -46.46\n",
      "Environment 3: episode 21, score -50.0, avg_score -46.96\n",
      "Environment 4: episode 21, score -50.0, avg_score -46.96\n",
      "Environment 5: episode 21, score -50.0, avg_score -46.96\n",
      "Environment 6: episode 21, score -50.0, avg_score -46.96\n",
      "Environment 7: episode 21, score -50.0, avg_score -46.96\n",
      "Environment 0: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 1: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 2: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 3: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 4: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 5: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 6: episode 22, score -50.0, avg_score -46.96\n",
      "Environment 7: episode 22, score 0.0, avg_score -46.46\n",
      "Environment 0: episode 23, score -50.0, avg_score -46.46\n",
      "Environment 1: episode 23, score 0.0, avg_score -45.96\n",
      "Environment 2: episode 23, score -50.0, avg_score -45.96\n",
      "Rendering episode 180.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_180.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_180.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_180.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 23, score -50.0, avg_score -46.46\n",
      "Environment 4: episode 23, score -50.0, avg_score -46.46\n",
      "Environment 5: episode 23, score -50.0, avg_score -46.46\n",
      "Environment 6: episode 23, score -50.0, avg_score -46.46\n",
      "Environment 7: episode 23, score -50.0, avg_score -46.96\n",
      "Environment 0: episode 24, score -50.0, avg_score -46.96\n",
      "Environment 1: episode 24, score -50.0, avg_score -46.96\n",
      "Environment 2: episode 24, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 24, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 24, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 24, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 24, score -50.0, avg_score -47.0\n",
      "Environment 7: episode 24, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 25, score -50.0, avg_score -47.0\n",
      "Environment 1: episode 25, score -50.0, avg_score -47.0\n",
      "Environment 2: episode 25, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 25, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 25, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 25, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 25, score -50.0, avg_score -47.5\n",
      "Rendering episode 200.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_200.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_200.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_200.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 25, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 26, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 26, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 26, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 26, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 26, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 26, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 26, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 26, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 27, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 27, score 0.0, avg_score -47.5\n",
      "Environment 2: episode 27, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 27, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 27, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 27, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 27, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 27, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 28, score -50.0, avg_score -47.5\n",
      "Rendering episode 220.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_220.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_220.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_220.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 28, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 29, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 29, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 29, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 29, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 29, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 29, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 29, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 29, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 30, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 30, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 30, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 30, score 0.0, avg_score -47.5\n",
      "Environment 4: episode 30, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 30, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 30, score -50.0, avg_score -47.5\n",
      "Rendering episode 240.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_240.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_240.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_240.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 30, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 31, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 32, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 32, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 32, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 32, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 32, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 32, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 32, score 0.0, avg_score -47.5\n",
      "Environment 7: episode 32, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 33, score -50.0, avg_score -47.5\n",
      "Rendering episode 260.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_260.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_260.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_260.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: 0.0 Avg Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 33, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 34, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 35, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 35, score 0.0, avg_score -47.0\n",
      "Environment 2: episode 35, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 35, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 35, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 35, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 35, score -50.0, avg_score -48.0\n",
      "Rendering episode 280.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_280.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_280.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_280.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 35, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 36, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 37, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 37, score 0.0, avg_score -47.5\n",
      "Environment 0: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 38, score -50.0, avg_score -47.5\n",
      "Rendering episode 300.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_300.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_300.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_300.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 38, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 39, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 39, score 0.0, avg_score -47.0\n",
      "Environment 2: episode 39, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 39, score 0.0, avg_score -46.5\n",
      "Environment 4: episode 39, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 39, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 39, score -50.0, avg_score -47.0\n",
      "Environment 7: episode 39, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 1: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 2: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 40, score -50.0, avg_score -47.0\n",
      "Rendering episode 320.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_320.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_320.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_320.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 40, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 1: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 2: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 7: episode 41, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 42, score 0.0, avg_score -46.5\n",
      "Environment 1: episode 42, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 42, score -50.0, avg_score -46.5\n",
      "Environment 3: episode 42, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 42, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 42, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 42, score -50.0, avg_score -46.5\n",
      "Environment 7: episode 42, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 43, score 0.0, avg_score -46.5\n",
      "Environment 1: episode 43, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 43, score -50.0, avg_score -46.5\n",
      "Rendering episode 340.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_340.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_340.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_340.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 43, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 43, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 43, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 43, score -50.0, avg_score -46.5\n",
      "Environment 7: episode 43, score -50.0, avg_score -46.5\n",
      "Environment 0: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 1: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 3: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 7: episode 44, score -50.0, avg_score -46.5\n",
      "Environment 0: episode 45, score -50.0, avg_score -46.5\n",
      "Environment 1: episode 45, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 45, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 45, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 45, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 45, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 45, score -50.0, avg_score -47.0\n",
      "Rendering episode 360.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_360.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_360.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_360.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 45, score 0.0, avg_score -46.5\n",
      "Environment 0: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 1: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 3: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 7: episode 46, score -50.0, avg_score -46.5\n",
      "Environment 0: episode 47, score -50.0, avg_score -46.5\n",
      "Environment 1: episode 47, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 47, score -50.0, avg_score -46.5\n",
      "Environment 3: episode 47, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 47, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 47, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 47, score -50.0, avg_score -47.0\n",
      "Environment 7: episode 47, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 48, score 0.0, avg_score -46.5\n",
      "Environment 1: episode 48, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 48, score -50.0, avg_score -46.5\n",
      "Rendering episode 380.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_380.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_380.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_380.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 48, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 48, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 48, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 48, score -50.0, avg_score -46.5\n",
      "Environment 7: episode 48, score -50.0, avg_score -46.5\n",
      "Environment 0: episode 49, score -50.0, avg_score -46.5\n",
      "Environment 1: episode 49, score -50.0, avg_score -46.5\n",
      "Environment 2: episode 49, score -50.0, avg_score -46.5\n",
      "Environment 3: episode 49, score -50.0, avg_score -46.5\n",
      "Environment 4: episode 49, score -50.0, avg_score -46.5\n",
      "Environment 5: episode 49, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 49, score 0.0, avg_score -46.0\n",
      "Environment 7: episode 49, score -50.0, avg_score -46.0\n",
      "Environment 0: episode 50, score -50.0, avg_score -46.0\n",
      "Environment 1: episode 50, score -50.0, avg_score -46.0\n",
      "Environment 2: episode 50, score -50.0, avg_score -46.0\n",
      "Environment 3: episode 50, score 0.0, avg_score -46.0\n",
      "Environment 4: episode 50, score -50.0, avg_score -46.0\n",
      "Environment 5: episode 50, score -50.0, avg_score -46.0\n",
      "Environment 6: episode 50, score -50.0, avg_score -46.0\n",
      "Rendering episode 400.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_400.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_400.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_400.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 50, score -50.0, avg_score -46.0\n",
      "Environment 0: episode 51, score -50.0, avg_score -46.0\n",
      "Environment 1: episode 51, score -50.0, avg_score -46.0\n",
      "Environment 2: episode 51, score -50.0, avg_score -46.0\n",
      "Environment 3: episode 51, score -50.0, avg_score -46.0\n",
      "Environment 4: episode 51, score -50.0, avg_score -46.0\n",
      "Environment 5: episode 51, score -50.0, avg_score -46.5\n",
      "Environment 6: episode 51, score -50.0, avg_score -46.5\n",
      "Environment 7: episode 51, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 1: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 2: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 7: episode 52, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 1: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 2: episode 53, score -50.0, avg_score -47.0\n",
      "Rendering episode 420.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_420.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_420.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_420.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 5: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 6: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 7: episode 53, score -50.0, avg_score -47.0\n",
      "Environment 0: episode 54, score -50.0, avg_score -47.0\n",
      "Environment 1: episode 54, score -50.0, avg_score -47.0\n",
      "Environment 2: episode 54, score -50.0, avg_score -47.0\n",
      "Environment 3: episode 54, score -50.0, avg_score -47.0\n",
      "Environment 4: episode 54, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 54, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 54, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 54, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 55, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 55, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 55, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 55, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 55, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 55, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 55, score -50.0, avg_score -48.0\n",
      "Rendering episode 440.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_440.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_440.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_440.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 55, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 56, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 57, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 57, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 57, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 57, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 57, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 57, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 57, score 0.0, avg_score -47.5\n",
      "Environment 7: episode 57, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 58, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 58, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 58, score -50.0, avg_score -47.5\n",
      "Rendering episode 460.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_460.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_460.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_460.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 58, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 58, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 58, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 58, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 58, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 59, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 60, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 60, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 60, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 60, score 0.0, avg_score -47.5\n",
      "Environment 4: episode 60, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 60, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 60, score -50.0, avg_score -48.0\n",
      "Rendering episode 480.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_480.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_480.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_480.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 60, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 61, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 62, score 0.0, avg_score -47.5\n",
      "Environment 1: episode 62, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 62, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 62, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 62, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 62, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 62, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 62, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 63, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 63, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 63, score -50.0, avg_score -48.5\n",
      "Rendering episode 500.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_500.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_500.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_500.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 63, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 63, score 0.0, avg_score -48.0\n",
      "Environment 5: episode 63, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 63, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 63, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 64, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 65, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 65, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 65, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 65, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 65, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 65, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 65, score 0.0, avg_score -47.5\n",
      "Rendering episode 520.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_520.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_520.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_520.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 65, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 66, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 67, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 68, score -50.0, avg_score -47.5\n",
      "Rendering episode 540.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_540.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_540.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_540.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: 0.0 Avg Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 68, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 69, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 70, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 70, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 70, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 70, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 70, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 70, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 70, score -50.0, avg_score -48.0\n",
      "Rendering episode 560.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_560.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_560.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_560.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 70, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 71, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 71, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 71, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 71, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 71, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 71, score 0.0, avg_score -47.5\n",
      "Environment 6: episode 71, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 71, score -50.0, avg_score -47.5\n",
      "Environment 0: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 5: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 6: episode 72, score -50.0, avg_score -47.5\n",
      "Environment 7: episode 72, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 73, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 73, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 73, score -50.0, avg_score -48.0\n",
      "Rendering episode 580.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_580.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_580.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_580.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 73, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 73, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 73, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 73, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 73, score 0.0, avg_score -47.5\n",
      "Environment 0: episode 74, score -50.0, avg_score -47.5\n",
      "Environment 1: episode 74, score -50.0, avg_score -47.5\n",
      "Environment 2: episode 74, score -50.0, avg_score -47.5\n",
      "Environment 3: episode 74, score -50.0, avg_score -47.5\n",
      "Environment 4: episode 74, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 74, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 74, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 74, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 75, score -50.0, avg_score -48.0\n",
      "Rendering episode 600.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_600.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_600.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_600.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n",
      "Environment 7: episode 75, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 76, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 76, score 0.0, avg_score -48.0\n",
      "Environment 2: episode 76, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 76, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 76, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 76, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 76, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 76, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 77, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 78, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 78, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 78, score -50.0, avg_score -48.5\n",
      "Rendering episode 620.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_620.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_620.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_620.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n",
      "Environment 3: episode 78, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 78, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 78, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 78, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 78, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 79, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 80, score -50.0, avg_score -48.5\n",
      "Rendering episode 640.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_640.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_640.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_640.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 80, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 81, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 82, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 83, score -50.0, avg_score -48.5\n",
      "Rendering episode 660.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_660.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_660.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_660.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n",
      "Environment 3: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 83, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 84, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 2: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 3: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 4: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 5: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 7: episode 84, score -50.0, avg_score -49.0\n",
      "Environment 0: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 1: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 2: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 3: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 4: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 5: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 85, score -50.0, avg_score -49.0\n",
      "Rendering episode 680.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_680.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_680.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_680.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 85, score -50.0, avg_score -49.0\n",
      "Environment 0: episode 86, score -50.0, avg_score -49.0\n",
      "Environment 1: episode 86, score -50.0, avg_score -49.0\n",
      "Environment 2: episode 86, score -50.0, avg_score -49.0\n",
      "Environment 3: episode 86, score -50.0, avg_score -49.5\n",
      "Environment 4: episode 86, score 0.0, avg_score -49.0\n",
      "Environment 5: episode 86, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 86, score -50.0, avg_score -49.0\n",
      "Environment 7: episode 86, score 0.0, avg_score -48.5\n",
      "Environment 0: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 87, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 88, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 88, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 88, score -50.0, avg_score -48.5\n",
      "Rendering episode 700.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_700.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_700.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_700.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 88, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 88, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 88, score 0.0, avg_score -48.5\n",
      "Environment 6: episode 88, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 88, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 89, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 90, score -50.0, avg_score -48.5\n",
      "Rendering episode 720.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_720.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_720.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_720.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 90, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 91, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 92, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 93, score -50.0, avg_score -48.5\n",
      "Rendering episode 740.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_740.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_740.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_740.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 93, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 94, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 95, score -50.0, avg_score -48.5\n",
      "Rendering episode 760.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_760.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_760.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_760.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 95, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 96, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 97, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 98, score -50.0, avg_score -48.5\n",
      "Rendering episode 780.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_780.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_780.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_780.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 98, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 99, score 0.0, avg_score -48.5\n",
      "Environment 1: episode 99, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 99, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 99, score -50.0, avg_score -49.0\n",
      "Environment 4: episode 99, score -50.0, avg_score -49.0\n",
      "Environment 5: episode 99, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 99, score -50.0, avg_score -49.0\n",
      "Environment 7: episode 99, score -50.0, avg_score -49.0\n",
      "Environment 0: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 1: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 2: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 3: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 4: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 5: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 100, score -50.0, avg_score -49.0\n",
      "Rendering episode 800.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_800.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_800.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_800.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 100, score -50.0, avg_score -49.0\n",
      "Environment 0: episode 101, score -50.0, avg_score -49.0\n",
      "Environment 1: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 2: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 3: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 4: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 5: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 6: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 7: episode 101, score -50.0, avg_score -49.5\n",
      "Environment 0: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 1: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 2: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 3: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 4: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 5: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 6: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 7: episode 102, score -50.0, avg_score -49.5\n",
      "Environment 0: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 1: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 2: episode 103, score -50.0, avg_score -49.5\n",
      "Rendering episode 820.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_820.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_820.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_820.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 4: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 5: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 6: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 7: episode 103, score -50.0, avg_score -49.5\n",
      "Environment 0: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 1: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 2: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 3: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 4: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 5: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 6: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 7: episode 104, score -50.0, avg_score -49.5\n",
      "Environment 0: episode 105, score -50.0, avg_score -49.5\n",
      "Environment 1: episode 105, score -50.0, avg_score -49.5\n",
      "Environment 2: episode 105, score -50.0, avg_score -49.5\n",
      "Environment 3: episode 105, score -50.0, avg_score -49.5\n",
      "Environment 4: episode 105, score 0.0, avg_score -49.0\n",
      "Environment 5: episode 105, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 105, score -50.0, avg_score -49.0\n",
      "Rendering episode 840.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_840.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_840.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_840.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 105, score -50.0, avg_score -49.0\n",
      "Environment 0: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 1: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 2: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 3: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 4: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 5: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 6: episode 106, score -50.0, avg_score -49.0\n",
      "Environment 7: episode 106, score 0.0, avg_score -48.5\n",
      "Environment 0: episode 107, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 107, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 107, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 107, score 0.0, avg_score -48.0\n",
      "Environment 4: episode 107, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 107, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 107, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 107, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 108, score -50.0, avg_score -48.0\n",
      "Rendering episode 860.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_860.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_860.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_860.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 108, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 109, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 110, score -50.0, avg_score -48.0\n",
      "Rendering episode 880.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_880.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_880.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_880.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 110, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 111, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 111, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 111, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 111, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 111, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 111, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 111, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 111, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 112, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 113, score -50.0, avg_score -48.5\n",
      "Rendering episode 900.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_900.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_900.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_900.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n",
      "Environment 3: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 113, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 5: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 6: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 7: episode 114, score -50.0, avg_score -48.5\n",
      "Environment 0: episode 115, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 115, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 115, score -50.0, avg_score -48.5\n",
      "Environment 3: episode 115, score 0.0, avg_score -48.0\n",
      "Environment 4: episode 115, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 115, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 115, score -50.0, avg_score -48.0\n",
      "Rendering episode 920.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_920.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_920.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_920.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 115, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 116, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 117, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 118, score -50.0, avg_score -48.5\n",
      "Environment 1: episode 118, score -50.0, avg_score -48.5\n",
      "Environment 2: episode 118, score 0.0, avg_score -48.0\n",
      "Rendering episode 940.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_940.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_940.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_940.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 118, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 118, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 118, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 118, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 118, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 119, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 119, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 119, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 119, score -50.0, avg_score -48.5\n",
      "Environment 4: episode 119, score 0.0, avg_score -48.0\n",
      "Environment 5: episode 119, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 119, score 0.0, avg_score -47.5\n",
      "Environment 7: episode 119, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 120, score -50.0, avg_score -48.0\n",
      "Rendering episode 960.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_960.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_960.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_960.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 120, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 121, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 122, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 123, score -50.0, avg_score -48.0\n",
      "Rendering episode 980.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_980.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_980.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_980.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 3: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 123, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 7: episode 124, score -50.0, avg_score -48.0\n",
      "Environment 0: episode 125, score -50.0, avg_score -48.0\n",
      "Environment 1: episode 125, score -50.0, avg_score -48.0\n",
      "Environment 2: episode 125, score -50.0, avg_score -48.0\n",
      "Environment 3: episode 125, score -50.0, avg_score -48.0\n",
      "Environment 4: episode 125, score -50.0, avg_score -48.0\n",
      "Environment 5: episode 125, score -50.0, avg_score -48.0\n",
      "Environment 6: episode 125, score -50.0, avg_score -48.0\n",
      "Rendering episode 1000.0 during training...\n",
      "rendering episode...\n",
      "Moviepy - Building video models/her/renders/train/episode_1000.0.mp4.\n",
      "Moviepy - Writing video models/her/renders/train/episode_1000.0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready models/her/renders/train/episode_1000.0.mp4\n",
      "episode rendered\n",
      "Environment 0: Episode 1/1 Score: -50.0 Avg Score: -50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 7: episode 125, score -50.0, avg_score -48.0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▄▄▅▃▂▅█▄▃▂▃▆▅▃▃▄▃▅▆▃▃▄▇▄▁▃▅▄▁▁▆▃▅▄▃▅▁▆▆▃</td></tr><tr><td>action_0_noise</td><td>▅▅▅▅▅▅▅▅▁▅▄▇▄▂▇▆▅▅▇█▃▅▃▇▆▅▅█▆▃▅▂▇█▇▅▂▂▄▅</td></tr><tr><td>action_1</td><td>▅█▄▆▅▄▁▃▄▂▇▁▃▄▃▄▂▆▅▅▄▄▄▅▂▄▁▃▆▂▁▄▅▄▃▃▅▄▃▅</td></tr><tr><td>action_1_noise</td><td>▅▅▅▅▅▅▅▅▅▅▂▁▃▃▅▇▅▂▆▆▂▆▅▅▁▄▆█▅▄▅▆▅▅▅▅▅▅▅▆</td></tr><tr><td>action_2</td><td>▆▄▂▅▅█▂▃▄▂▅▃▄▅▇▄▅▃▅▅▅▅▄▃▃▃▄▄▃▂▃▅▄▄▁▄▅▅▄▂</td></tr><tr><td>action_2_noise</td><td>▅▅▅▅▄▆▂▆▄▅▇▃▆▅▅▄▇▅▅▃▇▁▄▃▅▅▄▆▄▅▅▇█▇▅▅▆▅▄▅</td></tr><tr><td>action_3</td><td>▇▇▇▅▅▆█▄▄▆▄▇▂▅▄▄▂█▇▁▃▂▅▂▅▅▆▆▃▃▄▁▁▅▃▃▂▄▆▄</td></tr><tr><td>action_3_noise</td><td>▄▄▄▄▄▄▄▄▄▄▄▄█▄▃▅▁▃▃▄▄▄▇▃▄▄█▆▅▁▄▇▇▇▅▄▄▃▄▄</td></tr><tr><td>actor_loss</td><td>▇▄▃▃▆▆▇▃▄▄▂▄▁▆▇▄▄▇▆▂▄▅▅▃▅▅▃▄▁▄█▄▅▆▆▇▆▄▃█</td></tr><tr><td>actor_predictions</td><td>▅▁▅▃▁█▅▅▅▆▃▁▅█▆▄▃▆▅▅▅▆▅▄▅▃▃▆▅▅▄▆▇▃▄▄▆▅▆▃</td></tr><tr><td>best</td><td>▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▆█▂▃▂▁▂▃▁▄▁▁▂▁▂▁▅▁▄▁▁▁▁▂▁▂▃▂▁▁▂▂▂▂▁▂▂▂▁▄</td></tr><tr><td>critic_predictions</td><td>▄▁▃▅▃▅▅▅▅▇▆█▄▆▃▇▇▄▃▅▅▆▅▄▃▆▆█▅▅▆▄▅▅▄▃▃▅▄▄</td></tr><tr><td>episode</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>episode_reward</td><td>▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>goal distance</td><td>▃▃▃▃▁▁▅▁█▇▄█▄▄▆▅▃▅▂▆▅▅▂▆▄█▃▇▇▃▆▆▆▅▅▂▆▃▄▃</td></tr><tr><td>step_reward</td><td>▁█▂▂▁▃▁▁▁▂▁▂▁▁▁▂▁▂▁▁▁▂▂▂▁▂▁▁█▁▁▁▁▁▂▁█▁▃▁</td></tr><tr><td>success rate</td><td>▁▁█▇█▇▇█▇▇▇▇▇██████▇█▇▇▇▇▇▇▇▇▇▆▆▆▆▆▇▇▇▇▆</td></tr><tr><td>target_actor_predictions</td><td>▂▂▁▃▆▃▆▂▃▃▄▂▃▄▂▄▃▇▆▄▃▃█▃▅▁▂▆▂▆▄▂▇▅▅▄▅▆▇▅</td></tr><tr><td>target_critic_predictions</td><td>▁▇▄▆▆▅▆█▇▆▇█▇▇█▆▆▇▆▆▇▇▅▆▆▅▇▆▇▇▅▇▇▅▆▆▆▅▇▇</td></tr><tr><td>tolerance count</td><td>████████████████▅███████████▁█▆█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>-0.15962</td></tr><tr><td>action_0_noise</td><td>-0.03015</td></tr><tr><td>action_1</td><td>0.0638</td></tr><tr><td>action_1_noise</td><td>-0.08183</td></tr><tr><td>action_2</td><td>-0.19211</td></tr><tr><td>action_2_noise</td><td>-0.0506</td></tr><tr><td>action_3</td><td>-0.1514</td></tr><tr><td>action_3_noise</td><td>-0.09034</td></tr><tr><td>actor_loss</td><td>1.2489</td></tr><tr><td>actor_predictions</td><td>-0.00256</td></tr><tr><td>best</td><td>0</td></tr><tr><td>critic_loss</td><td>0.15704</td></tr><tr><td>critic_predictions</td><td>-1.19902</td></tr><tr><td>episode</td><td>1000</td></tr><tr><td>episode_reward</td><td>-50</td></tr><tr><td>goal distance</td><td>0.20891</td></tr><tr><td>step_reward</td><td>-1</td></tr><tr><td>success rate</td><td>0.04209</td></tr><tr><td>target_actor_predictions</td><td>0.00079</td></tr><tr><td>target_critic_predictions</td><td>-1.19332</td></tr><tr><td>tolerance count</td><td>364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-14</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4/runs/xszmti40' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4/runs/xszmti40</a><br> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchPickAndPlace-v4</a><br>Synced 5 W&B file(s), 52 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250226_033547-xszmti40/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logging_config - ERROR - Error during HER train process: 'GymnasiumWrapper' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/src/app/rl_agents.py\", line 4481, in train\n",
      "    self.agent.env.close()\n",
      "AttributeError: 'GymnasiumWrapper' object has no attribute 'close'\n"
     ]
    }
   ],
   "source": [
    "her.train(1000, 40, 20, 8, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in her.agent.env.env.envs:\n",
    "    e.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.replay_buffer.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [\n",
    "    (128, 'relu', \"kaiming normal\"),\n",
    "    (256, 'relu', \"kaiming normal\"),\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = models.PolicyModel(env=env, dense_layers=dense_layers, optimizer='Adam', learning_rate=0.001,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in policy_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = models.ValueModel(env, dense_layers=dense_layers, optimizer='Adam', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in value_model.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = rl_agents.ActorCritic(env,\n",
    "                                     policy_model,\n",
    "                                     value_model,\n",
    "                                     discount=0.99,\n",
    "                                     policy_trace_decay=0.5,\n",
    "                                     value_trace_decay=0.5,\n",
    "                                     callbacks=[rl_callbacks.WandbCallback('CartPole-v1-Actor-Critic')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic.train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [\n",
    "    (128, 'relu', {\n",
    "                    \"kaiming normal\": {\n",
    "                        \"a\":1.0,\n",
    "                        \"mode\":'fan_in'\n",
    "                    }\n",
    "                },\n",
    "    ),\n",
    "    # (256, 'relu', {\n",
    "    #                 \"kaiming_normal\": {\n",
    "    #                     \"a\":0.0,\n",
    "    #                     \"mode\":'fan_in'\n",
    "    #                 }\n",
    "    #             },\n",
    "    # )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [(128, 'relu', \"kaiming normal\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = models.ValueModel(env, dense_layers, 'Adam', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in value_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = models.PolicyModel(env, dense_layers, 'Adam', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in policy_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce = rl_agents.Reinforce(env, policy_model, value_model, 0.99, [rl_callbacks.WandbCallback('CartPole-v0_REINFORCE', chkpt_freq=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce.train(200, True, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG w/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layers = [\n",
    "    # {\n",
    "    #     \"batchnorm\":\n",
    "    #     {\n",
    "    #         \"num_features\":3\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 7,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_models.CNN(cnn_layers, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=cnn, dense_layers=dense_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=cnn, state_layers=state_layers, merged_layers=merged_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape=(1,))\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, mean=0.0, theta=0.15, sigma=0.01, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(\n",
    "    env,\n",
    "    actor,\n",
    "    critic,\n",
    "    discount=0.98,\n",
    "    tau=0.05,\n",
    "    action_epsilon=0.2,\n",
    "    replay_buffer=replay_buffer,\n",
    "    batch_size=128,\n",
    "    noise=noise,\n",
    "    callbacks=[rl_callbacks.WandbCallback(\"CarRacing-v2\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.train(1000, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Reacher-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieved_goal = gym_helper.reacher_achieved_goal(env)\n",
    "action = env.action_space.sample()\n",
    "env.step(action)\n",
    "print(f'observation: {env.get_wrapper_attr(\"_get_obs\")()}')\n",
    "print(f'distance to goal: {env.get_wrapper_attr(\"_get_obs\")()[8::]}')\n",
    "print(f'fingertip: {env.get_wrapper_attr(\"get_body_com\")(\"fingertip\")}')\n",
    "print(f'target: {env.get_wrapper_attr(\"get_body_com\")(\"target\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_achieved_goal = env.get_wrapper_attr(\"_get_obs\")()[8::]\n",
    "desired_goal = [0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func(env, action, achieved_goal, next_achieved_goal, desired_goal, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env,\n",
    "                          cnn_model=None,\n",
    "                          dense_layers=dense_layers,\n",
    "                          goal_shape=(3,),\n",
    "                          optimizer=\"Adam\",\n",
    "                          optimizer_params={'weight_decay':0.0},\n",
    "                          learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env,\n",
    "                            cnn_model=None,\n",
    "                            state_layers=state_layers,\n",
    "                            merged_layers=merged_layers,\n",
    "                            goal_shape=(3,),\n",
    "                            optimizer=\"Adam\",\n",
    "                            optimizer_params={'weight_decay':0.0},\n",
    "                            learning_rate=0.0001,\n",
    "                            normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape\n",
    "replay_buffer = helper.ReplayBuffer(env, 100000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape,\n",
    "#                        mean=0.0,\n",
    "#                        theta=0.05,\n",
    "#                        sigma=0.15,\n",
    "#                        dt=1.0, device='cuda')\n",
    "\n",
    "noise=helper.NormalNoise(shape=env.action_space.shape,\n",
    "                         mean = 0.0,\n",
    "                         stddev=0.05,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Reacher-v4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(ddpg_agent,\n",
    "                    strategy='future',\n",
    "                    num_goals=4,\n",
    "                    tolerance=0.001,\n",
    "                    desired_goal=desired_goal_func,\n",
    "                    achieved_goal=achieved_goal_func,\n",
    "                    reward_fn=reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(10, 50, 16, 40, True, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.goal_normalizer.running_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.agent.replay_buffer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.agent.state_normalizer.running_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER w/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layers = [\n",
    "    # {\n",
    "    #     \"batchnorm\":\n",
    "    #     {\n",
    "    #         \"num_features\":3\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 7,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "cnn = cnn_models.CNN(cnn_layers, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env,\n",
    "                          cnn_model=cnn,\n",
    "                          dense_layers=dense_layers,\n",
    "                          goal_shape=(1,),\n",
    "                          optimizer=\"Adam\",\n",
    "                          optimizer_params={'weight_decay':0.0},\n",
    "                          learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env,\n",
    "                            cnn_model=cnn,\n",
    "                            state_layers=state_layers,\n",
    "                            merged_layers=merged_layers,\n",
    "                            goal_shape=(1,),\n",
    "                            optimizer=\"Adam\",\n",
    "                            optimizer_params={'weight_decay':0.0},\n",
    "                            learning_rate=0.001,\n",
    "                            normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape\n",
    "replay_buffer = helper.ReplayBuffer(env, 100000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape,\n",
    "#                        mean=0.0,\n",
    "#                        theta=0.05,\n",
    "#                        sigma=0.15,\n",
    "#                        dt=1.0, device='cuda')\n",
    "\n",
    "noise=helper.NormalNoise(shape=env.action_space.shape,\n",
    "                         mean = 0.0,\n",
    "                         stddev=0.05,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('CarRacing-v2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(ddpg_agent,\n",
    "                    strategy='future',\n",
    "                    num_goals=4,\n",
    "                    tolerance=1,\n",
    "                    desired_goal=desired_goal_func,\n",
    "                    achieved_goal=achieved_goal_func,\n",
    "                    reward_fn=reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=20,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=20\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset environment\n",
    "state, _ = her.agent.env.reset()\n",
    "# instantiate empty lists to store current episode trajectory\n",
    "states, actions, next_states, dones, state_achieved_goals, \\\n",
    "next_state_achieved_goals, desired_goals = [], [], [], [], [], [], []\n",
    "# set desired goal\n",
    "desired_goal = her.desired_goal_func(her.agent.env)\n",
    "# set achieved goal\n",
    "state_achieved_goal = her.achieved_goal_func(her.agent.env)\n",
    "# add initial state and goals to local normalizer stats\n",
    "her.state_normalizer.update_local_stats(state)\n",
    "her.goal_normalizer.update_local_stats(desired_goal)\n",
    "her.goal_normalizer.update_local_stats(state_achieved_goal)\n",
    "# set done flag\n",
    "done = False\n",
    "# reset episode reward to 0\n",
    "episode_reward = 0\n",
    "# reset steps counter for the episode\n",
    "episode_steps = 0\n",
    "\n",
    "while not done:\n",
    "    # get normalized values for state and desired goal\n",
    "    state_norm = her.state_normalizer.normalize(state)\n",
    "    desired_goal_norm = her.goal_normalizer.normalize(desired_goal)\n",
    "    # get action\n",
    "    action = her.agent.get_action(state_norm, desired_goal_norm, grad=False)\n",
    "    # take action\n",
    "    next_state, reward, term, trunc, _ = her.agent.env.step(action)\n",
    "    # get next state achieved goal\n",
    "    next_state_achieved_goal = her.achieved_goal_func(her.agent.env)\n",
    "    # add next state and next state achieved goal to normalizers\n",
    "    her.state_normalizer.update_local_stats(next_state)\n",
    "    her.goal_normalizer.update_local_stats(next_state_achieved_goal)\n",
    "    # store trajectory in replay buffer (non normalized!)\n",
    "    her.agent.replay_buffer.add(state, action, reward, next_state, done,\\\n",
    "                                    state_achieved_goal, next_state_achieved_goal, desired_goal)\n",
    "    \n",
    "    # append step state, action, next state, and goals to respective lists\n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "    next_states.append(next_state)\n",
    "    dones.append(done)\n",
    "    state_achieved_goals.append(state_achieved_goal)\n",
    "    next_state_achieved_goals.append(next_state_achieved_goal)\n",
    "    desired_goals.append(desired_goal)\n",
    "\n",
    "    # add to episode reward and increment steps counter\n",
    "    episode_reward += reward\n",
    "    episode_steps += 1\n",
    "    # update state and state achieved goal\n",
    "    state = next_state\n",
    "    state_achieved_goal = next_state_achieved_goal\n",
    "    # update done flag\n",
    "    if term or trunc:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package episode states, actions, next states, and goals into trajectory tuple\n",
    "trajectory = (states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals = trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (s, a, ns, d, sag, nsag, dg) in enumerate(zip(states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)):\n",
    "    print(f'a={a}, d={d}, sag={sag}, nsag={nsag}, dg={dg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"future\"\n",
    "num_goals = 4\n",
    "\n",
    "# loop over each step in the trajectory to set new achieved goals, calculate new reward, and save to replay buffer\n",
    "for idx, (state, action, next_state, done, state_achieved_goal, next_state_achieved_goal, desired_goal) in enumerate(zip(states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)):\n",
    "\n",
    "    if strategy == \"final\":\n",
    "        new_desired_goal = next_state_achieved_goals[-1]\n",
    "        new_reward = her.reward_fn(state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "        print(f'transition: action={action}, reward={new_reward}, done={done}, state_achieved_goal={state_achieved_goal}, next_state_achieved_goal={next_state_achieved_goal}, desired_goal={new_desired_goal}')\n",
    "        her.agent.replay_buffer.add(state, action, new_reward, next_state, done, state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "\n",
    "    if strategy == 'future':\n",
    "        for i in range(num_goals):\n",
    "            if idx + i + 1 >= len(states):\n",
    "                break\n",
    "            goal_idx = np.random.randint(idx + 1, len(states))\n",
    "            new_desired_goal = next_state_achieved_goals[goal_idx]\n",
    "            new_reward = her.reward_fn(state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "            print(f'transition: action={action}, reward={new_reward}, done={done}, state_achieved_goal={state_achieved_goal}, next_state_achieved_goal={next_state_achieved_goal}, desired_goal={new_desired_goal}')\n",
    "            her.agent.replay_buffer.add(state, action, new_reward, next_state, done, state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a, r, ns, d, sag, nsag, dg = her.agent.replay_buffer.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f'{i}: a={a[i]}, r={r[i]}, d={d[i]}, sag={sag[i]}, nsag={nsag[i]}, dg={dg[i]} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.01}, learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 100000, (3,))\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.99,\n",
    "                            tau=0.005,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_goal_func(env):\n",
    "    return np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "def achieved_goal_func(env):\n",
    "    return env.get_wrapper_attr('_get_obs')()\n",
    "\n",
    "def reward_func(env):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='none',\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.target_critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(1,1,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.observation_space.sample()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.state_normalizer.normalize(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = her.desired_goal_func(her.agent.env)\n",
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.goal_normalizer.normalize(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_renders(folder_path):\n",
    "    # Iterate over the files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has a .mp4 or .meta.json extension\n",
    "        if filename.endswith(\".mp4\") or filename.endswith(\".meta.json\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Remove the file\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_renders(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/ddpg/renders/training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Fetch-Reach (Robotics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v3\", max_episode_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieved_goal_func(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_wrapper_attr(\"_get_obs\")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchReach-v2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='future',\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=50,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, action, rewards, next_states, dones, achieved_goals, next_achieved_goals, desired_goals = her.agent.replay_buffer.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.env.get_wrapper_attr(\"distance_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get success\n",
    "her.agent.env.get_wrapper_attr(\"_is_success\")(achieved_goal_func(her.agent.env), desired_goal_func(her.agent.env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.env.get_wrapper_attr(\"goal_distance\")(next_state_achieved_goal, desired_goal, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.agent.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(pusher_her.agent.env.get_wrapper_attr(\"get_body_com\")(\"goal\") - pusher_her.agent.env.get_wrapper_attr(\"get_body_com\")(\"object\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.agent.replay_buffer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pusher_her.agent.replay_buffer.desired_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST ENV\n",
    "env = gym.make(\"Pusher-v5\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.wrappers.RecordVideo(\n",
    "                    env,\n",
    "                    \"/renders/training\",\n",
    "                    episode_trigger=lambda x: True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "# take action\n",
    "    next_state, reward, term, trunc, _ = env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Fetch Push (Robitics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.3,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=128,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchPush-v2\")],\n",
    "                            save_dir=\"fetch_push/models/ddpg/\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='final',\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0,\n",
    "    save_dir=\"fetch_push/models/her/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=50,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MULTITHREADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.3,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=128,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchPush-v2\")],\n",
    "                            save_dir=\"fetch_push/models/ddpg/\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='final',\n",
    "    num_workers=4,\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0,\n",
    "    save_dir=\"fetch_push/models/her/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config_path = \"/workspaces/RL_Agents/pytorch/src/app/HER_Test/her/config.json\"\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = rl_agents.HER.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for callback in agent.agent.callbacks:\n",
    "    print(callback._sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'assets/wandb_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    wandb_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'assets/sweep_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    sweep_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated configuration to a train config file\n",
    "os.makedirs('sweep', exist_ok=True)\n",
    "train_config_path = os.path.join(os.getcwd(), 'sweep/train_config.json')\n",
    "with open(train_config_path, 'w') as f:\n",
    "    json.dump(sweep_config, f)\n",
    "\n",
    "# Save and Set the sweep config path\n",
    "sweep_config_path = os.path.join(os.getcwd(), 'sweep/sweep_config.json')\n",
    "with open(sweep_config_path, 'w') as f:\n",
    "    json.dump(wandb_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['python', 'sweep.py']\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['WANDB_DISABLE_SERVICE'] = 'true'\n",
    "\n",
    "subprocess.Popen(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable\n",
    "os.environ['WANDB_DISABLE_SERVICE'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'sweep/sweep_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    sweep_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'sweep/train_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    train_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep=sweep_config, project=sweep_config[\"project\"])\n",
    "# loop over num wandb agents\n",
    "num_agents = 1\n",
    "# for agent in range(num_agents):\n",
    "wandb.agent(\n",
    "    sweep_id,\n",
    "    function=lambda: wandb_support._run_sweep(sweep_config, train_config,),\n",
    "    count=train_config['num_sweeps'],\n",
    "    project=sweep_config[\"project\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical, Beta, Normal, kl_divergence\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# env_id = 'Pendulum-v1'\n",
    "# env_id = 'LunarLanderContinuous-v3'\n",
    "env_id = 'BipedalWalker-v3'\n",
    "policy_lr = 3e-4\n",
    "value_lr = 2e-5\n",
    "entropy_coeff = 0.1\n",
    "kl_coeff = 0.1\n",
    "loss = 'kl'\n",
    "timesteps = 100_000\n",
    "num_envs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "seed = 42\n",
    "env = gym.make_vec(env_id, num_envs)\n",
    "# env = gym.make('BipedalWalker-v3')\n",
    "# _,_ = env.reset()\n",
    "# sample = env.action_space.sample()\n",
    "# if isinstance(sample, np.int64) or isinstance(sample, np.int32):\n",
    "#     print(f'discrete action space of size {env.action_space.n}')\n",
    "# elif isinstance(sample, np.ndarray):\n",
    "#     print(f'continuous action space of size {env.action_space.shape}')\n",
    "\n",
    "T.manual_seed(seed)\n",
    "T.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "gym.utils.seeding.np_random.seed = seed\n",
    "# Build policy model\n",
    "dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "policy = StochasticContinuousPolicy(env, num_envs, dense_layers, learning_rate=policy_lr, distribution='Beta', device=device)\n",
    "dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "value_function = ValueModel(env, dense_layers, learning_rate=value_lr, device=device)\n",
    "ppo_agent_hybrid1 = PPO(env, policy, value_function, distribution='Beta', discount=0.99, gae_coefficient=0.95, policy_clip=0.2, entropy_coefficient=entropy_coeff, kl_coefficient=kl_coeff, loss=loss)\n",
    "hybrid_train_info_1 = ppo_agent_hybrid1.train(timesteps=timesteps, trajectory_length=2048, batch_size=640, learning_epochs=10, num_envs=num_envs)\n",
    "\n",
    "# seed = 43\n",
    "# env = gym.make(env_id)\n",
    "# T.manual_seed(seed)\n",
    "# T.cuda.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# gym.utils.seeding.np_random.seed = seed\n",
    "# # Build policy model\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# policy = StochasticContinuousPolicy(env, dense_layers, learning_rate=3e-4)\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# value_function = ValueModel(env, dense_layers, learning_rate=3e-4)\n",
    "# ppo_agent_hybrid2 = PPO(env, policy, value_function, distribution='Beta', discount=0.99, gae_coefficient=0.95, policy_clip=0.2, entropy_coefficient=entropy_coeff, kl_coefficient=kl_coeff, loss=loss)\n",
    "# hybrid_train_info_2 = ppo_agent_hybrid2.train(timesteps=timesteps, trajectory_length=2048, batch_size=64, learning_epochs=10)\n",
    "\n",
    "# seed = 44\n",
    "# env = gym.make(env_id)\n",
    "# T.manual_seed(seed)\n",
    "# T.cuda.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# gym.utils.seeding.np_random.seed = seed\n",
    "# # Build policy model\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# policy = StochasticContinuousPolicy(env, dense_layers, learning_rate=3e-4)\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# value_function = ValueModel(env, dense_layers, learning_rate=3e-4)\n",
    "# ppo_agent_hybrid3 = PPO(env, policy, value_function, distribution='Beta', discount=0.99, gae_coefficient=0.95, policy_clip=0.2, entropy_coefficient=entropy_coeff, kl_coefficient=kl_coeff, loss=loss)\n",
    "# hybrid_train_info_3 = ppo_agent_hybrid3.train(timesteps=timesteps, trajectory_length=2048, batch_size=64, learning_epochs=10)\n",
    "# hybrid_test_info = ppo_agent_hybrid.test(1000, 'PPO_hybrid', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# env_id = 'Pendulum-v1'\n",
    "# env_id = 'LunarLanderContinuous-v3'\n",
    "env_id = 'BipedalWalker-v3'\n",
    "policy_lr = 3e-4\n",
    "value_lr = 2e-5\n",
    "entropy_coeff = 0.1\n",
    "kl_coeff = 0.01\n",
    "loss = 'kl'\n",
    "timesteps = 100_000\n",
    "num_envs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "seed = 42\n",
    "env = gym.make_vec(env_id, num_envs)\n",
    "# env = gym.make('BipedalWalker-v3')\n",
    "# _,_ = env.reset()\n",
    "# sample = env.action_space.sample()\n",
    "# if isinstance(sample, np.int64) or isinstance(sample, np.int32):\n",
    "#     print(f'discrete action space of size {env.action_space.n}')\n",
    "# elif isinstance(sample, np.ndarray):\n",
    "#     print(f'continuous action space of size {env.action_space.shape}')\n",
    "\n",
    "T.manual_seed(seed)\n",
    "T.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "gym.utils.seeding.np_random.seed = seed\n",
    "# Build policy model\n",
    "dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "policy = StochasticContinuousPolicy(env, num_envs, dense_layers, learning_rate=policy_lr, distribution='Beta', device=device)\n",
    "dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "value_function = ValueModel(env, dense_layers, learning_rate=value_lr, device=device)\n",
    "ppo_agent_hybrid2 = PPO(env, policy, value_function, distribution='Beta', discount=0.99, gae_coefficient=0.95, policy_clip=0.2, entropy_coefficient=entropy_coeff, kl_coefficient=kl_coeff, loss=loss)\n",
    "hybrid_train_info_2 = ppo_agent_hybrid2.train(timesteps=timesteps, trajectory_length=2048, batch_size=640, learning_epochs=10, num_envs=num_envs)\n",
    "\n",
    "# seed = 43\n",
    "# env = gym.make(env_id)\n",
    "# T.manual_seed(seed)\n",
    "# T.cuda.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# gym.utils.seeding.np_random.seed = seed\n",
    "# # Build policy model\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# policy = StochasticContinuousPolicy(env, dense_layers, learning_rate=3e-4)\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# value_function = ValueModel(env, dense_layers, learning_rate=3e-4)\n",
    "# ppo_agent_hybrid2 = PPO(env, policy, value_function, distribution='Beta', discount=0.99, gae_coefficient=0.95, policy_clip=0.2, entropy_coefficient=entropy_coeff, kl_coefficient=kl_coeff, loss=loss)\n",
    "# hybrid_train_info_2 = ppo_agent_hybrid2.train(timesteps=timesteps, trajectory_length=2048, batch_size=64, learning_epochs=10)\n",
    "\n",
    "# seed = 44\n",
    "# env = gym.make(env_id)\n",
    "# T.manual_seed(seed)\n",
    "# T.cuda.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# gym.utils.seeding.np_random.seed = seed\n",
    "# # Build policy model\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# policy = StochasticContinuousPolicy(env, dense_layers, learning_rate=3e-4)\n",
    "# dense_layers = [(128,\"tanh\",{\"default\":{}}),(128,\"tanh\",{\"default\":{}})]\n",
    "# value_function = ValueModel(env, dense_layers, learning_rate=3e-4)\n",
    "# ppo_agent_hybrid3 = PPO(env, policy, value_function, distribution='Beta', discount=0.99, gae_coefficient=0.95, policy_clip=0.2, entropy_coefficient=entropy_coeff, kl_coefficient=kl_coeff, loss=loss)\n",
    "# hybrid_train_info_3 = ppo_agent_hybrid3.train(timesteps=timesteps, trajectory_length=2048, batch_size=64, learning_epochs=10)\n",
    "# hybrid_test_info = ppo_agent_hybrid.test(1000, 'PPO_hybrid', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMS ##\n",
    "# env_id = 'Pendulum-v1'\n",
    "# env_id = 'LunarLanderContinuous-v3'\n",
    "# env_id = 'BipedalWalker-v3'\n",
    "env_id = 'Humanoid-v5'\n",
    "# env_id = \"Reacher-v5\"\n",
    "# env_id = \"Walker2d-v5\"\n",
    "# env_id = 'ALE/SpaceInvaders-ram-v5'\n",
    "# env_id = \"CarRacing-v2\"\n",
    "# env_id = \"BipedalWalkerHardcore-v3\"\n",
    "\n",
    "timesteps = 1_000_000\n",
    "trajectory_length = 2000\n",
    "batch_size = 64\n",
    "learning_epochs = 10\n",
    "num_envs = 16\n",
    "policy_lr = 3e-4\n",
    "value_lr = 2e-5\n",
    "policy_clip = 0.2\n",
    "entropy_coeff = 0.001\n",
    "loss = 'hybrid'\n",
    "kl_coeff = 0.0\n",
    "normalize_advantages = True\n",
    "normalize_values = False\n",
    "norm_clip = np.inf\n",
    "grad_clip = 40.0\n",
    "reward_clip = 1.0\n",
    "lambda_ = 0.0\n",
    "distribution = 'beta'\n",
    "device = 'cuda'\n",
    "\n",
    "# Render Settings\n",
    "render_freq = 100\n",
    "\n",
    "## WANDB ##\n",
    "project_name = 'Humanoid-v5'\n",
    "run_name = None\n",
    "callbacks = [WandbCallback(project_name, run_name)]\n",
    "# callbacks = []\n",
    "\n",
    "seed = 42\n",
    "env = gym.make(env_id)\n",
    "\n",
    "save_dir = 'Humanoid'\n",
    "# env = gym.make('BipedalWalker-v3')\n",
    "# _,_ = env.reset()\n",
    "# sample = env.action_space.sample()\n",
    "# if isinstance(sample, np.int64) or isinstance(sample, np.int32):\n",
    "#     print(f'discrete action space of size {env.action_space.n}')\n",
    "# elif isinstance(sample, np.ndarray):\n",
    "#     print(f'continuous action space of size {env.action_space.shape}')\n",
    "\n",
    "# T.manual_seed(seed)\n",
    "# T.cuda.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# gym.utils.seeding.np_random.seed = seed\n",
    "\n",
    "# Build policy model\n",
    "# dense_layers = [(64,\"tanh\",{\"default\":{}}),(64,\"tanh\",{\"default\":{}})]\n",
    "layer_config = [\n",
    "    # {'type': 'cnn', 'params': {'out_channels': 32, 'kernel_size': (8, 8), 'stride': 4, 'padding': 0}},\n",
    "    # {'type': 'cnn', 'params': {'out_channels': 64, 'kernel_size': (4, 4), 'stride': 2, 'padding': 0}},\n",
    "    # {'type': 'cnn', 'params': {'out_channels': 64, 'kernel_size': (3, 3), 'stride': 1, 'padding': 0}},\n",
    "    # {'type': 'flatten'},\n",
    "    {'type': 'dense', 'params': {'units': 128, 'kernel': 'default', 'kernel params':{}}},\n",
    "    {'type': 'tanh'},\n",
    "    {'type': 'dense', 'params': {'units': 64, 'kernel': 'default', 'kernel params':{}}},\n",
    "    {'type': 'tanh'},\n",
    "]\n",
    "output_layer_kernel = {'type': 'dense', 'params': {'kernel': 'default', 'kernel params':{}}},\n",
    "policy = StochasticContinuousPolicy(env, layer_config, output_layer_kernel, learning_rate=policy_lr, distribution=distribution, device=device)\n",
    "# dense_layers = [(64,\"tanh\",{\"default\":{}}),(64,\"tanh\",{\"default\":{}})]\n",
    "value_function = ValueModel(env, layer_config, output_layer_kernel, learning_rate=value_lr, device=device)\n",
    "ppo = PPO(env, policy, value_function, distribution=distribution, discount=0.99, gae_coefficient=0.95, policy_clip=policy_clip, entropy_coefficient=entropy_coeff,\n",
    "          loss=loss, kl_coefficient=kl_coeff, normalize_advantages=normalize_advantages, normalize_values=normalize_values, value_normalizer_clip=norm_clip, policy_grad_clip=grad_clip,\n",
    "          reward_clip=reward_clip, lambda_=lambda_, callbacks=callbacks, save_dir=save_dir,device=device)\n",
    "hybrid_train_info_2 = ppo.train(timesteps=timesteps, trajectory_length=trajectory_length, batch_size=batch_size, learning_epochs=learning_epochs, num_envs=num_envs, seed=seed, render_freq=render_freq)\n",
    "# ppo.test(10,\"ppo_test\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = '/workspaces/RL_Agents/src/app/pong_v5_3/ppo/config.json'\n",
    "with open(config_file_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['wrappers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong = PPO.load(config, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.env.env = pong.env._initialize_env(num_envs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 2\n",
    "action_shape = (3,1)\n",
    "obs_shape = (3,)\n",
    "\n",
    "observation_space = gym.spaces.Box(low=0, high=1, shape=(num_envs, *obs_shape))\n",
    "action_space = gym.spaces.Box(low=0, high=1, shape=(num_envs, *action_shape)) if len(action_shape) > 1 else gym.spaces.MultiDiscrete([action_shape[0] for n in range(num_envs)])\n",
    "single_observation_space = gym.spaces.Box(low=0, high=1, shape=obs_shape)\n",
    "single_action_space = gym.spaces.Box(low=0, high=1, shape=action_shape) if len(action_shape) > 1 else gym.spaces.Discrete(action_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_obs = T.tensor(single_observation_space.sample())\n",
    "state, info = (T.stack([single_obs for _ in range(observation_space.shape[0])]), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = T.stack([single_obs for _ in range(observation_space.shape[0])])\n",
    "reward = T.zeros(observation_space.shape[0])\n",
    "terminated = T.zeros(observation_space.shape[0], dtype=T.bool)\n",
    "truncated = T.zeros(observation_space.shape[0], dtype=T.bool)\n",
    "info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = gym.make_vec(\"LunarLanderContinuous-v3\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.ones(vec_env.single_action_space.shape).dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "num_envs = 2\n",
    "expected_mu = T.stack([T.tensor([1.65, 1.65, 1.65]) for t in range(num_envs)])\n",
    "expected_sigma = T.stack([T.tensor([3.9, 3.9, 3.9]) for t in range(num_envs)])\n",
    "expected_dist = Normal(expected_mu, expected_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_dist.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.train(2000000, 128, 32, 3, 12, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[1] = 1\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium.wrappers as base_wrappers\n",
    "\n",
    "WRAPPER_REGISTRY = {\n",
    "    \"AtariPreprocessing\": {\n",
    "        \"cls\": base_wrappers.AtariPreprocessing,\n",
    "        \"default_params\": {\n",
    "            \"frame_skip\": 1,\n",
    "            \"grayscale_obs\": True,\n",
    "            \"scale_obs\": True\n",
    "        }\n",
    "    },\n",
    "    \"TimeLimit\": {\n",
    "        \"cls\": base_wrappers.TimeLimit,\n",
    "        \"default_params\": {\n",
    "            \"max_episode_steps\": 1000\n",
    "        }\n",
    "    },\n",
    "    \"TimeAwareObservation\": {\n",
    "        \"cls\": base_wrappers.TimeAwareObservation,\n",
    "        \"default_params\": {\n",
    "            \"flatten\": False,\n",
    "            \"normalize_time\": False\n",
    "        }\n",
    "    },\n",
    "    \"FrameStackObservation\": {\n",
    "        \"cls\": base_wrappers.FrameStackObservation,\n",
    "        \"default_params\": {\n",
    "            \"stack_size\": 4\n",
    "        }\n",
    "    },\n",
    "    \"ResizeObservation\": {\n",
    "        \"cls\": base_wrappers.ResizeObservation,\n",
    "        \"default_params\": {\n",
    "            \"shape\": 84\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrappers = [\n",
    "    {'type': \"AtariPreprocessing\", 'params': {'frame_skip':1, 'grayscale_obs':True, 'scale_obs':True}},\n",
    "    {'type': \"FrameStackObservation\", 'params': {'stack_size':4}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_env(vec_env, wrappers):\n",
    "    wrapper_list = []\n",
    "    for wrapper in wrappers:\n",
    "        if wrapper['type'] in WRAPPER_REGISTRY:\n",
    "            print(f'wrapper type:{wrapper[\"type\"]}')\n",
    "            # Use a copy of default_params to avoid modifying the registry\n",
    "            default_params = WRAPPER_REGISTRY[wrapper['type']][\"default_params\"].copy()\n",
    "            \n",
    "            if wrapper['type'] == \"ResizeObservation\":\n",
    "                # Ensure shape is a tuple for ResizeObservation\n",
    "                default_params['shape'] = (default_params['shape'], default_params['shape']) if isinstance(default_params['shape'], int) else default_params['shape']\n",
    "            \n",
    "            print(f'default params:{default_params}')\n",
    "            override_params = wrapper.get(\"params\", {})\n",
    "            \n",
    "            if wrapper['type'] == \"ResizeObservation\":\n",
    "                # Ensure override_params shape is a tuple\n",
    "                if 'shape' in override_params:\n",
    "                    override_params['shape'] = (override_params['shape'], override_params['shape']) if isinstance(override_params['shape'], int) else override_params['shape']\n",
    "            \n",
    "            print(f'override params:{override_params}')\n",
    "            final_params = {**default_params, **override_params}\n",
    "            print(f'final params:{final_params}')\n",
    "            \n",
    "            def wrapper_factory(env, cls=WRAPPER_REGISTRY[wrapper['type']][\"cls\"], params=final_params):\n",
    "                return cls(env, **params)\n",
    "            \n",
    "            wrapper_list.append(wrapper_factory)\n",
    "    \n",
    "    # Define apply_wrappers outside the loop\n",
    "    def apply_wrappers(env):\n",
    "        for wrapper in wrapper_list:\n",
    "            env = wrapper(env)\n",
    "            print(f'length of obs space:{len(env.observation_space.shape)}')\n",
    "            print(f'env obs space shape:{env.observation_space.shape}')\n",
    "        return env\n",
    "    \n",
    "    print(f'wrapper list:{wrapper_list}')\n",
    "    envs = [lambda: apply_wrappers(gym.make(vec_env.spec.id, render_mode=\"rgb_array\")) for _ in range(vec_env.num_envs)]    \n",
    "    return SyncVectorEnv(envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = gym.make_vec(\"ALE/Pong-v5\", render_mode=\"rgb_array\", num_envs=8)\n",
    "wrapped_vec = wrap_env(vec_env, wrappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_vec.single_observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in wrapped_vec.envs:\n",
    "    print(env.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_wrappers(wrapper_store):\n",
    "    wrappers_dict = {}\n",
    "    for key, value in wrapper_store.items():\n",
    "        # Split the key into wrapper type and parameter name\n",
    "        parts = key.split('_param:')\n",
    "        print(f'parts:{parts}')\n",
    "        wrapper_type = parts[0].split('wrapper:')[1]\n",
    "        print(f'wrapper_type:{wrapper_type}')\n",
    "        param_name = parts[1]\n",
    "        print(f'param name:{param_name}')\n",
    "        \n",
    "        # If the wrapper type already exists in the dictionary, append to its params\n",
    "        if wrapper_type not in wrappers_dict:\n",
    "            wrappers_dict[wrapper_type] = {'type': wrapper_type, 'params': {}}\n",
    "        \n",
    "        wrappers_dict[wrapper_type]['params'][param_name] = value\n",
    "    \n",
    "    # Convert the dictionary to a list of dictionaries\n",
    "    formatted_wrappers = list(wrappers_dict.values())\n",
    "    \n",
    "    return formatted_wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_params = {'wrapper:AtariPreprocessing_param:frame_skip': 1, 'wrapper:AtariPreprocessing_param:grayscale_obs': True, 'wrapper:AtariPreprocessing_param:scale_obs': True, 'wrapper:FrameStackObservation_param:stack_size': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_wrappers = format_wrappers(wrapper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_params = {'wrapper:AtariPreprocessing_param:frame_skip': 1, 'wrapper:AtariPreprocessing_param:grayscale_obs': True, 'wrapper:AtariPreprocessing_param:scale_obs': True, 'wrapper:FrameStackObservation_param:stack_size': 4}\n",
    "formatted_wrappers = dash_utils.format_wrappers(wrapper_params)\n",
    "#DEBUG\n",
    "print(f'formatted wrappers:{formatted_wrappers}')\n",
    "env = dash_utils.instantiate_envwrapper_obj(\"gymnasium\", \"ALE/Pong-v5\", formatted_wrappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = '/workspaces/RL_Agents/src/app/humanoid_v5_2/ppo/config.json'\n",
    "with open(config_file_path, 'r') as file:\n",
    "    config = json.load(file)\n",
    "ppo = PPO.load(config, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo.env.env = ppo.env._initialize_env(0, 8, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in ppo.env.env.envs:\n",
    "    print(env.spec.pprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo.callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo.train(2_000_000, 128, 64, 10, 8, 42, render_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states, _ = ppo.env.reset()\n",
    "steps = 10\n",
    "all_states = []\n",
    "all_next_states = []\n",
    "for step in range(steps):\n",
    "    actions, log_probs = ppo.get_action(states)\n",
    "    next_states, rewards, terms, truncs, infos = ppo.env.step(actions)\n",
    "    all_states.append(states)\n",
    "    all_next_states.append(next_states)\n",
    "    states = next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, step_states in enumerate(all_states):\n",
    "    print(f'step states shape:{step_states.shape}')\n",
    "    for i in range(len(step_states)):\n",
    "        for j in range(i + 1, len(step_states)):  # Compare each environment with others\n",
    "            print(f'step state {i} shape:{step_states[i].shape}')\n",
    "            print(f'step state {j} shape:{step_states[j].shape}')\n",
    "            assert np.allclose(step_states[i], step_states[j]), f\"Environments {i} and {j} differ at step {step}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_states)):\n",
    "    for j in range(i + 1, len(all_states)):  # Note the change here\n",
    "        print(np.allclose(all_states[i], all_states[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = []\n",
    "obs = np.ones((8,1,84,84))\n",
    "for _ in range(10):\n",
    "    all_obs.append(obs)\n",
    "# all_obs = np.array(all_obs)\n",
    "all_obs = T.stack([T.tensor(s, dtype=T.float32) for s in all_obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = gym.spaces.Box(low=0, high=1, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_advantages = []\n",
    "all_returns = []\n",
    "all_values = []\n",
    "advantage = T.ones(128)\n",
    "return_ = T.ones(128)\n",
    "value = T.ones(128)\n",
    "num_envs = 2\n",
    "\n",
    "for _ in range(num_envs):\n",
    "    all_advantages.append(advantage)\n",
    "    all_returns.append(return_)\n",
    "    all_values.append(value)\n",
    "\n",
    "advantages = T.stack(all_advantages, dim=1)\n",
    "returns = T.stack(all_returns, dim=1)\n",
    "values = T.stack(all_values, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, _ = pong.env.reset()\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns, r, term, trunc, _ = pong.env.step(pong.env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.env.single_observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.env.env.envs[0].spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, _ = pong.env.reset()\n",
    "states = T.tensor(states)\n",
    "dist, _ = pong.policy_model(states)\n",
    "sample = dist.sample()\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.policy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_reward(reward):\n",
    "    \"\"\"\n",
    "    Clip rewards to the specified range.\n",
    "\n",
    "    Args:\n",
    "        reward (float): Reward to clip.\n",
    "\n",
    "    Returns:\n",
    "        float: Clipped reward.\n",
    "    \"\"\"\n",
    "    if reward > 1:\n",
    "        return 1\n",
    "    elif reward < -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make_vec(\"ALE/Pong-v5\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "all_dones = []\n",
    "for _ in range(10):\n",
    "    next_states, rewards, terms, truncs, infos = env.step(env.action_space.sample())\n",
    "    all_rewards.append(rewards)\n",
    "    all_dones.append(np.logical_or(terms, truncs))\n",
    "rewards = T.stack([T.tensor(r, dtype=T.float32) for r in all_rewards])\n",
    "dones = T.stack([T.tensor(d, dtype=T.float32) for d in all_dones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[clip_reward(reward) for reward in rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlk9JREFUeJzs3Xd4FFUXx/HvphcIvfdepEqT3kMXKYLSqyIKIipFQKoi+CLYAFG6NEGKVAm9dxDpSm+RTmgpJPP+MWYlpJBAkkn5fZ5nHzKzd3fO7t1d9uy9c67NMAwDERERERERiZSD1QGIiIiIiIgkdEqcREREREREnkGJk4iIiIiIyDMocRIREREREXkGJU4iIiIiIiLPoMRJRERERETkGZQ4iYiIiIiIPIMSJxERERERkWdQ4iQiIiIiIvIMSpxEJFYcPnyYzp07kydPHtzc3EiRIgUvv/wyY8eO5datW3FyzNy5c9OpU6c4ue/o+vPPP7HZbDg7O3P16lVLY3kRmzZtwmazsWnTJvu+YcOGYbPZrAsK2Lp1K61atSJbtmy4uLiQKlUqKlWqxKRJk3jw4IGlsT2vgwcPUr16dVKlSoXNZmPChAlxejybzYbNZuOLL74Id92MGTOw2Wzs27cvxvcbettz587FQpQxM2LECIoWLUpISEi0b3Ps2DGGDRsWo3hr1KhBjRo1ntkuovdPbBsyZAgvv/xyjB6ziMQuJU4i8sJ+/PFHypQpw969e/n4449Zs2YNS5Ys4fXXX2fy5Ml07do1To67ZMkShgwZEif3HV0//fQTAI8fP2bWrFmWxhLbunXrxs6dOy07/tChQ6lWrRqXL19m5MiR+Pj4MH/+fGrXrs2wYcMYPHiwZbG9iC5dunD16lXmz5/Pzp07eeONN+LluF988UWs/ojRqFEjdu7cSZYsWWLtPqPjypUrjB07lhEjRuDgEP2vMceOHWP48OGWJHqx4aOPPuLs2bPMnDnT6lBEki0nqwMQkcRt586dvPPOO9StW5elS5fi6upqv65u3bp8+OGHrFmzJk6OXbp06Ti53+gKCAhgzpw5lCxZkhs3bjBt2jT69+9vaUyxKXv27GTPnt2SYy9cuJARI0bQtWtXfvzxxzAjXw0aNKBfv36xltQ9fPgQDw+PWLmv6Dhy5Ajdu3enQYMGsXJ/QUFB2Gw2nJwi/y+9Tp06bNq0ic8++4xx48bFynEzZMhAhgwZYuW+YuLrr78mderUNG/ePN6PbaVUqVLRrl07vvjiCzp16mT5aLBIcqQRJxF5IZ9//jk2m40pU6aESZpCubi48Oqrr9q3Q0JCGDt2LIULF8bV1ZWMGTPSoUMHLl26FOZ2Bw8epHHjxmTMmBFXV1eyZs1Ko0aNwrR7eqpe6HSZefPmMWjQILJmzYqXlxd16tTh5MmT4WJbt24dtWvXxsvLCw8PDypXrsz69euj/diXLl3KzZs36datGx07duTUqVNs27YtXLvcuXPTuHFj1qxZw8svv4y7uzuFCxdm2rRpYdqFTn3auHEj77zzDunTpyddunQ0b96cK1euhLvfBQsWULFiRTw9PUmRIgX16tXj4MGDYdrs27ePN954g9y5c+Pu7k7u3Ll58803OX/+/DMfX0RT9aL7WAC2bdtGxYoVcXNzI1u2bAwZMoSffvopWtO7RowYQZo0afjmm28i/IKYMmVKvL29ATh37hw2m40ZM2aEa2ez2Rg2bFi4x3TgwAFatmxJmjRpyJcvHxMmTMBms/H333+Hu4/+/fvj4uLCjRs37Pue57UT2r+PHz9m0qRJ9il0oY4cOULTpk1JkyYNbm5ulCpVKtzoQuhrfPbs2Xz44Ydky5YNV1fXCON+UqFChejatSvff/99tPr+t99+o2LFinh4eJAyZUrq1q0bLlGNaKpedN63hmEwceJESpUqhbu7O2nSpKFly5acOXPmmXEFBgYydepU2rRpE260adKkSZQsWZIUKVKQMmVKChcuzCeffGKP9fXXXwegZs2a9uc+9DVjGAZjx44lV65cuLm58fLLL7N69eoIYzhx4gT169fHw8OD9OnT06NHD+7duxdh22e9TpYuXYrNZovwtRP6Gjl8+LB9X/v27Tl16hQbN2585nMlIrFPiZOIPLfg4GA2bNhAmTJlyJEjR7Ru884779C/f3/q1q3Lb7/9xsiRI1mzZg2VKlWyfzF98OABdevW5Z9//uH777/Hx8eHCRMmkDNnzki/oDzpk08+4fz58/z0009MmTKFv/76iyZNmhAcHGxv8/PPP+Pt7Y2XlxczZ87kl19+IW3atNSrVy/aydPUqVNxdXWlbdu2dOnSBZvNxtSpUyNs+8cff/Dhhx/ywQcfsGzZMkqUKEHXrl3ZsmVLuLbdunXD2dmZuXPnMnbsWDZt2kS7du3CtPn888958803KVq0KL/88guzZ8/m3r17VK1alWPHjtnbnTt3jkKFCjFhwgR+//13xowZw9WrVylXrlyYRCAmovNYDh8+TN26dXn48CEzZ85k8uTJHDhwgM8+++yZ93/16lWOHDmCt7d3nI0ENW/enPz587Nw4UImT55Mu3btcHFxCZd8BQcH8/PPP9OkSRPSp08PPP9rJ3RqG0DLli3ZuXOnffvkyZNUqlSJo0eP8s0337B48WKKFi1Kp06dGDt2bLj7GjhwIBcuXGDy5MksX76cjBkzPvMxDxs2DEdHx2dOb507dy5NmzbFy8uLefPmMXXqVG7fvk2NGjUi/GEgVHTft2+//TZ9+vShTp06LF26lIkTJ3L06FEqVarEP//8E2Vsu3fv5ubNm9SsWTPM/vnz59OzZ0+qV6/OkiVLWLp0KR988IH9PLhGjRrx+eefA/D999/bn/tGjRoBMHz4cPvn0tKlS3nnnXfo3r17uB9c/vnnH6pXr86RI0eYOHEis2fP5v79+7z33nvhYo3O6yQ0yZw+fXq428+YMYOXX36ZEiVK2PeVKVOGFClSsHLlyiifJxGJI4aIyHPy9fU1AOONN96IVvvjx48bgNGzZ88w+3fv3m0AxieffGIYhmHs27fPAIylS5dGeX+5cuUyOnbsaN/euHGjARgNGzYM0+6XX34xAGPnzp2GYRjGgwcPjLRp0xpNmjQJ0y44ONgoWbKkUb58+Wc+lnPnzhkODg5hHnv16tUNT09Pw8/PL1ycbm5uxvnz5+37Hj16ZKRNm9Z4++237fumT58e4fMzduxYAzCuXr1qGIZhXLhwwXBycjJ69eoVpt29e/eMzJkzG61atYo07sePHxv37983PD09ja+//tq+P/S527hxo33f0KFDjaf/m4juY3n99dcNT09P4/r16/Z9wcHBRtGiRQ3AOHv2bKQx7tq1ywCMAQMGRNrmSWfPnjUAY/r06eGuA4yhQ4eGe0yffvppuLbNmzc3smfPbgQHB9v3rVq1ygCM5cuXG4YRO68dwHj33XfD7HvjjTcMV1dX48KFC2H2N2jQwPDw8DDu3LljGMZ//VStWrVnHiei4w0aNMhwcHAw/vjjD8Mw/nvN7d271/44smbNahQvXjzM83Dv3j0jY8aMRqVKlez7Qm8b2pfRed/u3LnTAIxx48aF2X/x4kXD3d3d6NevX5SPZcyYMQZg+Pr6htn/3nvvGalTp47ytgsXLgz3GjcMw7h9+7bh5uZmNGvWLMz+7du3G4BRvXp1+77+/fsbNpvNOHToUJi2devWDXPfMXmd9O3b13B3d7f3sWEYxrFjxwzA+Pbbb8M9jsqVKxsVKlSI8rGKSNzQiJOIxJvQ6SVPV8IrX748RYoUsf8Kmz9/ftKkSUP//v2ZPHlymBGU6HhyaiBg/8U2dIrSjh07uHXrFh07duTx48f2S0hICPXr12fv3r3PrNg2ffp0QkJC6NKli31fly5dePDgAQsWLAjXvlSpUuTMmdO+7ebmRsGCBSOcNvWs+H///XceP35Mhw4dwsTv5uZG9erVw1T2un//Pv379yd//vw4OTnh5OREihQpePDgAcePH4/yMUYmOo9l8+bN1KpVyz5KA+Dg4ECrVq2e65ixrUWLFuH2de7cmUuXLrFu3Tr7vunTp5M5c2b7+Uix8dqJyIYNG6hdu3a4kdtOnTrx8OHDcNPkIoo/Ovr160fatGkjPRfv5MmTXLlyhfbt24eZCpciRQpatGjBrl27ePjwYYS3jc77dsWKFdhsNtq1axfm+cucOTMlS5Z8ZlW6K1euYLPZwryuwPwMuXPnDm+++SbLli2L0Wjqzp078ff3p23btmH2V6pUiVy5coXZt3HjRl566SVKliwZZn+bNm3CbMfkddKlSxcePXoU5nNj+vTpuLq6hrtfgIwZM3L58uVoPz4RiT1KnETkuaVPnx4PDw/Onj0brfY3b94EiLAKV9asWe3Xp0qVis2bN1OqVCk++eQTXnrpJbJmzcrQoUMJCgp65nHSpUsXZjv03KtHjx4B2KcDtWzZEmdn5zCXMWPGYBhGlNXHQkJCmDFjBlmzZqVMmTLcuXOHO3fuUKdOHTw9PSOcrvd0TKFxhcb0PPGXK1cuXPwLFiwI86WxTZs2fPfdd3Tr1o3ff/+dPXv2sHfvXjJkyBDhsaMjOo/l5s2bZMqUKVy7iPY9LTQpi+7r6nlE9Bps0KABWbJksU+bun37Nr/99hsdOnTA0dERePHXTmRu3rwZ6fsi9PpnxR8dXl5eDB48mDVr1kR4nsyz3qMhISHcvn07wvuOzvv2n3/+wTAMMmXKFO7527Vr1zMTnkePHuHs7Gzvj1Dt27dn2rRpnD9/nhYtWpAxY0YqVKiAj4/PM5+T0MecOXPmcNc9ve/mzZvRaheT18lLL71EuXLl7K+70OmhTZs2JW3atOGO5ebm9tzvXRF5MaqqJyLPzdHRkdq1a7N69WouXbr0zApsoV+4r169Gq7tlStXwvyKXLx4cebPn49hGBw+fJgZM2YwYsQI3N3dGTBgwAvFHXqcb7/9lldeeSXCNlF9wV+3bp19dCWiJGLXrl0cO3aMokWLvlCckQmNf9GiReF+EX/S3bt3WbFiBUOHDg3znAUEBMTZ2lqh0qVLF+H5Kr6+vs+8bZYsWShevDhr166NVsU7Nzc3wHxcT3o62XhSRAUnHB0dad++Pd988w137txh7ty5BAQE0LlzZ3ubF33tRCZdunQRrgMWWhTk6RGWF6mo9s477/D111/Tv39/3nnnnXBxAJHG4uDgQJo0aSK972e9b9OnT4/NZmPr1q0RFpOJaN+T0qdPT2BgIA8ePMDT0zPMdZ07d6Zz5848ePCALVu2MHToUBo3bsypU6eifJ+EPuaIXpu+vr7kzp07TNvI2j0dJ0T/ddK5c2d69uzJ8ePHOXPmDFevXg3zunvSrVu3wr0eRCR+aMRJRF7IwIEDMQyD7t27ExgYGO76oKAgli9fDkCtWrUA86TpJ+3du5fjx49Tu3btcLe32WyULFmS8ePHkzp1ag4cOPDCMVeuXJnUqVNz7NgxypYtG+HFxcUl0ttPnToVBwcHli5dysaNG8NcZs+eDRBhlbnYUq9ePZycnDh9+nSk8YP53BmGEe7L6E8//RSmUEZcqF69Ohs2bAgzghASEsLChQujdfshQ4Zw+/ZtevfujWEY4a6/f/8+a9euBcwvoG5ubmGqjwEsW7YsxnF37twZf39/5s2bx4wZM6hYsSKFCxe2X/+ir53I1K5dmw0bNoSrnjhr1iw8PDwi/fL9PFxcXBg1ahR79+4N1x+FChUiW7ZszJ07N8zz/uDBA3799Vd7pb1niex927hxYwzD4PLlyxE+d8WLF4/yfkP74vTp05G28fT0pEGDBgwaNIjAwECOHj0KhB+5DfXKK6/g5ubGnDlzwuzfsWNHuKm0NWvW5OjRo/zxxx9h9s+dOzfMdkxfJ2+++SZubm7MmDGDGTNmkC1bNnvVyKedOXMmzn6UEZGoacRJRF5IxYoVmTRpEj179qRMmTK88847vPTSSwQFBXHw4EGmTJlCsWLFaNKkCYUKFeKtt97i22+/xcHBgQYNGnDu3DmGDBlCjhw5+OCDDwDzPIiJEyfy2muvkTdvXgzDYPHixdy5c4e6deu+cMwpUqTg22+/pWPHjty6dYuWLVuSMWNGrl+/zh9//MH169eZNGlShLe9efMmy5Yto169ejRt2jTCNuPHj2fWrFmMHj0aZ2fnF473ablz52bEiBEMGjSIM2fOUL9+fdKkScM///zDnj178PT0ZPjw4Xh5eVGtWjW+/PJL0qdPT+7cudm8eTNTp04lderUsR7XkwYNGsTy5cupXbs2gwYNwt3dncmTJ9vP63jWwqWvv/46Q4YMYeTIkZw4cYKuXbuSL18+Hj58yO7du/nhhx9o3bo13t7e9nNmpk2bRr58+ShZsiR79uwJ92U2OgoXLkzFihUZPXo0Fy9eZMqUKWGuf5HXTlSGDh3KihUrqFmzJp9++ilp06Zlzpw5rFy5krFjx5IqVaoY32dU3nzzTf73v/+FK7nt4ODA2LFjadu2LY0bN+btt98mICCAL7/8kjt37vDFF19Eep/Red9WrlyZt956i86dO7Nv3z6qVauGp6cnV69eZdu2bRQvXjzcKNiTatSoAZijuk9Wm+vevTvu7u5UrlyZLFmy4Ovry+jRo0mVKhXlypUDoFixYgBMmTKFlClT4ubmRp48eUiXLh0fffQRo0aNolu3brz++utcvHiRYcOGhZuC16dPH6ZNm0ajRo0YNWoUmTJlYs6cOZw4cSJMu5i+TlKnTk2zZs2YMWMGd+7c4aOPPorwPXLz5k3++usvevXqFelzJCJxyJKSFCKS5Bw6dMjo2LGjkTNnTsPFxcXw9PQ0SpcubXz66afGtWvX7O2Cg4ONMWPGGAULFjScnZ2N9OnTG+3atTMuXrxob3PixAnjzTffNPLly2e4u7sbqVKlMsqXL2/MmDEjzDEjq6q3cOHCMO0iq7q2efNmo1GjRkbatGkNZ2dnI1u2bEajRo3C3f5JEyZMeGblsMmTJxuA8euvv9rjbNSoUbh21atXD1Ox6+kKZ08/rqergS1dutSoWbOm4eXlZbi6uhq5cuUyWrZsaaxbt87e5tKlS0aLFi2MNGnSGClTpjTq169vHDlyJNLnLjpV9aLzWAzDMLZu3WpUqFDBcHV1NTJnzmx8/PHH9qpoT1YQi8rmzZuNli1bGlmyZDGcnZ0NLy8vo2LFisaXX34Zpnrh3bt3jW7duhmZMmUyPD09jSZNmhjnzp2LtKrek9X+njZlyhQDMNzd3Y27d+9GGldMXzuhiKCqnmEYxp9//mk0adLESJUqleHi4mKULFky3Gs2stf48xxv7dq1BhDha27p0qVGhQoVDDc3N8PT09OoXbu2sX379jBtnq6qF933rWEYxrRp04wKFSoYnp6ehru7u5EvXz6jQ4cOxr59+575eKpWrRqucubMmTONmjVrGpkyZTJcXFyMrFmzGq1atTIOHz4cpt2ECROMPHnyGI6OjmE+E0JCQozRo0cbOXLkMFxcXIwSJUoYy5cvj/B1fezYMaNu3bqGm5ubkTZtWqNr167GsmXLInyPxuR18mR/nDp1KsLHPnXqVMPZ2TlcVUERiR82w4hgDoSIiEgc8Pb25ty5c5w6dcrqUCSR+vXXX2ndujXnz58nW7ZsVocTr6pWrUrOnDnDTSsUkfihxElEROJE3759KV26NDly5ODWrVvMmTOHxYsXM3Xq1DBl3EViwjAMKlWqRJkyZfjuu++sDifebNmyBW9vb44dO0bevHmtDkckWdI5TiIiEieCg4P59NNP8fX1xWazUbRoUWbPnk27du2sDk0SMZvNxo8//shvv/1GSEjIM8+XSypu3rzJrFmzlDSJWEgjTiIiIiIiIs+QPH6mEREREREReQFKnERERERERJ5BiZOIiIiIiMgzJLviECEhIVy5coWUKVNis9msDkdERERERCxiGAb37t0ja9aszyw2k+wSpytXrpAjRw6rwxARERERkQTi4sWLZM+ePco2yS5xSpkyJWA+OV5eXhZHA0FBQaxduxZvb2+cnZ2tDkdigfo06VGfJk3q16RHfZo0qV+TnoTUp35+fuTIkcOeI0Ql2SVOodPzvLy8Ekzi5OHhgZeXl+UvHIkd6tOkR32aNKlfkx71adKkfk16EmKfRucUHhWHEBEREREReQYlTiIiIiIiIs+gxElEREREROQZlDiJiIiIiIg8gxInERERERGRZ1DiJCIiIiIi8gxKnERERERERJ5BiZOIiIiIiMgzKHESERERERF5BiVOIiIiIiIiz6DESURERERE5BmUOImIiIiIiDyDEicREREREZFnUOIkIiIiIiLyDJYmTlu2bKFJkyZkzZoVm83G0qVLn3mbzZs3U6ZMGdzc3MibNy+TJ0+O+0BFRERERCRZszRxevDgASVLluS7776LVvuzZ8/SsGFDqlatysGDB/nkk0/o3bs3v/76axxHKiIiIiIiyZmTlQdv0KABDRo0iHb7yZMnkzNnTiZMmABAkSJF2LdvH//73/9o0aJFzA7+4AE4Oobf7+gIbm5h20XGwQHc3Z+v7cOHnDltcODAY/78MxUOjx7i5uaEoyM4OdtwSOGBk5N5kxQOD0nhaeDhAR4eT4Vts5k7Qz16BCEhkcfh6fl8bf39ITg4dtp6eJhxAwQEwOPHsdPW3d18ngECAyEoKHbaurn996RHp22ooCCzfWRcXcHJKeZtHz82n4vIuLiAs3PM2wYHm30XGWdns31M24aEmK+12Gjr5GQ+FwCGAQ8fxk7bZ73vg4Jw9Pc397u5xdtnBIYRcdun3/cxaavPCPPvwEB4+PC/fg19H0TWNjY/I0Lb6jPC/Ds2PyOefB/E52fE87bVZ0T02j75GezsnPS/RySTz4hIP3+fbhvX3yOiet89zUggAGPJkiVRtqlatarRu3fvMPsWL15sODk5GYGBgRHext/f37h79679cvHiRQMw7ppPV7hLcIMGRmBgoP0S4uERYTsDjOBq1cK2TZ8+8rZlyoRtmytXpG2PUDTMriMUjbTtZZdcRoMGwUbbtsFGr16PjUtZy0baNiR9+jAxBFerFnlbD4+wbRs0iLStAWHbNm8eddvbt/9r27591G0vX7a3fdyjR9RtT536r23fvlG3PXjwv7aDB0fZNmjHjv/ajh4ddVsfH+PBgwfG0qVLjYCvvoq67dKl9vsN+umnqNvOnftf27lzo27700//tV26NMq2j7/++r+2Pj5Rtx09+r+2O3ZE3Xbw4P9eEwcPRt22b9//2p46FXXbHj3+a3v5cpRtg9u3/6/t7dtRt23ePMxrOMq2CeAzIqRIkbBtixSJvG2uXGHfn2XKRN5WnxH/tY3Dzwh726+/jrqtPiPMtjH4jAh86y1j6dKlxoMHD/QZoc8Is60+I8y2Cewz4tGWLVG3jcfvEXfBAIy7d+8+M1+xdMQppnx9fcmUKVOYfZkyZeLx48fcuHGDLFmyhLvN6NGjGT58eLSPce3aNXavWmXfbhQcHOmw3K2bN9n+RNv6gYG4RtL27t27bHmibd2HD/GIpK2TUwhZM94nONhGYKAjtjuYXRqBwEBYvfq/GZftgWyRxXvLoH6lm2TI8IhMmR4w5Ox98kbSNjg4mFVPxFvh2jUyR9IWCNO2rK9vpDEA/P777wT/+2tc6UuXyBlF23Xr1hGYKhUAJc6fJ08UbTdu3Mijf18fRc+coUAUbbdu3cq98+cBKPTXXxSOou327du5c+0aAPlPnOClKNru2rWLm//+cnHixAlKRNF23759/PPv3zn++IOXo2h78OBBrvz7i2DWgwcpF0Xbw3/8wcV/+yPTvn28EkXbo0ePcvbftun+/JMqUbQ9ceIEf//bNvVff1E9irZ//fUXJ/9tm/LCBWpF0fbMmTMc+7et+z//4B1F2wvnz3P437Yud+8S1Xj1pUuXOPhvW0d/fxpH0faqry/7nngNN42ibUL4jLh3/z4bn2hb8/59vCJp++jhQ3yeaFvt7l3SRNI2MDCQNU+0rXzzJukjaavPiP8872dEnqNH9RlB7H5GXLp4EQAfHx99RugzAtBnRCh9Rphi8j0iIrZ/R3ssZ7PZWLJkCa+99lqkbQoWLEjnzp0ZOHCgfd/27dupUqUKV69eJXPm8G/JgIAAAp4YYvTz8yNHjhzcOH8eL68IPkbieYg9KCiIDRs2UKtWLZxDhyojGGI3Qgz8/c2b3b9vHurOHRu3btu48dCDmzdt3LwJ9675c+tGCNeuga+vjatX4XGw7b+74r+hcDce4YA5xJ42jUGuXAb58kHBgoZ5Ke1B/vz/jn4mxmk4Fg2xB4WE4OPjQ90aNXCO6u2VyIfYk9NUvTDvU03Vi7htIvyMCHr4MPznbyRtNQ2HRPEZEWQY+GzZQt26dXF2ctJUvedpmwA/I8J9V0ri3yOSw2dEkL8/G1ativjz96m2cf09ws/Pj/S5cnH37t2Ic4Mnbx7ltQlM5syZ8fX1DbPv2rVrODk5kS5dughv4+rqiqtr+N9vnFOnxvkZTw4AqVNHP8CYtP331w+Cggh2czPjieiF80RbF4j0F6P/eIbZCgmBGzfgyhW4fNm8nD8PZ87AmTPunD0L16/Dw9tw6TZsPxT23hwdIX9+KFLEmeLFoXRp85Ir13+fQ+FE9jiSS9t/PxCdPTwi79OI7tcjst8OI2j75H+esdn2yf/sY6st/PchFdttQz8oY7vt0+/lqN6ncf0ZEdttE8v7KD7aurg8+/M3rmOIyftenxHPbhv6+evsbPZpfH1GWNE2OX1GRPUZnBDjjc22SfUzAqL3+RsqDr9HODs4PLvdvxJV4lSxYkWWL18eZt/atWspW7Zs9L+gJjMODpAxo3kpVSriNvfuwdmzZjJ18iQcPw7Hjpn/3r9v7jt5Ep6sFp8mjXl/oYlU6dJQuHDE9TZERERERBI7SxOn+/fv8/fff9u3z549y6FDh0ibNi05c+Zk4MCBXL58mVmzZgHQo0cPvvvuO/r27Uv37t3ZuXMnU6dOZd68eVY9hCQhZUooUcK8PMkwzBGqY8fMy+HDcPAgHD0Kt2/Dxo3m5cn7KV8eKlY0L6+8AmnTxu9jERERERGJC5YmTvv27aNmzZr27b59+wLQsWNHZsyYwdWrV7lw4YL9+jx58rBq1So++OADvv/+e7Jmzco333wT81LkEi02G2TPbl68nzjTLiDATKQOHvzvcuiQOXK1fr15CVWokJlEVaoE1atDgQJRTPETEREREUmgLE2catSoQVS1KWbMmBFuX/Xq1Tlw4EAcRiXP4ur63/S8UMHBcOQI7Nz53+Wvv/6b5hfaldmyQY0aULMm1KoFeaIqbyMiIiIikkAkqnOcJOFydISSJc1Ljx7mvhs3YNcuM4nats38+/JlmDPHvIBZZCI0ifL2hqeqzYuIiIiIJAhKnCTOpE8PjRubFzCrQ+7Y8d+5UXv2mBX+Zsz4b0SqTBlo0MC8VKigYhMiIiIikjAocZJ44+4OtWubFzAr9m3fbiZRa9ea50rt329eRo0yK/d5e/+XSGXMaG38IiIiIpJ8Rb9wuUgsS5EC6tWDL76AAwfg6lWYPh1atTKXsrh9GxYsgE6dIHNmqFoVvvrKLJ0uIiIiIhKflDhJgpE5s5kkLVhgLsq7bRsMGmQWoTAMc/vDDyFvXnMNqeHDzRLpUdQXERERERGJFUqcJEFycoLKlc0pewcOmOdCff21WZHPwQH++AOGDTOLUeTPD/37myXRlUSJiIiISFxQ4iSJQs6c0Lu3eT7UP/+YU/pefRXc3ODMGRg71hyZKlrUHIk6dcrqiEVEREQkKVHiJIlO+vTmlL5ly8yS5wsXQosW5vpSJ06YI1GFCsHLL8OXX8ITayiLiIiIiDwXJU6SqHl6QsuWsGgRXLsGM2eaFfgcHc0qff36mWtF1aoFs2bBgwdWRywiIiIiiZESJ0kyvLygQwdYtQp8fWHSJKheHWw2c4pfx45mAYquXWHrVp0PJSIiIiLRp8RJkqT06aFHD9i0ySxfPnIk5Mtnrh01bRpUqwYFCpjFJzSVT0RERESeRYmTJHm5csHgwfDXX7BlC3TpYq4hdfo0DBkCuXNDo0awfDkEB1sdrYiIiIgkREqcJNmw2cxFdKdONafyzZxpljc3DHN636uvQp48MGIEXL5sdbQiIiIikpAocZJkydPTPB9q40azdPlHH0G6dHDxIgwdao5SNW8Oa9dCSIjV0YqIiIiI1ZQ4SbJXoIBZtvzSJZgzxxyVCg6GJUugXj0oWBC++Qb8/KyOVERERESsosRJ5F9ubtCmjXke1JEj0KsXpEplngv1/vuQPTv06WNui4iIiEjyosRJJAIvvWSOMl2+DBMnQuHCcO8efP21OULVtCls2KCS5iIiIiLJhRInkSh4esI778DRo7B6NdSvbyZLv/0GtWtDyZIwfToEBlodqYiIiIjEJSVOItHg4GAmTatXw/HjZjLl4QF//mmWN8+bF8aNM0elRERERCTpUeIkEkOFC5vT9y5dgjFjIEsWc0rfRx9BzpwwZIgDd+64Wh2miIiIiMQiJU4izylNGujXD86ehZ9+gkKF4M4dGDPGke7d6/Luuw78/bfVUYqIiIhIbFDiJPKCXF2ha1c4dgwWL4by5UMICnLkxx8dKVQIWrWCw4etjlJEREREXoQSJ5FY4uAAzZrB1q3BfPbZNho0CCEkBBYuNItING8Ohw5ZHaWIiIiIPA8lTiKxzGaDl166ybJlwfzxhzniZLOZC+qWLm2WMt+/3+ooRURERCQmlDiJxKESJWDBAnNB3TffNBOo336DsmWhSRPYu9fqCEVEREQkOpQ4icSDokVh7lzzPKh27cxpfStWQPny0LChEigRERGRhE6Jk0g8KlwYZs8214Lq2BEcHc21ocqXN8+BOnrU6ghFREREJCJKnEQsULAgzJgBJ06YCZSDg3kOVPHi0KEDnDljdYQiIiIi8iQlTiIWyp/fTKD+/BNatADDMEekChWCnj3h6lWrIxQRERERUOIkkiAULQqLFpnnOtWrB48fw6RJkC8f9O8PN29aHaGIiIhI8qbESSQBKVsW1qyBTZugUiV49AjGjoW8eWHMGPD3tzpCERERkeRJiZNIAlS9OmzbZlbeK1kS/PxgwABzCt+cORASYnWEIiIiIsmLEieRBMpmg0aN4MABmDkTsmeHCxfMcublysHGjVZHKCIiIpJ8KHESSeAcHMxKe6dOweefQ8qUZjJVqxa8+qpZ2lxERERE4pYSJ5FEwt0dBg6Ev/82K+45OsLy5WYJ83fegWvXrI5QREREJOlS4iSSyGTMCN9/D0eOQNOmEBwMkydDgQLw1VcQGGh1hCIiIiJJjxInkUSqcGFYuhQ2b4aXXzYLSHz4IZQoYVbmExEREZHYo8RJJJGrVg327IEff4QMGeDkSWjQwDz/6e+/rY5OREREJGlQ4iSSBDg6QrduZgGJDz4AJyfz/KeXXjLLmN+7Z3WEIiIiIombEieRJCR1avM8p8OHoV4983ynMWPM9Z9mzdL6TyIiIiLPS4mTSBJUpAisXg2//Qb58sHVq9CxI1SpAn/8YXV0IiIiIomPEieRJMpmgyZN4OhR+OIL8PSEnTuhTBno21fT90RERERiQomTSBLn6gr9+8OJE9CypVm+fPx4syrfwoVgGFZHKCIiIpLwKXESSSayZzcTpdWrzel7V65Aq1ZmBT5V3xMRERGJmhInkWSmfn3480/49FNwcYHff4dixWD4cPD3tzo6ERERkYRJiZNIMuTubiZKR45A3boQEADDhkHx4uDjY3V0IiIiIgmPEieRZKxAAXPEacECyJLFnLLn7Q0dOsDNm1ZHJyIiIpJwKHESSeZsNvNcpxMnoHdvc3v2bLOk+dy5Kh4hIiIiAkqcRORfXl7w9ddmyfJixeD6dWjbFho1gvPnrY5ORERExFpKnEQkjAoVYP9+GDnSLB6xejW89BJ8841ZylxEREQkOVLiJCLhuLjA4MHwxx9QpQo8eADvvw+VK5sFJURERESSGyVOIhKpwoVh82aYNAlSpoTdu+Hll81S5oGBVkcnIiIiEn+UOIlIlBwcoEcPOH4cmjaFoCBzGl/ZsnDggNXRiYiIiMQPJU4iEi3ZssGSJfDLL5Ahg7mIbvnyMGSIRp9EREQk6VPiJCLRZrPB66/D0aPmv8HBMGqURp9EREQk6VPiJCIxliGDOfL0yy+QPr05+lShAgwdqtEnERERSZqUOInIc3v9dTh2zPz38WMYMQLKlYODB62OTERERCR2KXESkRcSOvq0YIE5+nT4sHnu09ChZiEJERERkaRAiZOIxIpWrcxzn1q0+G/0qWJFsxqfiIiISGKnxElEYk3GjLBwIcyfD2nTwv795rpP334LISFWRyciIiLy/JQ4iUisstmgdWuzYIS3N/j7Q+/eUL8+XL5sdXQiIiIiz0eJk4jEiaxZYc0a+O47cHcHHx8oXtw8F0pEREQksVHiJCJxxmaDd981q+yVKwe3b8Mbb0DbtubfIiIiIomFEicRiXOFCsH27WalPUdHmDsXSpSA9eutjkxEREQkepQ4iUi8cHaGYcPMBKpAAbh0CerUgT59zPOgRERERBIyJU4iEq8qVDCn7r3zjrn99dfmvmPHrI1LREREJCpKnEQk3nl6wsSJsHKluYDu4cNQtiz88AMYhtXRiYiIiISnxElELNOwoZk0eXvDo0fQo4e5gO6tW1ZHJiIiIhKWEicRsVTmzLB6NYwbZ54HtWSJWThi0yarIxMRERH5jxInEbGcgwP07Qu7dkHBguZCubVqweDBEBRkdXQiIiIiSpxEJAF5+WXYvx+6djXPdfrsM6hWDc6etToyERERSe6UOIlIgpIiBfz0EyxYAKlSmaNQpUrBvHlWRyYiIiLJmRInEUmQWrWCP/6AypXBzw/atIHu3c0iEiIiIiLxTYmTiCRYuXKZRSI+/RRsNnMkqkIFOHHC6shEREQkuVHiJCIJmpMTDB8OPj6QKRP8+ae55tPPP1sdmYiIiCQnSpxEJFGoXRsOHTKr7T14AO3bQ7du8PCh1ZGJiIhIcqDESUQSjcyZYe1acwTKZoOpU82pe8ePWx2ZiIiIJHVKnEQkUXF0NM95Wr/eTKSOHDGn7s2aZXVkIiIikpQpcRKRRKlmTXPqXp065nS9jh2hSxdN3RMREZG4ocRJRBKtTJlgzRoYMQIcHGD6dChXDo4dszoyERERSWqUOIlIouboCEOG/Dd179gxKF/eXEBXREREJLYocRKRJKFGjbBV9954A/r0gcBAiwMTERGRJMHyxGnixInkyZMHNzc3ypQpw9atW6NsP2fOHEqWLImHhwdZsmShc+fO3Lx5M56iFZGELFMms+reJ5+Y219/bZ4LdfmytXGJiIhI4mdp4rRgwQL69OnDoEGDOHjwIFWrVqVBgwZcuHAhwvbbtm2jQ4cOdO3alaNHj7Jw4UL27t1Lt27d4jlyEUmoHB3hs8/gt98gVSrYsQNKl4YNG6yOTERERBIzSxOnr776iq5du9KtWzeKFCnChAkTyJEjB5MmTYqw/a5du8idOze9e/cmT548VKlShbfffpt9+/bFc+QiktA1aQL790PJknD9OtStC198ASEhVkcmIiIiiZGTVQcODAxk//79DBgwIMx+b29vduzYEeFtKlWqxKBBg1i1ahUNGjTg2rVrLFq0iEaNGkV6nICAAAICAuzbfn5+AAQFBREUFBQLj+TFhMaQEGKR2KE+TThy5oQtW6BXL0dmzXJg4EDYvj2EadOCSZ06+vejPk2a1K9Jj/o0aVK/Jj0JqU9jEoPNMAwjDmOJ1JUrV8iWLRvbt2+nUqVK9v2ff/45M2fO5OTJkxHebtGiRXTu3Bl/f38eP37Mq6++yqJFi3B2do6w/bBhwxg+fHi4/XPnzsXDwyN2HoyIJGiGAevW5WTKlBIEBTmSOfN9+vXbS968flaHJiIiIhZ6+PAhbdq04e7du3h5eUXZ1vLEaceOHVSsWNG+/7PPPmP27NmcOHEi3G2OHTtGnTp1+OCDD6hXrx5Xr17l448/ply5ckydOjXC40Q04pQjRw5u3LjxzCcnPgQFBeHj40PdunUjTf4kcVGfJlwHDsAbbzhx7pwNNzeD774LpkOHZ38Eqk+TJvVr0qM+TZrUr0lPQupTPz8/0qdPH63EybKpeunTp8fR0RFfX98w+69du0amTJkivM3o0aOpXLkyH3/8MQAlSpTA09OTqlWrMmrUKLJkyRLuNq6urri6uobb7+zsbHlHPSmhxSMvTn2a8FSoYJ731K4drF5to1s3J/bvhwkTwMXl2bdXnyZN6tekR32aNKlfk56E0KcxOb5lxSFcXFwoU6YMPj4+Yfb7+PiEmbr3pIcPH+LgEDZkR0dHACwaOBORRCZtWlixAoYPB5sNJk2C2rXhqd9wRERERMKwtKpe3759+emnn5g2bRrHjx/ngw8+4MKFC/To0QOAgQMH0qFDB3v7Jk2asHjxYiZNmsSZM2fYvn07vXv3pnz58mTNmtWqhyEiiYyDA3z6qVmy3MsLtm2DMmVg926rIxMREZGEyrKpegCtW7fm5s2bjBgxgqtXr1KsWDFWrVpFrly5ALh69WqYNZ06derEvXv3+O677/jwww9JnTo1tWrVYsyYMVY9BBFJxBo3hr174bXX4PhxqFYNJk6Erl2tjkxEREQSGksTJ4CePXvSs2fPCK+bMWNGuH29evWiV69ecRyViCQXBQuaI00dO8KSJdCtGzE670lERESSB0un6omIJAQpU8KiRTBq1H/nPdWqpfOeRERE5D9KnEREMM97GjTILByRKhVs326e97Rrl9WRiYiISEKgxElE5AkNG5rnPRUtCleuQPXqMG2azeqwRERExGJKnEREnlKggDnS1KIFBAZCjx5OTJpUgsBAqyMTERERqyhxEhGJQMqUsHAhfPYZ2GwGv/+eh3r1HLl2zerIRERExApKnEREImGzwSefwLJlwXh4BLF9uwPlysGhQ1ZHJiIiIvFNiZOIyDPUr2/w5ZdbyJ/f4MIFqFwZfv3V6qhEREQkPilxEhGJhmzZ7rN9+2Pq1oWHD6FlSxg+HEJCrI5MRERE4oMSJxGRaEqTBlatgj59zO1hw6B1a3jwwMqoREREJD4ocRIRiQEnJxg/HqZOBWdnc+HcKlXgwgWrIxMREZG4pMRJROQ5dOkCGzZAhgxmsYhy5cxFc0VERCRpUuIkIvKcqlSBffugZEm4dg1q1oRp06yOSkREROKCEicRkReQM6c50tSiBQQFQdeu8MEH8Pix1ZGJiIhIbFLiJCLygjw94ZdfzGIRABMmQKNGcPu2lVGJiIhIbFLiJCISCxwcYOhQWLgQPDxg7VqoVAlOn7Y6MhEREYkNSpxERGJRy5awbRtkzw4nTkCFCrB1q9VRiYiIyItS4iQiEstKl4Y9e6BsWbh5E2rXhlmzrI5KREREXoQSJxGROJAlC2ze/F/RiI4dYfBgCAmxOjIRERF5HkqcRETiiIeHWTRi4EBz+7PPoHVrePjQ2rhEREQk5pQ4iYjEIQcH+PxzmDEDnJ1h0SKoUQOuXrU6MhEREYkJJU4iIvGgY0dYtw7SpoW9e82iEX/8YXVUIiIiEl1KnERE4km1arB7NxQqBBcvQpUqsGKF1VGJiIhIdChxEhGJR/nzw86dUKsW3L8Pr74K48eDYVgdmYiIiERFiZOISDxLkwbWrIHu3c2EqW9feOcds/qeiIiIJExKnERELODsDD/8AOPGgc1m/t2wIdy9a3VkIiIiEhElTiIiFrHZzNGmpUvB09MsHlG5Mly4YHVkIiIi8jQlTiIiFnv1Vdi6FbJmhaNHzYp7Bw5YHZWIiIg8SYmTiEgCULo07NoFxYqBr69ZgU8V90RERBIOJU4iIglEjhywbRvUrQsPHkDTpjBxotVRiYiICChxEhFJUFKlgpUroUsXCAmBd9+Fjz82/xYRERHrKHESEUlgnJ3hp59g1Chz+3//g1at4NEja+MSERFJzpQ4iYgkQDYbDBoEP/8MLi7w66/mornXr1sdmYiISPKkxElEJAFr2xbWrjUXzd21C155BU6dsjoqERGR5EeJk4hIAle9OuzYAXnywJkzULGiWb5cRERE4o8SJxGRRKBwYXPEqXx5uHUL6tSBBQusjkpERCT5UOIkIpJIZMwIGzfCa69BYCC88QaMGQOGYXVkIiIiSZ8SJxGRRMTDAxYtgj59zO0BA+Cdd+DxY0vDEhERSfKUOImIJDKOjjB+PHzzjVl974cfoHlzePjQ6shERESSLiVOIiKJVK9eZplyNzdYvlzlykVEROKSEicRkUSsWTNYt84sV757N1SubFbeExERkdilxElEJJGrXBm2b4dcueCvv8xy5fv3Wx2ViIhI0qLESUQkCShSBHbuhFKl4No1c+2nNWusjkpERCTpUOIkIpJEZMkCmzebazw9eACNG8OMGVZHJSIikjQocRIRSUK8vGDlSmjXDoKDoXNnGDVKaz2JiIi8KCVOIiJJjIsLzJplrvEEMGQI9OihtZ5ERERehBInEZEkyGaD0aPhu+/Mv6dM0VpPIiIiL0KJk4hIEvbuu1rrSUREJDYocRIRSeK01pOIiMiLU+IkIpIMaK0nERGRF6PESUQkmYhorafff7c6KhERkcRBiZOISDISutZT3br/rfU0Z47VUYmIiCR8SpxERJIZLy9YsQLefNMsUd6uHYwfb3VUIiIiCZsSJxGRZMjFBX7+Gd5/39zu2xf699dCuSIiIpFR4iQikkw5OJgjTV98YW6PHQudO0NQkLVxiYiIJERKnEREkjGbzRxpmjYNHB1h5kyzfLkWyhUREQlLiZOIiNC5MyxdCu7usHIl1K4NN29aHZWIiEjCocRJREQAs8Je6EK5u3ZB1apw8aLVUYmIiCQMSpxERMSuUiXYuhWyZYPjx83tY8esjkpERMR6SpxERCSMl16CHTvMBXMvXYIqVcxtERGR5EyJk4iIhJMzpzny9MorcPs21Kljrv0kIiKSXClxEhGRCKVLZ57z1LAhPHoEr70GM2ZYHZWIiIg1lDiJiEikPD3NansdOkBwsFl9b8wYLZQrIiLJjxInERGJkrOzOdL08cfm9oAB0LcvhIRYGpaIiEi8UuIkIiLPZLPB2LEwbpy5PWECtG8PgYGWhiUiIhJvlDiJiEi09e0Ls2eDkxPMnQtNmsD9+1ZHJSIiEvdinDjVrFmTqVOncvfu3biIR0REErh27WD5cvDwgLVroXZtuHnT6qhERETiVowTp+LFizN48GAyZ85MixYtWLp0KYGaqyEikqzUrw8bNkDatLBnD1SrBpcvWx2ViIhI3Ilx4vTNN99w+fJlli1bRsqUKenYsSOZM2fmrbfeYvPmzXERo4iIJEAVKphrPWXLBseOQeXKcOqU1VGJiIjEjec6x8nBwQFvb29mzJjBP//8ww8//MCePXuoVatWbMcnIiIJWNGisH07FCgA589DlSpw4IDVUYmIiMS+FyoO4evry+TJkxkzZgyHDx+mbNmysRWXiIgkErlywbZtULo0XL8ONWrApk1WRyUiIhK7Ypw4+fn5MX36dOrWrUuOHDmYNGkSTZo04dSpU+zevTsuYhQRkQQuY0YzWapeHe7dM8+BWrbM6qhERERij1NMb5ApUybSpElDq1at+PzzzylXrlxcxCUiIomMlxesWQNvvGEmTS1awNSp0LGj1ZGJiIi8uBgnTsuWLaNOnTo4OGgJKBERCcvNDRYtgu7dYcYM6NTJLFXet6/VkYmIiLyYGGc/3t7ehISEsG7dOn744Qfu3bsHwJUrV7ivVRBFRJI9JydzpCk0WfrwQ/jkEzAMa+MSERF5ETEecTp//jz169fnwoULBAQEULduXVKmTMnYsWPx9/dn8uTJcRGniIgkIg4O8L//QYYMMHAgjB5tjjxNnAiOjlZHJyIiEnMxTpzef/99ypYtyx9//EG6dOns+5s1a0a3bt1iNTgREUm8bDYYMMBcJLdHD5gyBW7dgp9/BldXq6MTiRshISEEBgZaHUaSEhQUhJOTE/7+/gQHB1sdjsSC+O5TFxeXWDnNKMaJ07Zt29i+fTsuLi5h9ufKlYvLWjZeRESe8tZbZvLUtq15/tPdu7B4MaRIYXVkIrErMDCQs2fPEhISYnUoSYphGGTOnJmLFy9is9msDkdiQXz3qYODA3ny5AmXv8RUjBOnkJCQCDPDS5cukTJlyhcKRkREkqaWLSF1anjtNfDxgdq1YdUqeGLigkiiZhgGV69exdHRkRw5cqiIViwKCQnh/v37pEiRQs9rEhGffRoSEsKVK1e4evUqOXPmfKFELcaJU926dZkwYQJTpkwBwGazcf/+fYYOHUrDhg2fOxAREUna6tSBDRugQQPYsweqVoW1ayF7dqsjE3lxjx8/5uHDh2TNmhUPDw+rw0lSQqc/urm5KXFKIuK7TzNkyMCVK1d4/Pgxzs7Oz30/MY50/PjxbN68maJFi+Lv70+bNm3InTs3ly9fZsyYMc8diIiIJH3ly8PWrZAtGxw/DpUrw6lTVkcl8uJCZ+O86FQgEYl9oe/LFz2fKsYjTlmzZuXQoUPMmzePAwcOEBISQteuXWnbti3u7u4vFIyIiCR9RYvC9u3g7W0mTVWqmAvnvvyy1ZGJvDidgyOS8MTW+zLGiROAu7s7Xbp0oUuXLrEShIiIJC+5cpkjTw0awIEDUKMG/Pab+a+IiEhCFOOpehs2bOC9996jcePGNGnShPfff58tW7Y8dwATJ04kT548uLm5UaZMGbZu3Rpl+4CAAAYNGkSuXLlwdXUlX758TJs27bmPLyIi1siYETZuNJOle/egfn1YtszqqEQkts2YMYPUqVNbHUaCU6NGDfr06WPfzp07NxMmTIiXY2/YsIHChQvHegXI6DwGm83G0qVLY+2YK1asoHTp0vFSzTJGiVOPHj2oU6cO8+bN4+bNm1y/fp2ff/6ZmjVr0qtXrxgffMGCBfTp04dBgwZx8OBBqlatSoMGDbhw4UKkt2nVqhXr169n6tSpnDx5knnz5lG4cOEYH1tERKzn5QWrV0PTphAQAM2bw8yZVkclkrz4+vrSq1cv8ubNi6urKzly5KBJkyasX78+Vu6/devWnIrHkxnnzp2Lo6MjPXr0iLdjxoa9e/fy1ltvxcux+vXrx6BBg6JVmCGhJ76NGzfGZrMxd+7cOD9WtBOnJUuWMH36dKZNm8aNGzfYuXMnu3bt4vr16/z4449MmTKF3377LUYH/+qrr+jatSvdunWjSJEiTJgwgRw5cjBp0qQI269Zs4bNmzezatUq6tSpQ+7cuSlfvjyVKlWK0XFFRCThcHMz13fq1AlCQsx/v/nG6qhEkodz585RpkwZNmzYwNixY/nzzz9Zs2YNNWvW5N13342VY7i7u5MxY8ZYua/omDZtGv369WP+/Pk8fPgw3o77ojJkyBAvFRl37NjBX3/9xeuvvx7nx4ovnTt35ttvv43z40Q7cZo+fTp9+/alU6dOYU6wcnBwoEuXLvTp04epU6dG+8CBgYHs378fb2/vMPu9vb3ZsWNHhLf57bffKFu2LGPHjiVbtmwULFiQjz76iEePHkV6nICAAPz8/MJcwFyxOKFcElo8uqhPdVGfxvfFMIKYPDmI3r3Nikfvvw+ffhpMYKD6VZfE06eGYRASEpKoLu+88w42m41du3bRvHlz8ufPT5EiRejTpw87duywtzt37hyvvvoqKVKkwMvLi9dff52rV6/arz948CA1a9YkZcqUeHl5UaZMGfbs2UNISAjTpk0jderU9rZDhw6lVKlSzJw5k9y5c5MqVSpat27N3bt37W2Cg4MZM2YMefPmxdPTkypVqrBo0aJnPp4zZ86wY8cO+vXrR+HChfnll1/CXB8ay+rVqylSpAgpUqSgXr16XL582d6mY8eONG3alC+//JIsWbKQLl06evbsSUBAgL2Nv78/H3/8MdmyZcPT05MKFSqwYcMG+/XXr1/njTfeIHv27Hh4eFC8eHHmzJkTJhYgzGsmd+7cjB8/3r5ts9mYMmUKr732Gh4eHhQoUIClS5eGuY+lS5dSoEAB3N3dqVmzJtOnT8dms3Hr1q1In6N58+ZRt25dXFxcntl/GzZsoHPnzty9exebzYbNZmPo0KGEhITg6+tL48aNcXd3J0+ePMyePTvcYzp58iTVqlXDzc2NokWL8vvvv4f5nm4YBhcvXqRVq1akSZOGdOnS8eqrr3LmzBlCQkJYvXo1bm5u4R5Pr169qF69un27cePG7Nmzh7///jvSx20YRpSfG9ER7eIQBw4cYPDgwZFe36JFC5o3bx7tA9+4cYPg4GAyZcoUZn+mTJnw9fWN8DZnzpxh27ZtuLm5sWTJEm7cuEHPnj25detWpOc5jR49muHDh4fbv3bt2gS1zoKPj4/VIUgsU58mPerTuFezJly/XpB584owcqQjBw+eo0uXI8TlMh/q16THij51cnIic+bM3L9/n8DAQAwDrBrs8PCA6BQRu337Nr///juDBw8mODjY/uNyKAcHB/z8/DAMg6ZNm+Lh4cGKFSt4/PgxH330Ea+//jorVqwAoE2bNpQoUYL169fj6OjIn3/+af/x2t/fH8Mw7PcfEBDA6dOn+fXXX5k7dy537tyhS5cujBgxgiFDhgAwcuRIVqxYwZdffkm+fPnYsWMHHTp0wNPTk8qVK0f6mCZPnoy3tzc2m43mzZvz448/8tprr9mv9/f35+HDh4wdO5aJEyfi4ODA22+/TZ8+ffjxxx8BM/HeuHEj6dKlY9myZZw5c4auXbtSqFAhOnbsCED37t25cOECP/74I1myZGHFihU0bNiQ7du3ky9fPq5fv85LL73Eu+++S8qUKVm7di0dO3YkU6ZMlC1bFjDX/goMDLQ/L6EJ2ZP9MHz4cIYPH86nn37KlClTaN++PYcPHyZNmjRcuHCBVq1a8fbbb9OhQwcOHz5s/65+7969SKfhbdq0iRYtWoQ5TmT9V6xYMUaPHs3nn3/O3r17AfD09MTPz4/27dtz+fJlli1bhouLC/379+fatWv2xxASEkKzZs1Ily4dPj4++Pn50a9fPwD7oMc///xDzZo1qVixIitWrMDJyYn//e9/1K9fn23btlG+fHlSpUrFnDlzaN++PWCWFP/ll18YOHCg/TGkSZOGDBky4OPjw5tvvhnuMQcGBvLo0SO2bNnC48ePw1wXk1HJaCdON27cIFu2bJFeny1bNm7evBntA4d6ujygYRiRlgwMzb7nzJlDqlSpAHO6X8uWLfn+++8jLIc+cOBA+vbta9/28/MjR44ceHt74+XlFeN4Y1tQUBA+Pj7UrVv3hRbkkoRDfZr0qE/jV6NGUK5cMH37OrJiRT7Sps3D5MnBOD1XHdjIqV+THiv71N/fn4sXL5IiRQrc3Nx48ACyZ7dmsVY/vxA8PZ/d7sSJExiGQcmSJaP8TuTj48PRo0c5ffo0OXLkAODnn3+mePHinDx5knLlynH58mX69etnTwpKly5tv72bmxs2m81+DFdXV0JCQpg9ezYpU6YEoH379mzduhUvLy8ePHjAxIkTWbduHRUrVsQwDHLnzs3+/fv5+eefadCgQYRxhoSEMH/+fL7++mu8vLzo1KkTgwcP5tq1a+TPn98eS1BQEFOmTCFfvnwA9OrVi5EjR9rjc3Z2Jm3atPzwww84OjpStmxZfv31V3bs2EGvXr3sSd+FCxfImjUrACVLlmTz5s0sWrSIzz77DC8vLwYNGmSPrUSJEmzatInVq1dTq1YtwEy2XVxc7Md1cHDAzc0tTF907tzZXsX6yy+/ZMqUKRw/fpz69eszZ84cChUqxNdffw1AmTJlOHPmDJ9//rl95CgiFy9eJE+ePGGuj6r/MmbMiIODAwUKFLDvO3XqFOvWrWPHjh1UqFABMGenvfTSS/bHsHbtWk6dOsWZM2fI/u9K5zabjUaNGtm/s69atQonJydmzJhh//4/e/Zs0qZNy4EDB/D29qZ169YsXbrUPnV07dq13Llzh/bt24d5DNmzZ+eff/6J8HH7+/vj7u5uH/160tM/GEQl2v8NBQYGRrmom5OTE4GBgdE+cPr06XF0dAw3unTt2rVwo1ChsmTJQrZs2exJE0CRIkUwDINLly6F6dBQrq6uuLq6htvv7OycoP6jTGjxyItTnyY96tP488EHkC4ddOkCs2Y5cO+eA/PmQQQf5y9M/Zr0WNGnwcHB2Gw2HBwc/r3E6+HDiO7xQ7+oOjo6Rlkk4OTJk+TIkYNcuXLZ9xUrVozUqVNz8uRJKlSoQN++fXnrrbeYM2cOderU4fXXX7cnJqH3HfqvzWazT9ELlTVrVq5du4aDgwMnTpzA39+fevXqhYkjMDCQ0qVLRxrr2rVrefDgAY0aNcLBwYGMGTPi7e3NjBkz+Pzzz+0xhE57i+jYofG99NJLYV5DWbNm5c8//8TBwYFDhw5hGEa44mQBAQGkS5cOBwcHgoOD+eKLL1iwYAGXL18mICCAgIAAUqRIESb+0NdMZNslS5a0b6dMmZKUKVNy48YNHBwcOHXqFOXKlQvTPjSJCX0dRuTRo0d4eHiEuT4m/Qfma8LJyYny5cvb9xctWpTUqVPbH8PJkyfJmTMnOXPmtN/u6dHCAwcO8Pfff4d5LYCZ6Jw9exYHBwfatWtHxYoV8fX1JWvWrMybN4+GDRuSLl26MLdxd3fn0aNHET5uBwcHbDZbhJ8NMfmsiNHvd0OGDIl0eltMT75zcXGhTJky+Pj40KxZM/t+Hx8fmjZtGuFtKleuzMKFC7l//z4pUqQAzIzXwcHBnsmKiEjS0KGDWXWvdWtYsgQaNzb//ffjXyRB8/CA+/etO3Z0FChQAJvNxvHjx8NMZ3taZLOBntw/bNgw2rRpw8qVK1m9ejVDhw5l/vz5Yb7jPenpL6s2m81+3k/ovytXriRbtmyEhITYv/tFNLso1LRp07h161aY76qh5++MHDkSR0fHSI9tGEaM4nN0dGT//v32+wwV+v103LhxjB8/ngkTJlC8eHE8PT3p06dPjAYZnhVHRP3y9OOISPr06bl9+3aYfTHtv9DjRLWwbESxPN0+JCSEMmXKMGfOnHBtM2TIAED58uXJly8f8+fP55133rEXrHvarVu37LeJK9FOnKpVq8bJkyef2SYm+vbtS/v27SlbtiwVK1ZkypQpXLhwwV4+cuDAgVy+fJlZs2YB5vzLkSNH0rlzZ4YPH86NGzf4+OOP6dKlS5RvJBERSZxeew1WrTLLla9bB3XrwsqVkDat1ZGJRM1mI1rT5ayUNm1a6tWrx/fff0/v3r3xfCrgO3fukDp1aooWLcqFCxe4ePGifaresWPHuHv3LkWKFLG3L1iwIAULFuSDDz7gzTffZPr06ZF+8Y5K0aJFcXV15cKFC/YCAH5+fnh5eUU6inLz5k2WLVvG/Pnzeemll+z7Q0JCqFq1KqtXr6Zx48YxjiUipUuXJjg4mGvXrlG1atUI22zdupWmTZvSrl07exx//fVXmOfrRRUuXJhVq1aF2bdv375n3q506dIcO3Ys3P7I+s/FxYXg4OAwbYsUKcLjx4/Zt28f5cuXB8xRqDt37tjbhL5urly5Yp/SuHPnznCx/PLLL2TMmDHK6aJt2rRhzpw5ZM+eHQcHBxo1ahTmen9/f06fPh1mimFciHbitGnTplg/eOvWrbl58yYjRozg6tWrFCtWjFWrVtmHgq9evRpmTacUKVLg4+NDr169KFu2LOnSpaNVq1aMGjUq1mMTEZGEoXZtWL8eGjSAXbugenVYuxayZLE6MpHEb+LEiVSqVIny5cszYsQISpQowePHj/Hx8WHSpEkcP36cOnXqUKJECdq2bcuECRN4/PgxPXv2pHr16pQtW5ZHjx7x8ccf07JlS/LkycOlS5fYu3cvLVq0eK6YUqZMyUcffcQHH3xASEgIlSpV4urVqxw+fJiUKVPaCzQ8afbs2aRLl47XX389XHLVuHFjpk6dGmuJU8GCBWnbti0dOnRg3LhxlC5dmhs3brBhwwaKFy9Ow4YNyZ8/v/28qDRp0vDVV1/h6+sbq4nT22+/zVdffUX//v3p2rUrhw4dYsaMGUDUI0H16tVj5hML5j2r/3Lnzs39+/dZv349JUuWxMPDg0KFClG/fn26d+/OlClTcHJyok+fPmEGMurUqUOhQoXsz5Ofn1+Y874A2rZty7hx42jatCkjRowge/bsXLhwgcWLF/Pxxx/bZ5S1bduW4cOH89lnn9GyZctw5ynt2rULV1dXKlas+ELP6bNYOAPX1LNnT86dO0dAQAD79+8PM2o1Y8aMcAlb4cKF8fHx4eHDh1y8eJFx48ZptElEJImrUAG2bDGTpSNHoGpVOHvW6qhEEr88efJw4MABatasyYcffkixYsWoW7cu69evt6+rabPZWLp0KWnSpKFatWrUqVOHvHnzsmDBAsA8R+rmzZt06NCBggUL0qpVKxo0aBBhVePoGjlyJJ9++imjR4/mpZdeokWLFixfvpw8efJE2H7atGk0a9YswhGpFi1asGLFCv7555/njudp06dPp0OHDnz44YcUKlSIV199ld27d9tH5IYMGcLLL79MvXr1qFGjBpkzZ45yOuTzyJMnD4sWLWLx4sWUKFGCSZMm2ROTiM7vD9WuXTuOHTtmn0n2rP6rVKkSPXr0oHXr1mTIkIGxY8fan4McOXJQvXp1mjdvzltvvRVmvS4HBweWLFlCQEAA5cuXp1u3bnz22WdhYvHw8GDLli3kzJmT5s2bU6RIEbp06cKjR4/CjEAVKFCAcuXKcfjwYdq2bRvuMc2bN4+2bdvGecVsmxGNyZBPVqV7lq+++uqFAoprfn5+pEqVirt37yaYqnqrVq2iYcOGOjk5iVCfJj3q04Tj9Glzut7Zs5A1K/j4QNGiz3df6tekx8o+DT2ZPU+ePOF+DZcXE52pemL67LPPmDx5MhcvXoyyXb9+/bh79y4//PBDPEUWVmz26fXr1ylcuDD79u2LNLGO6v0Zk9wgWlP1Dh48GGZ7//79BAcHU6hQIcAs0ODo6EiZMmWic3ciIiLPJV8+2LYNvL3h6FGoVg1Wr4Zy5ayOTEQk/k2cOJFy5cqRLl06tm/fzpdffsl77733zNsNGjSI77//nuDg4HAFLhKbs2fPMnHixEiTptgUrcRp48aN9r+/+uorUqZMycyZM0mTJg1gLqDWuXPnSE+QExERiS1Zs8LmzdCwIezZA7VqwfLlUKOG1ZGJiMSvv/76i1GjRnHr1i1y5szJhx9+yMCBA595u1SpUvHJJ5/EQ4Rxr3z58vYCFXEtxmNj48aNY/To0fakCczVekeNGsW4ceNiNTgREZGIpEtnVtmrVcss+Vy/vpk8iYgkJ+PHj+fKlSv4+/tz6tQphgwZglNsrxYudjFOnPz8/CI8ue7atWvcu3cvVoISERF5lpQpzdLkTZtCQAA0awY//2x1VCIiklTFOHFq1qwZnTt3ZtGiRVy6dIlLly6xaNEiunbtSvPmzeMiRhERkQi5ucGiReZiucHB0L49fP+91VGJiEhSFOOxvMmTJ/PRRx/Rrl07goKCzDtxcqJr1658+eWXsR6giIhIVJycYPp0SJUKvv0W3nsP7tyBTz4xFyEVERGJDTFOnDw8PJg4cSJffvklp0+fxjAM8ufPH261aRERkfji4ABffw1p0sCIETB4MNy+DV9+qeRJRERiR4yn6nXp0oV79+7h6elJiRIlKFmyJJ6enjx48IAuXbrERYwiIiLPZLPB8OEwfry5PW4cdO9uTuETERF5UTFOnGbOnMmjR4/C7X/06BGzZs2KlaBERESeV58+MG2aOQo1dSq88YZZPEJERORFRHuqnp+fH4ZhYBgG9+7dC7PqbnBwMKtWrSJjxoxxEqSIiEhMdO5snvP05ptm8Qg/P1i8GDSrXEREnle0R5xSp05N2rRpsdlsFCxYkDRp0tgv6dOnp0uXLrz77rtxGauIiEi0NW8OK1aAhwesXQve3mbRCBF5MTabjaVLl0bZplOnTrz22mvRvs9z585hs9k4dOhQlO1OnjxJ5syZ43wJnD///JPs2bPz4MGDOD2OJC7RTpw2btzI+vXrMQyDRYsWsWHDBvtl27ZtXLhwgUGDBsVlrCIiIjFSt665UG7q1LBjB9SoAREsRSiSbMU0wQG4evUqDRo0ACJPeL7++mtmzJgRO0E+YdCgQbz77rukTJkSAH9/fzp16kTx4sVxcnKK9mO5ffs27du3J1WqVKRKlYr27dtz54lfVooXL0758uUZH3rSpAgxmKpXvXp1AM6ePUvOnDmxqUyRiIgkAhUrwubN5ojTH39A1arg4wNZs1odmUjilDlz5me2SZUqVawf99KlS/z2229MmDDBvi84OBh3d3d69+7Nr7/+Gu37atOmDZcuXWLNmjUAvPXWW7Rv357ly5fb23Tu3JkePXowcOBAHB0dY+1xSOIV7RGnW7ducenSJXLlymVPmo4ePUrnzp1p1aoVc+fOjbMgRUREXkSJErBtG+TKBX/9BVWqwIkTVkclycKDB5Ff/P2j3/bpwlyRtXtBNWrUoHfv3vTr14+0adOSOXNmhg0bFqbNk1P18uTJA0Dp0qWx2WzUqFEDCD+StWbNGqpUqULq1KlJly4djRs35vTp0zGKbeHChZQsWZLs2bPb93l6ejJp0iS6d+8erYQO4Pjx46xZs4affvqJihUrUrFiRX788UdWrFjByZMn7e3q1avHzZs32bx5c4zilKQr2onTu+++y1dffWXfvnbtGlWrVmXv3r0EBATQqVMnZs+eHSdBioiIvKj8+WH7dihSBC5dglq1nDh9OvZ/FRcJI0WKyC8tWoRtmzFj5G3/nRpnlzt3xO1iwcyZM/H09GT37t2MHTuWESNG4OPjE2HbPXv2ALBu3TquXr3K4sWLI2z34MED+vbty969e1m/fj0ODg40a9aMkJCQaMe1ZcsWypYtG/MH9JSdO3eSKlUqKlSoYN/3yiuvkCpVKnbs2GHf5+LiQsmSJdm6desLH1OShmhP1du1axfTp0+3b8+aNYu0adNy6NAhnJyc+N///sf3339P+/bt4yRQERGRF5UtG2zZAvXrw/79NoYMqUypUjZq1bI6MpGEo0SJEgwdOhSAAgUK8N1337F+/Xrq1q0brm2GDBkASJcuXZQjPi2eShKnTp1KxowZOXbsGMWKFYtWXOfPn4+VxMnX1zfCStAZM2bE19c3zL5s2bJx7ty5Fz6mJA3RHnHy9fW1D8cCbNiwgWbNmuHkZOZer776Kn/99VfsRygiIhKL0qeHDRugWrUQHj50plEjR1atsjoqSbLu34/88vQ5OdeuRd529eqwbc+di7hdLChRokSY7SxZsnDt2rUXus/Tp0/Tpk0b8ubNi5eXl/075YULF6J9H48ePQqzHM6LiOhcfcMwwu13d3fn4cOHsXJMSfyinTh5eXmFqTayZ88eXnnlFfu2zWYjQCsMiohIIuDlBcuXB1O2rC/+/jaaNoX5862OSpIkT8/IL08nAVG1dXePXttY4OzsHGbbZrPFaEpdRJo0acLNmzf58ccf2b17N7t37wYgMDAw2veRPn16bt++/UJxgFnc4p8Iymtev36dTJkyhdl369Yt+6iaSLQTp/Lly/PNN98QEhLCokWLuHfvHrWemNtw6tQpcuTIESdBioiIxDZ3dxgwYA9vvBHC48fQpg388IPVUYkkLi4uLoBZ3S4yN2/e5Pjx4wwePJjatWtTpEiR50qASpUqxbFjx5471lAVK1bk7t279vOzAHbv3s3du3epVKlSmLZHjhyhdOnSL3xMSRqinTiNHDmSZcuW4e7uTuvWrenXrx9p0qSxXz9//nx7yXIREZHEwMnJYMaMYHr2BMOAHj3giy+sjkok8ciYMSPu7u6sWbOGf/75h7t374ZrkyZNGtKlS8eUKVP4+++/2bBhA3379o3xsby9vdm5c2e4JO3YsWMcOnSIW7ducffuXQ4dOhRmXak9e/ZQuHBhLl++DECRIkWoX78+3bt3Z9euXezatYvu3bvTuHFjChUqZL/duXPnuHz5MnXq1IlxrJI0Rbs4RKlSpTh+/Dg7duwgc+bMYSqRALzxxhsULVo01gMUERGJSw4O8N13kCYNfPYZDBwIt2+bCZSWLBSJmpOTE9988w0jRozg008/pWrVqmzatClMGwcHB+bPn0/v3r0pVqwYhQoV4ptvvrGXLo+uhg0b4uzszLp166hXr16Y/efPn7dvh44QGYYBwMOHDzl58iRBQUH2NnPmzKF37954e3sD5rn63333XZjjzZs3D29vb3LlyhWjOCXpshmhr6pkws/Pj1SpUnH37l28vLysDoegoCBWrVpl/zCQxE99mvSoT5OmiPp13Dj46CPz+m7dYPJk0LqXiYeV71V/f3/Onj1Lnjx5Yq2AgZhCQkLw8/PDy8uLyZMns2zZMn7//fc4PWZAQAAFChRg3rx5VK5cOU6PlRw92acODtGeAPfconp/xiQ3iPaIk4iISFL34YfmyFP37vDTT3D3Lvz8M/x7GoeIWOytt97i9u3b3Lt3j5QpU8bZcc6fP8+gQYOUNEkYSpxERESe0KULpEplFotYuBD8/Myq0bFUsExEXoCTkxODBg2K8+MULFiQggULxvlxJHGJ+7ExERGRRKZFC1ixAjw84PffwdvbPO9JRESSLyVOIiIiEahbF9atg9SpYccOqFEDIlj6RUREkonnSpxOnz7N4MGDefPNN+0rSa9Zs4ajR4/GanAiIiJWqlgRtmyBzJnh8GGoUgXOnbM6KhERsUKME6fNmzdTvHhxdu/ezeLFi7l//z4Ahw8fZujQobEeoIiIiJWKF4dt2yBPHvj7bzN5ioU1OEVEJJGJceI0YMAARo0ahY+Pj321aICaNWuyc+fOWA1OREQkIciXD7ZuhaJF4fJlqFYN9u61OioREYlPMU6c/vzzT5o1axZuf4YMGbh582asBCUiIpLQZMtmTtsrXx5u3oRateCpdT5FRCQJi3HilDp1aq5evRpu/8GDB8mWLVusBCUiIpIQpUtnFoyoVQvu34f69eG336yOSkRE4kOME6c2bdrQv39/fH19sdlshISEsH37dj766CM6dOgQFzGKiIgkGClTwsqV8NprEBAAzZvD7NlWRyUSP2rUqEGfPn2i3f7cuXPYbDYOHToUZzHFhalTp+Lt7R3nx/nuu+949dVX4/w4EjtinDh99tln5MyZk2zZsnH//n2KFi1KtWrVqFSpEoMHD46LGEVERBIUNzdzcdyOHSE4GDp0gG+/tToqkZjr1KkTNpuNHj16hLuuZ8+e2Gw2OnXqZN+3ePFiRo4cGe37z5EjB1evXqVYsWKxEW68CAgI4NNPP2XIkCFh9v/6668ULVoUV1dXihYtypIlS6K8H39/fzp16kTx4sVxcnLitddeC9eme/fu7N27l23btsXmQ5A4EuPEydnZmTlz5vDXX3/xyy+/8PPPP3PixAlmz56No6NjXMQoIiKS4Dg5wbRp8P775nbv3jByJBiGtXGJxFSOHDmYP38+jx49su/z9/dn3rx55MyZM0zbtGnTkjJlymjft6OjI5kzZ8bJySnW4o1rv/76KylSpKBq1ar2fTt37qR169a0b9+eP/74g/bt29OqVSt2794d6f0EBwfj7u5O7969qVOnToRtXF1dadOmDd/ql5dE4bkXwM2bNy8tW7akRYsWPHjwgNtaUl1ERJIZBwcYPx6GDze3P/0U+vaFkBBr45KE40Hgg0gv/o/9o932UdCjaLV9Hi+//DI5c+Zk8eLF9n2LFy8mR44clC5dOkzbp6fq5c6dm88//5wuXbqQMmVKcubMyZQpU+zXPz1Vb9OmTdhsNn7//XdKly6Nu7s7tWrV4tq1a6xevZoiRYrg5eXFm2++ycOHD+33U6JECb7++uswsZQqVYphw4bZt202Gz/88AONGzfGw8ODIkWKsHPnTv7++29q1KiBp6cnFStW5PTp01E+H/Pnzw83fW7ChAnUrVuXgQMHUrhwYQYOHEjt2rWZMGFCpPfj6enJpEmT6N69O5kzZ4603auvvsrSpUvDJK6SMMU4cerTpw9Tp04FzEy6evXqvPzyy+TIkYNNKi8kIiLJjM1mJkyh3+kmTICuXeHxY0vDkgQixegUkV5a/NIiTNuM/8sYadsGcxqEaZv769wRtntenTt3Zvr06fbtadOm0aVLl2jddty4cZQtW5aDBw/Ss2dP3nnnHU6cOBHlbYYNG8Z3333Hjh07uHjxIq1atWLChAnMnTuXlStX4uPj81yjMCNHjqRDhw4cOnSIwoUL06ZNG95++20GDhzIvn37AHjvvfeivI+tW7dStmzZMPt27twZ7pynevXqsWPHjhjH+LSyZcsSFBTEnj17Xvi+JG7FOHFatGgRJUuWBGD58uWcOXOGEydO0KdPHwYNGhTrAYqIiCQGvXvDrFng6AgzZsDrr4O//zNvJpIgtG/fnm3btnHu3DnOnz/P9u3badeuXbRu27BhQ3r27En+/Pnp378/6dOnf+aP6aNGjaJy5cqULl2arl27snnzZiZNmkTp0qWpWrUqLVu2ZOPGjTF+HJ07d6ZVq1YULFiQ/v37c+7cOdq2bUu9evUoUqQI77//fpSx3blzhzt37pA1a9Yw+319fcmUKVOYfZkyZcLX1zfGMT7N09OT1KlTc+7cuRe+L4lbMZ5weuPGDftw46pVq+wvzq5du/LNN9/EeoAiIiKJRfv24OUFrVvD0qXQuDEsWWJW4pPk6f7A+5Fe5+gQ9tzwax9di7Stgy3sb93n3j/3QnE9LX369DRq1IiZM2diGAaNGjUiffr00bptiRIl7H/bbDYyZ87MtWuRP5anb5MpUyY8PDzImzdvmH3PMwLz9P0CFC9ePMw+f39//Pz88PLyCnf70Olybm5u4a6z2Wxhtg3DCLfvebm7u4eZmigJU4wTp0yZMnHs2DGyZMnCmjVrmDhxIgAPHz5UcQgREUn2mjaF1avh1Vdh/XqoUwdWrTLXgJLkx9PF0/K20dWlSxf7NLbvv/8+2rdzdnYOsx26XE10b2Oz2Z55Hw4ODhhPVV4JCgp65v1Gti+y+NKlS4fNZgt37n7mzJnDjS5du3Yt3CjU87p16xYZMmSIlfuSuBPjqXqhQ6DFihXDZrNRt25dAHbv3k3hwoVjPUAREZHEpmZN2LDBTJb27IHq1eHKFaujEola/fr1CQwMJDAwkHr16lkdThjp06fn6tWr9m0/Pz/Onj0b68dxcXGhaNGiHDt2LMz+ihUr4uPjE2bf2rVrqVSp0gsf8/Tp0/j7+4crxCEJT4wTp2HDhvHTTz/x1ltvsX37dlxdXQGz3OSAAQNiPUAREZHEqFw52LIFsmWDo0ehShV4RjEvEUs5Ojpy/Phxjh8/nuBmEVWtWpWff/6ZrVu3cuTIETp27BhnMdarVy/cukrvv/8+a9euZcyYMZw4cYIxY8awbt26MBUGv/vuO2rXrh3mdseOHePQoUPcunWLu3fvcujQoXCLAW/dupW8efOSL1++OHk8Enueq6h+y5Ytw+3r2LHjCwcjIiKSlBQtCtu2mdP1Tp82k6e1a+GJUy5EEpSIzvtJCD744AMuX75M48aNSZUqFSNHjoyTEScwF6V9+eWXuXv3LqlSpQKgUqVKzJ8/n8GDBzNkyBDy5cvHggULqFChgv12N27cCFfqvGHDhpw/f96+HTqq9OS0w3nz5tG9e/c4eSwSu2zG0xNGI/DNN9/w1ltv4ebm9swCEL1794614OKCn58fqVKl4u7duwniwyEoKIhVq1bRsGHDcPN7JXFSnyY96tOkKT771dcX6tWDw4chTRrznKdXXonTQyZLVr5X/f39OXv2LHny5ImwsIA8v5CQEHsxBweH516CNEZatWpF6dKlGThwYJwe58iRI9SuXZtTp07Zk7TkIL77NKr3Z0xyg2iNOI0fP562bdvi5ubG+PHjI21ns9kSfOIkIiIS3zJnhk2bzCp7O3ZA7dpm1b1/TxMWkQTmyy+/5Lfffovz41y5coVZs2Ylq6QpMYtW4vTkUGhcDYuKiIgkZWnSmNP0mjc3/23cGObNM7dFJGHJlSsXvXr1ivPjPL2oriRsLzQ2ZhhGuNKQIiIiEjFPT/jtN3Nx3MBA899p06yOSkREouO5EqdZs2ZRvHhx3N3dcXd3p0SJEsyePTu2YxMREUlyXF3NkaZu3SAkBLp2ha++sjoqiS36QVkk4Ymt92WMq+p99dVXDBkyhPfee4/KlStjGAbbt2+nR48e3Lhxgw8++CBWAhMREUmqHB1hyhRz+t6XX8KHH8Lt2zBiBPy7PqckMqGlsQMDA3F3d7c4GhF5UmBgIMALl7CPceL07bffMmnSJDp06GDf17RpU1566SWGDRumxElERCQabDYYOxbSpoWBA2HUKDN5+uYbiKfCYRKLnJyc8PDw4Pr16zg7O8db9bfkICQkhMDAQPz9/fW8JhHx2achISFcv34dDw8PnJyeayUmuxjf+urVqxGuklypUqUwKzqLiIjIsw0YAKlTQ8+e8P33cPMmzJwJLi5WRyYxYbPZyJIlC2fPng2zbo+8OMMwePToEe7u7tg0JJskxHefOjg4kDNnzhc+VowTp/z58/PLL7/wySefhNm/YMECChQo8ELBiIiIJEc9epjJU4cOMH8+3LoFv/4KKVJYHZnEhIuLCwUKFLBPC5LYERQUxJYtW6hWrZrW0ksi4rtPXVxcYmVkK8aJ0/Dhw2ndujVbtmyhcuXK2Gw2tm3bxvr16/nll19eOCAREZHk6I03zGl7zZqZ5crr1IGVKyFdOqsjk5hwcHDQArixzNHRkcePH+Pm5qbEKYlIrH0a49SrRYsW7N69m/Tp07N06VIWL15M+vTp2bNnD82aNYuLGEVERJIFb2/YsMFMoHbvhqpV4eJFq6MSERF4jhEngDJlyvDzzz/HdiwiIiLJXoUKsG2bmUQdPw6VK5sjUIULWx2ZiEjyptIkIiIiCUyRIrB9OxQqZI44VakCe/ZYHZWISPIW7cTJwcEBR0fHKC8vWuJPRERETDlzmiNP5cqZlfZq1QIfH6ujEhFJvqKd6SxZsiTS63bs2MG3336r1bJFRERiUfr05jlPzZubSVOjRvDzz9CqldWRiYgkP9FOnJo2bRpu34kTJxg4cCDLly+nbdu2jBw5MlaDExERSe5SpIDly81S5b/8Ylbfu3HDXPdJRETiz3Od43TlyhW6d+9OiRIlePz4MYcOHWLmzJnkzJkztuMTERFJ9lxdYe5cM1kyDHj3XRg2zPxbRETiR4wSp7t379K/f3/y58/P0aNHWb9+PcuXL6dYsWJxFZ+IiIgAjo7w3XdmwgQwfDi89x4EB1salohIshHtxGns2LHkzZuXFStWMG/ePHbs2EHVqlXjMjYRERF5gs0GQ4eaCZTNBhMnQtu2EBhodWQiIklftM9xGjBgAO7u7uTPn5+ZM2cyc+bMCNstXrw41oITERGR8N59F9KlM897WrAAbt2CxYvN86FERCRuRDtx6tChAzabLS5jERERkWh64w1Im/a/inu1a8PKlWYlPhERiX3RTpxmzJgRh2GIiIhITHl7w/r1ZpnyPXugalX4/XdzDSgREYldz1VVT0RERBKGChVg61bInh1OnIDKleH4caujEhFJepQ4iYiIJHJFisCOHVC4MFy6BFWqwO7dVkclIpK0KHESERFJAnLkMEeeypc3i0XUqmVO2xMRkdihxElERCSJSJ/ePOfJ2xsePoTGjWHOHKujEhFJGpQ4iYiIJCEpUsDy5WbVvcePoV07GDfO6qhERBI/JU4iIiJJjIuLOdLUp4+5/dFH0LcvhIRYGpaISKKmxElERCQJcnCAr76CL780t8ePN0efAgKsjUtEJLFS4iQiIpJE2WzmaNPPP4OTE8ybZ6755OdndWQiIomPEicREZEkrm1bWLnSPP9p/XqoXh18fa2OSkQkcVHiJCIikgx4e8OmTZAxIxw6BJUqwalTVkclIpJ4KHESERFJJsqUMRfKzZcPzp6FypVhzx6roxIRSRyUOImIiCQj+fKZyVOZMnDjBtSsCatXWx2ViEjCp8RJREQkmcmY0Zy2F7pQbpMmMHOm1VGJiCRsSpxERESSodCFctu1g+Bg6NQJvvgCDMPqyEREEiYlTiIiIsmUi4s50tSvn7k9cCC8/76ZSImISFhKnERERJIxBwcYM8ZcIBfg22/hzTfB39/auEREEholTiIiIkKfPuYCuc7OsHAhNGgAd+9aHZWISMKhxElEREQAeOMNWLMGUqY0i0dUrQqXL1sdlYhIwmB54jRx4kTy5MmDm5sbZcqUYevWrdG63fbt23FycqJUqVJxG6CIiEgyUqsWbNkCmTPDn3/CK6+Y/4qIJHeWJk4LFiygT58+DBo0iIMHD1K1alUaNGjAhQsXorzd3bt36dChA7Vr146nSEVERJKPUqVg504oXBguXYIqVWDDBqujEhGxlqWJ01dffUXXrl3p1q0bRYoUYcKECeTIkYNJkyZFebu3336bNm3aULFixXiKVEREJHnJnRu2bzen6/n5Qf36MHu21VGJiFjHyaoDBwYGsn//fgYMGBBmv7e3Nzt27Ij0dtOnT+f06dP8/PPPjBo16pnHCQgIICAgwL7t5+cHQFBQEEFBQc8ZfewJjSEhxCKxQ32a9KhPkyb167OlTAkrV0LXro4sXOhAhw5w9mwwAwaEYLNZHV146tOkSf2a9CSkPo1JDJYlTjdu3CA4OJhMmTKF2Z8pUyZ8fX0jvM1ff/3FgAED2Lp1K05O0Qt99OjRDB8+PNz+tWvX4uHhEfPA44iPj4/VIUgsU58mPerTpEn9+mxvvglBQUVZurQAQ4c6sm3bRXr0OIyjY8JcLVd9mjSpX5OehNCnDx8+jHZbyxKnULanfrIyDCPcPoDg4GDatGnD8OHDKViwYLTvf+DAgfTt29e+7efnR44cOfD29sbLy+v5A48lQUFB+Pj4ULduXZydna0OR2KB+jTpUZ8mTerXmGncGCZNCuaDDxzw8cmNo2NO5s4NJkUKqyP7j/o0aVK/Jj0JqU9DZ6NFh2WJU/r06XF0dAw3unTt2rVwo1AA9+7dY9++fRw8eJD33nsPgJCQEAzDwMnJibVr11KrVq1wt3N1dcXV1TXcfmdnZ8s76kkJLR55cerTpEd9mjSpX6Ovd2/IlcscgVqzxoE6dRxYsQKyZLE6srDUp0mT+jXpSQh9GpPjW1YcwsXFhTJlyoQbovPx8aFSpUrh2nt5efHnn39y6NAh+6VHjx4UKlSIQ4cOUaFChfgKXUREJNlq2hQ2boQMGeDAAahYEY4ftzoqEZG4Z+lUvb59+9K+fXvKli1LxYoVmTJlChcuXKBHjx6AOc3u8uXLzJo1CwcHB4oVKxbm9hkzZsTNzS3cfhEREYk7FSqY5cobNIC//oJKlWDZMqhWzerIRETijqWJU+vWrbl58yYjRozg6tWrFCtWjFWrVpErVy4Arl69+sw1nURERCT+5csHO3bAq6+aSVTdujBzJrzxhtWRiYjEDUvXcQLo2bMn586dIyAggP3791PtiZ+rZsyYwaZNmyK97bBhwzh06FDcBykiIiLhpE8P69dD8+YQGGie+zR2LBgJs9ieiMgLsTxxEhERkcTL3R1++QXef9/c7t8f3nsPgoOtjUtEJLYpcRIREZEX4ugIEybA+PFgs8HEidCsGdy/b3VkIiKxR4mTiIiIxIo+fWDhQnB1heXLzWIRV65YHZWISOxQ4iQiIiKxpkULs1x5+vRw8KBZge+PP6yOSkTkxSlxEhERkVhVsSLs3g2FC8OlS1ClCqxcaXVUIiIvRomTiIiIxLq8ec1y5bVqmec6vfoqfPut1VGJiDw/JU4iIiISJ9KkgdWroUsXCAmB3r3NiyruiUhipMRJRERE4oyLC/z0E4webW5/+y289poq7olI4qPESUREROKUzQYDBpjrPbm5wYoVULWqef6TiEhiocRJRERE4sXrr5sV9zJmhEOHzIp7Bw9aHZWISPQocRIREZF488orZsW9okXNNZ6qVDHXfBIRSeiUOImIiEi8yp0btm+HOnXg4UNo2hS+/hoMw+rIREQip8RJRERE4l3q1LBqFXTvbiZMffpAr17w+LHVkYmIREyJk4iIiFjC2Rl++AHGjjULSHz/PTRuDHfuWB2ZiEh4SpxERETEMjYbfPwxLFoEHh7w++/meVB//211ZCIiYSlxEhEREcs1bw7btkH27HDyJJQvDxs2WB2ViMh/lDiJiIhIglC6NOzZY5Ypv30b6tWDyZOtjkpExKTESURERBKMLFnMtZ7atDELRbzzjopGiEjCoMRJREREEhR3d/j5Z/jsM3P7u++gYUNzFEpExCpKnERERCTBsdngk09g8WKzaISPj1k04tQpqyMTkeRKiZOIiIgkWM2amYvl5shhJk0VKsD69VZHJSLJkRInERERSdBKlTKLRrzyirnGU716MHGi1VGJSHKjxElEREQSvMyZzaIR7dpBcDC8+y68956KRohI/FHiJCIiIomCmxvMmgWjR5vnQH3/PTRoALduWR2ZiCQHSpxEREQk0bDZYMAAs2iEpyesWwflysGff1odmYgkdUqcREREJNF57TXYsQPy5IEzZ6BiRVi82GZ1WCKShClxEhERkUSpRAnYuxdq14YHD+CNN5yYM6cwISFWRyYiSZESJxEREUm00qWDNWvggw/M7YULC9G8uSN371obl4gkPUqcREREJFFzcoKvvoJp0x7j7BzMqlUOVKgAJ09aHZmIJCVKnERERCRJaNfOYPTobWTPbnDyJJQvDytXWh2ViCQVSpxEREQkycif/w47dz6mShXw84MmTeCzz8AwrI5MRBI7JU4iIiKSpGTKBOvXQ48eZsI0eDC0agX371sdmYgkZkqcREREJMlxcYFJk+CHH8DZGRYtgkqVzNLlIiLPQ4mTiIiIJFlvvQUbN5qjUH/+CWXLmlX4RERiSomTiIiIJGmVK8P+/WaxiNu3oWFDGDkSrfckIjGixElERESSvGzZYPNmcwTKMODTT+HVV81ESkQkOpQ4iYiISLLg5mae8zRtGri6mqXKy5aFP/6wOjIRSQyUOImIiEiy0rkz7NgBuXObxSIqVoTZs62OSkQSOiVOIiIikuy8/DLs2wf168OjR9ChA7z7LgQGWh2ZiCRUSpxEREQkWUqXDlasMM93Apg4EapXh0uXrI1LRBImJU4iIiKSbDk6wvDhsHw5pE4Nu3ZBmTKwaZPVkYlIQqPESURERJK9xo3NqXslS8K1a1CnDvzvf2YFPhERUOIkIiIiAkC+fGbRiPbtITgYPv4YWrSAO3esjkxEEgIlTiIiIiL/8vCAmTPN851cXGDJkv8KSYhI8qbESUREROQJNhu88w5s3w558sDZs1C5Mnz/vabuiSRnSpxEREREIlC2LBw4AK+9ZpYpf+89aN0a/PysjkxErKDESURERCQSqVPD4sUwfjw4OcHChWbVvT/+sDoyEYlvSpxEREREomCzQZ8+sHUr5MwJf/8NFSrAjz9q6p5IcqLESURERCQaXnkFDh40S5cHBMBbb5kV+O7ftzoyEYkPSpxEREREoiltWli2DMaMMRfPnTMHypWDI0esjkxE4poSJxEREZEYcHCAfv1g0ybIlg1OnIDy5WHKFE3dE0nKlDiJiIiIPIcqVcype/Xrw6NH8Pbb0KoV3L5tdWQiEheUOImIiIg8pwwZYOVK+N//wNkZFi2CUqXMNaBEJGlR4iQiIiLyAhwc4MMPYccOyJ8fLlyAatVg5EgIDrY6OhGJLUqcRERERGJB6IK57dpBSAh8+inUrg2XLlkdmYjEBiVOIiIiIrEkZUqYPRtmzYIUKWDzZihZEn77zerIRORFKXESERERiWXt25ujT2XKwK1b0LQp9OoF/v5WRyYiz0uJk4iIiEgcKFDAPO+pb19z+7vvoEIFOHbM2rhE5PkocRIRERGJIy4uMG4crFplVuA7fNgchfr2W635JJLYKHESERERiWMNGphJU7165nS93r3N9Z+uXLE6MhGJLiVOIiIiIvEgc2ZYvdocbXJzg7VroXhx+PVXqyMTkehQ4iQiIiIST2w2eO89s3BE6dJm4YiWLaFzZ/Dzszo6EYmKEicRERGReFakCOzaBQMHmsnUjBlm2fJt26yOTEQio8RJRERExAIuLvD55+ZaT7lywblzUL06DBoEgYFWRyciT1PiJCIiImKhqlXNwhEdO0JIiJlMVaoEx49bHZmIPEmJk4iIiIjFvLzM6XoLF0KaNLB/v3kO1JdfQnCw1dGJCChxEhEREUkwWraEP/80y5cHBEC/fuaI1KlTVkcmIkqcRERERBKQbNlg5UqYOhVSpoSdO83CERMmmFP5RMQaSpxEREREEhibDbp0gSNHoG5dc9HcDz6AGjXg9GmroxNJnpQ4iYiIiCRQOXPC77/D5Mng6Qlbt0KJEvD99xp9EolvSpxEREREEjCbDd5+2zz3qWZNePjQXES3Th2zhLmIxA8lTiIiIiKJQJ48sG4dfPcdeHjAxo1QvLi5rdEnkbinxElEREQkkXBwgHffNdd9qloV7t+HXr3Mv7Xuk0jcUuIkIiIiksjkywebNpnnOqVIATt2QKlSMHIkBAZaHZ1I0qTESURERCQRcnCAnj3h6FFo2NBMmD79FMqWhT17rI5OJOlR4iQiIiKSiOXMCStWwJw5kD69WUSiYkXo2xcePLA6OpGkQ4mTiIiISCJns0GbNuZ5Tu3amcUixo83i0esW2d1dCJJgxInERERkSQifXqYPRtWrTJHos6eNRfQ7dABrl2zOjqRxE2Jk4iIiEgS06ABHDliVtyz2cxkqlAhmDJFpctFnpcSJxEREZEkKGVK+OYb2LULSpeGO3fMhXQrV4Y//rA6OpHER4mTiIiISBJWvrxZZW/CBDOZ2rULypSBDz+Ee/esjk4k8VDiJCIiIpLEOTnB+++bxSNefx2Cg+Grr6BoUViyBAzD6ghFEj7LE6eJEyeSJ08e3NzcKFOmDFu3bo207eLFi6lbty4ZMmTAy8uLihUr8vvvv8djtCIiIiKJV7Zs8MsvZvGIPHng0iVo3hyaNDELSYhI5CxNnBYsWECfPn0YNGgQBw8epGrVqjRo0IALFy5E2H7Lli3UrVuXVatWsX//fmrWrEmTJk04ePBgPEcuIiIikng1aGAunDtoEDg7w8qVUKSIuYDuw4dWRyeSMFmaOH311Vd07dqVbt26UaRIESZMmECOHDmYNGlShO0nTJhAv379KFeuHAUKFODzzz+nQIECLF++PJ4jFxEREUnc3N1h1CizUEStWhAQACNHQuHC5qiUpu+JhOVk1YEDAwPZv38/AwYMCLPf29ubHTt2ROs+QkJCuHfvHmnTpo20TUBAAAEBAfZtPz8/AIKCgggKCnqOyGNXaAwJIRaJHerTpEd9mjSpX5Me9enzyZ8fVq+GpUtt9OvnyPnzNlq3hokTQ/jqq2CKF7c2PvVr0pOQ+jQmMdgMw5rfE65cuUK2bNnYvn07lSpVsu///PPPmTlzJidPnnzmfXz55Zd88cUXHD9+nIwZM0bYZtiwYQwfPjzc/rlz5+Lh4fH8D0BEREQkiQkIcGTJkvwsXlyAwEBHHBwM6tc/y5tvniBlSuu/5IrEtocPH9KmTRvu3r2Ll5dXlG0tG3EKZbPZwmwbhhFuX0TmzZvHsGHDWLZsWaRJE8DAgQPp27evfdvPz48cOXLg7e39zCcnPgQFBeHj40PdunVxdna2OhyJBerTpEd9mjSpX5Me9WnsaNYMRo4MoV8/G0uWOLBqVV52787DyJHBdO5s4OgYv/GoX5OehNSnobPRosOyxCl9+vQ4Ojri6+sbZv+1a9fIlClTlLddsGABXbt2ZeHChdSpUyfKtq6urri6uobb7+zsbHlHPSmhxSMvTn2a9KhPkyb1a9KjPn1x+fPD4sWwfj307g3Hjtno2dOJH36AceOgdu34j0n9mvQkhD6NyfEtKw7h4uJCmTJl8PHxCbPfx8cnzNS9p82bN49OnToxd+5cGjVqFNdhioiIiCRbtWvDoUPw9deQKpVZSKJOHWjc2FwTSiQ5sbSqXt++ffnpp5+YNm0ax48f54MPPuDChQv06NEDMKfZdejQwd5+3rx5dOjQgXHjxvHKK6/g6+uLr68vd+/eteohiIiIiCRpzs7mqNPff0OvXuZiuitXQvHi0LMnXLtmdYQi8cPSxKl169ZMmDCBESNGUKpUKbZs2cKqVavIlSsXAFevXg2zptMPP/zA48ePeffdd8mSJYv98v7771v1EERERESShfTp4ZtvzPWfmjaF4GCYNMmc1vfFF/DokdURisQty4tD9OzZk549e0Z43YwZM8Jsb9q0Ke4DEhEREZFIFSwIS5fCpk3w4Ydw4AAMHGgmUZ9/Dm++CQ6W/jQvEjf0shYRERGRGKtRA/buhVmzIHt2uHAB2rWDl1+GVau0gK4kPUqcREREROS5ODhA+/Zw8iSMGgVeXmYBiUaNoHp12L7d6ghFYo8SJxERERF5IR4eMGgQnDkDH30Ebm6wdStUqQJNmsDhw1ZHKPLilDiJiIiISKxIlw6+/BL++gu6dwdHR1ixAkqVMqfxnTljdYQiz0+Jk4iIiIjEquzZYcoUOHYMWrUyz3eaMwcKFYIePczzoUQSGyVOIiIiIhInChaEBQtg/36oVw8eP4YffjBLmPfoAefPWx2hSPQpcRIRERGROPXyy7BmDWzZArVqQVCQmUAVKKAEShIPJU4iIiIiEi+qVoX1680EqnZtJVCSuChxEhEREZF4VbUqrFsXcQL11ltw+rTVEYqEp8RJRERERCwRUQL144/muVFvvgmHDlkdoch/lDiJiIiIiKVCE6itW6FhQwgJgfnzoXRpaNLEkSNH0mEYVkcpyZ0SJxERERFJEKpUgZUrzZGmNm3AwQF+/92BwYOrUL26I7/9ZiZVIlZQ4iQiIiIiCUrJkua6T3/9BW+/HYyzczC7djnQtCkULw7TpoG/v9VRSnKjxElEREREEqS8eeHbb0P48Ucf+vULxsvLXFS3a1fImROGDgVfX6ujlORCiZOIiIiIJGipUwcwalQIFy7A2LGQIwdcvw4jRkCuXNCpkwpJSNxT4iQiIiIiiUKqVPDxx3DmDPzyC1SqBIGBMHOmWUiiRg1YuhSCg62OVJIiJU4iIiIikqg4OcHrr8P27bB7t1m63MkJNm+GZs3M9aDGjIFr16yOVJISJU4iIiIikmiVLw9z58LZszBgAKRJ89/f2bOb1fm2bEHlzOWFKXESERERkUQve3YYPRouXTKr7pUvby6oO28eVK8OxYrBt9/C3btWRyqJlRInEREREUkyPDygc2dzCt++fdCtm7nv2DHo3RuyZoUuXczFdjUKJTGhxElEREREkqQyZeDHH+HKFXO0qWhRePgQpk+HatWgYEH47DO4eNHqSCUxUOIkIiIiIklaqlTw3ntw5Ig50tS5M3h6wt9/w+DBZknzevVg/nwtrCuRU+IkIiIiIsmCzQZVqpjnQPn6/jfyZBiwdq1ZnS9LFnjrLdi0SWXNJSwlTiIiIiKS7KRIYS6cu3nzfyNPOXLAnTvm9L6aNSFnTujb1zxXSudDiRInEREREUnW8uWDkSPNMubr1kHXrub0vitXYPx4KFfOPB/q00/h+HGroxWrKHESEREREQEcHaF2bfjpJ/jnH1i6FFq3Bnd3c1Rq5EizwMRLL8GQIXDwoEaikhMlTiIiIiIiT3F1haZNzYIR167Bzz9Do0bg5GSWNh81Cl5+GfLkMafzbd2qc6KSOiVOIiIiIiJRSJEC2raFFSvg+nWYPRuaNzdHos6fN6fzVatmrhHVvbs5UnXvntVRS2xT4iQiIiIiEk2pU0O7dvDrr3DjBixeDO3bm/uvXTOn+TVrBunSQZ06MG6ceV6UpvQlfkqcRERERESeg4eHmSTNmmWeE/X779Crl1lsIigI1q+Hjz4yz4vKmxfefRd++82s3CeJjxInEREREZEX5OIC3t7wzTdmIYlTp2DCBHOfqyucOwcTJ5rnTaVLB+XLw4AB5vpRDx5YHb1EhxInEREREZFYVqAAvP++OQp18yYsXw7vvAOFCkFICOzdC2PGQL16kCYNVK0KQ4ea5dB1flTC5GR1ACIiIiIiSZmnJzRubF4ALl+GjRthwwZzOt+FC7Btm3kBcHCA4sWhUiWoWNH8N29esNmsewyixElEREREJF5ly2YWmGjXziwacfasmURt3Ag7dpjT+v74w7xMmmTeJmNGM4kqU8Ysg/7yy5Ali6UPI9lR4iQiIiIiYhGbzRxNypsXunUz9125Ajt3mpcdO2D/frNi37Jl5iVU5sxQuvR/iVSpUpA7tzliJbFPiZOIiIiISAKSNSu0aGFeAPz94cAB2LULDh40/z5xAnx9YfVq8xLK3d08j6poUfNSpIj5b7584OxszeNJKv7f3v1HRVXnfQB/z+/hl6OmCPgDsHxiEdEAf6Ce1LUkhd3cNSofbWU7uUtJ6mm3Nt2zoe0WZrvbUydlW+qoHX2WjSVdSlpRV2h7wDCURHCJVrBWMMzkR/wcmM/zx8TVEYaBFhhmeL/Ouecw975nuONn7pf7OffOVzZORERERETDmNFo/Z7T/PnX1zU3A2fPWpuoM2esV6XKyoCWFqC42LrcSKe7fmVr6lQgONj251GjhvIduSY2TkRERERELsbTE5g3z7p06ey0fl+qrOz6cv68dWlqAsrLrUtPRo+2fvcqIMC63PjzhAnWKdRvucU6A6BGMyRvcdgZsY1TU3sTNO3dq65Ra2DUGm1y9qhVanjoPL5VttncDBGB2WxGa2crmtqboBPr9VOVSgVPnWe3bE9uzraYW2ARi9398NJ7fatsa0crOi2dA5L11HlC9c20MG0dbeiwdAxI1kPnAbXKelNve2c7zJ3mAckatUZo1Jo+Z7uYO81ol3a7WYPWAK1aez3b2bdsh6UDbR1tdrN6jR46ja7f2U5LJ1o7Wu1mdRod9Bp9v7MWsaDF3DIgWa1aC4PWAAAQETSbmwck6+i4v/E4NaqMQzpG9IRjxLfL3nzcN7c3dxt/7WUHcozoyvbnuOcY0besdF4/DoZyjPi2WY4RfcvefK7k7ucR/+kY4T/Fuiy953pWpzag5pIWn34KfHqhAxWVbaiqBCqrgItV1unS65qAuk+A0vN6wPLNmKjuADQ3jREqYLQJGDMWuGW0HmNNOnh7Ax5enfDwboWnl3UWQW8vwOhhbbK0GsCg08Go00OjsR7Lp0tGY0ZkEyb4dr9/cCjPI3o77m6mEntHkptqaGiAyWQCngZg7L59xbQVOPzfh5XHXs972R1MFwUuQm5CrvJ4/Ivj8WXzlz1mowKicGr9KeVx0P8E4WL9xR6zoeNDUfpYqfJ4+u7pKLtS1mM20BSIqs1VyuPZabPxUfVHPWbHeY7DlSevKI8X712MvIt5PWY9dZ5o2nr9gxT7v7HIrsjuMQsAknz9YxSfEY+/lP3FbvbrLV8rA2TCoQTs+3if3Wztz2sx3ms8AGDD4Q3Y/dFuu9nKTZUIGh0EAHgy50n8tuC3drPnHj2H6b7TAQDbcrdhe952u9nCRwoxe+JsAMCL//cinjr2lN3siXUnsGDiAmRnZ+Oi70VsytlkN/vu6ncR+1+xAIC9xXvx47/+2G72rfveQvz0eABARmkG7v/L/Xaze+7dg4RZCQCAw58cRtyf4uxmX13+KjbM2QAAyK3KxZJ9S+xmd961E08ueBIAcOrSKcx5fY7dbPKiZGxbvA0AUFpbirDUMLvZn0f/HC8uexEAUFVXheCXg+1mH4t6DLtidwEArjRdge9vfe1m181ch70r9wKwnox4p3jbzd4Xeh8y4jOUx6rt9ud75RhhxTHiuv6OEYuDFgMAdhXuQtJ7SXazHCOs+jNGJEYk4h7LPVixYgXq2us4RnyDYwTHiP6MEY+M24OpDQmorgaKGg+jINj+GIHDrwKnrGMEgnKBBPtjBHJ2AvnWMQIBp4CfDJPziFYAO4D6+nqMcnC/4oi94kRERERERLYWLAASZll/PvwJEPcn+9mf/ASYv8F6G+DZBuA1+xewERICTPEGOjqAax4WnBnQvR4aI/aKU/WV6h67SmfcqnfkyBHExMRAp+Otev9JdrhcYrd0WpCdnY27Y+6GqO0fXrwNp/9ZZ96q13WcGg28Va+nrCuOEc2tzd3GX3vZ4XQbjqPsSB4jpFNwPOc4VqxYAa1Wy1v1vkV2OI4RN58ruft5xEgYI1rbWvHXw3/tcfy9OTvY5xENDQ0IGB/AK0698dJ72RykveX685p91TVImVVmGDVGeOm9evzg3JjtixsH1YHM3vhHYCCzBq0BBhgGPKvX6JWDaKizlk7rHxGdRme3pjfTaXTKwOOIVq2FVt+3Q7c/WY1a0+fPcH+yapV6ULIqlWpQskD3Y9nmONXqes3253V705/jnmNE/7N6jR4qvcrh+NuVHYzxpD/HPceIvmXN5usnpEM5RjgjO5LGiN7OldzxPKKLu48RfRl/gcE/j+jU22/ou71+n5NEREREREQjFBsnIiIiIiIiB9g4EREREREROcDGiYiIiIiIyAE2TkRERERERA6wcSIiIiIiInKAjRMREREREZEDbJyIiIiIiIgcYONERERERETkABsnIiIiIiIiB9g4EREREREROcDGiYiIiIiIyAE2TkRERERERA6wcSIiIiIiInKAjRMREREREZEDbJyIiIiIiIgcYONERERERETkgNbZOzDURAQA0NDQ4OQ9sTKbzWhubkZDQwN0Op2zd4cGAGvqflhT98S6uh/W1D2xru5nONW0qyfo6hF6M+Iap8bGRgDA5MmTnbwnREREREQ0HDQ2NsJkMvWaUUlf2is3YrFYUF1dDR8fH6hUKmfvDhoaGjB58mR8/vnnGDVqlLN3hwYAa+p+WFP3xLq6H9bUPbGu7mc41VRE0NjYiICAAKjVvX+LacRdcVKr1Zg0aZKzd6ObUaNGOf2DQwOLNXU/rKl7Yl3dD2vqnlhX9zNcauroSlMXTg5BRERERETkABsnIiIiIiIiB9g4OZnBYEBycjIMBoOzd4UGCGvqflhT98S6uh/W1D2xru7HVWs64iaHICIiIiIi6i9ecSIiIiIiInKAjRMREREREZEDbJyIiIiIiIgcYONERERERETkABsnJ9q9ezeCg4NhNBoRGRmJf/zjH87eJfrG+++/j+9973sICAiASqXCoUOHbLaLCLZt24aAgAB4eHhg8eLFKC0ttcm0tbXh8ccfx7hx4+Dl5YXvf//7+Pe//22TuXbtGh566CGYTCaYTCY89NBDqKurG+R3NzKlpKRg9uzZ8PHxga+vL1auXIny8nKbDOvqWlJTUxEeHq78B4rR0dF47733lO2sp+tLSUmBSqXC5s2blXWsq+vZtm0bVCqVzeLn56dsZ01d06VLl7B27Vrccsst8PT0xKxZs1BUVKRsd8u6CjlFenq66HQ6SUtLk7KyMtm0aZN4eXnJxYsXnb1rJCLZ2dnyy1/+UjIzMwWAHDx40Gb7jh07xMfHRzIzM6WkpEQeeOAB8ff3l4aGBiWTmJgoEydOlKNHj8rp06dlyZIlMnPmTOno6FAy99xzj4SFhUl+fr7k5+dLWFiYxMXFDdXbHFFiYmJkz549cu7cOSkuLpbY2FiZMmWKfP3110qGdXUtWVlZcvjwYSkvL5fy8nLZunWr6HQ6OXfunIiwnq6usLBQgoKCJDw8XDZt2qSsZ11dT3JyskyfPl1qamqUpba2VtnOmrqer776SgIDAyUhIUE+/PBDqayslGPHjsmnn36qZNyxrmycnGTOnDmSmJhosy4kJESefvppJ+0R2XNz42SxWMTPz0927NihrGttbRWTySR/+MMfRESkrq5OdDqdpKenK5lLly6JWq2Wv/3tbyIiUlZWJgDk5MmTSqagoEAAyD//+c9BfldUW1srACQvL09EWFd3MWbMGHn99ddZTxfX2Ngo06ZNk6NHj8qiRYuUxol1dU3Jyckyc+bMHrexpq7pF7/4hSxcuNDudnetK2/Vc4L29nYUFRVh2bJlNuuXLVuG/Px8J+0V9VVlZSUuX75sUz+DwYBFixYp9SsqKoLZbLbJBAQEICwsTMkUFBTAZDJh7ty5SmbevHkwmUz8HAyB+vp6AMDYsWMBsK6urrOzE+np6WhqakJ0dDTr6eI2bNiA2NhY3HXXXTbrWVfXVVFRgYCAAAQHB+PBBx/EhQsXALCmriorKwtRUVGIj4+Hr68v7rjjDqSlpSnb3bWubJyc4Msvv0RnZycmTJhgs37ChAm4fPmyk/aK+qqrRr3V7/Lly9Dr9RgzZkyvGV9f326v7+vry8/BIBMRPPHEE1i4cCHCwsIAsK6uqqSkBN7e3jAYDEhMTMTBgwcRGhrKerqw9PR0nD59GikpKd22sa6uae7cuXjzzTdx5MgRpKWl4fLly5g/fz6uXr3KmrqoCxcuIDU1FdOmTcORI0eQmJiIjRs34s033wTgvseqdsh/IylUKpXNYxHpto6Gr29Tv5szPeX5ORh8SUlJOHv2LD744INu21hX13L77bejuLgYdXV1yMzMxLp165CXl6dsZz1dy+eff45NmzYhJycHRqPRbo51dS3Lly9Xfp4xYwaio6Nx6623Yt++fZg3bx4A1tTVWCwWREVF4fnnnwcA3HHHHSgtLUVqaip+9KMfKTl3qyuvODnBuHHjoNFounXKtbW13TpzGn66ZgLqrX5+fn5ob2/HtWvXes188cUX3V7/ypUr/BwMoscffxxZWVk4ceIEJk2apKxnXV2TXq/HbbfdhqioKKSkpGDmzJl4+eWXWU8XVVRUhNraWkRGRkKr1UKr1SIvLw+vvPIKtFqt8m/Ouro2Ly8vzJgxAxUVFTxWXZS/vz9CQ0Nt1n3nO9/BZ599BsB9/6aycXICvV6PyMhIHD161Gb90aNHMX/+fCftFfVVcHAw/Pz8bOrX3t6OvLw8pX6RkZHQ6XQ2mZqaGpw7d07JREdHo76+HoWFhUrmww8/RH19PT8Hg0BEkJSUhLfffht///vfERwcbLOddXUPIoK2tjbW00UtXboUJSUlKC4uVpaoqCisWbMGxcXFmDp1KuvqBtra2nD+/Hn4+/vzWHVRCxYs6PZfenzyyScIDAwE4MZ/U4dyJgq6rms68jfeeEPKyspk8+bN4uXlJVVVVc7eNRLrjE5nzpyRM2fOCAD5/e9/L2fOnFGmi9+xY4eYTCZ5++23paSkRFavXt3jFJuTJk2SY8eOyenTp+W73/1uj1NshoeHS0FBgRQUFMiMGTM4deogefTRR8VkMklubq7NlLjNzc1KhnV1LVu2bJH3339fKisr5ezZs7J161ZRq9WSk5MjIqynu7hxVj0R1tUV/exnP5Pc3Fy5cOGCnDx5UuLi4sTHx0c552FNXU9hYaFotVp57rnnpKKiQg4cOCCenp6yf/9+JeOOdWXj5ES7du2SwMBA0ev1EhERoUyLTM534sQJAdBtWbdunYhYp9lMTk4WPz8/MRgMcuedd0pJSYnNa7S0tEhSUpKMHTtWPDw8JC4uTj777DObzNWrV2XNmjXi4+MjPj4+smbNGrl27doQvcuRpad6ApA9e/YoGdbVtTz88MPKGDp+/HhZunSp0jSJsJ7u4ubGiXV1PV3/f49Op5OAgAD54Q9/KKWlpcp21tQ1vfPOOxIWFiYGg0FCQkLkj3/8o812d6yrSkRk6K9zERERERERuQ5+x4mIiIiIiMgBNk5EREREREQOsHEiIiIiIiJygI0TERERERGRA2yciIiIiIiIHGDjRERERERE5AAbJyIiIiIiIgfYOBERERERETnAxomIiIiIiMgBNk5ERORyamtr8dOf/hRTpkyBwWCAn58fYmJiUFBQAABQqVQ4dOiQc3eSiIjcitbZO0BERNRfq1atgtlsxr59+zB16lR88cUXOH78OL766itn7xoREbkpXnEiIiKXUldXhw8++AAvvPAClixZgsDAQMyZMwdbtmxBbGwsgoKCAAA/+MEPoFKplMcA8M477yAyMhJGoxFTp07F9u3b0dHRoWxXqVRITU3F8uXL4eHhgeDgYGRkZCjb29vbkZSUBH9/fxiNRgQFBSElJWWo3joRETkRGyciInIp3t7e8Pb2xqFDh9DW1tZt+6lTpwAAe/bsQU1NjfL4yJEjWLt2LTZu3IiysjK89tpr2Lt3L5577jmb5//qV7/CqlWr8PHHH2Pt2rVYvXo1zp8/DwB45ZVXkJWVhbfeegvl5eXYv3+/TWNGRETuSyUi4uydICIi6o/MzEysX78eLS0tiIiIwKJFi/Dggw8iPDwcgPXK0cGDB7Fy5UrlOXfeeSeWL1+OLVu2KOv279+Pp556CtXV1crzEhMTkZqaqmTmzZuHiIgI7N69Gxs3bkRpaSmOHTsGlUo1NG+WiIiGBV5xIiIil7Nq1SpUV1cjKysLMTExyM3NRUREBPbu3Wv3OUVFRXj22WeVK1be3t5Yv349ampq0NzcrOSio6NtnhcdHa1ccUpISEBxcTFuv/12bNy4ETk5OYPy/oiIaPhh40RERC7JaDTi7rvvxjPPPIP8/HwkJCQgOTnZbt5isWD79u0oLi5WlpKSElRUVMBoNPb6u7quLkVERKCyshK//vWv0dLSgvvvvx/33XffgL4vIiIantg4ERGRWwgNDUVTUxMAQKfTobOz02Z7REQEysvLcdttt3Vb1Orrfw5Pnjxp87yTJ08iJCREeTxq1Cg88MADSEtLw5///GdkZmZyNj8iohGA05ETEZFLuXr1KuLj4/Hwww8jPDwcPj4++Oijj7Bz507ce++9AICgoCAcP34cCxYsgMFgwJgxY/DMM88gLi4OkydPRnx8PNRqNc6ePYuSkhL85je/UV4/IyMDUVFRWLhwIQ4cOIDCwkK88cYbAICXXnoJ/v7+mDVrFtRqNTIyMuDn54fRo0c745+CiIiGEBsnIiJyKd7e3pg7dy5eeukl/Otf/4LZbMbkyZOxfv16bN26FQDwu9/9Dk888QTS0tIwceJEVFVVISYmBu+++y6effZZ7Ny5EzqdDiEhIXjkkUdsXn/79u1IT0/HY489Bj8/Pxw4cAChoaHK737hhRdQUVEBjUaD2bNnIzs72+aKFRERuSfOqkdERPSNnmbjIyIiAvgdJyIiIiIiIofYOBERERERETnA7zgRERF9g3evExGRPbziRERERERE5AAbJyIiIiIiIgfYOBERERERETnAxomIiIiIiMgBNk5EREREREQOsHEiIiIiIiJygI0TERERERGRA2yciIiIiIiIHPh/UIpgBmLKxEwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T_max = 6000  # Total steps\n",
    "eta_max = 1.0  # Initial noise stddev\n",
    "eta_min = 0.1  # Minimum noise stddev\n",
    "\n",
    "t = np.linspace(0, T_max, 1000)  # Sample points\n",
    "value = eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(t * np.pi / T_max))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(t, value, 'b-', label='Cosine Annealing (stddev)')\n",
    "plt.axhline(y=eta_max, color='r', linestyle='--', label='Initial (1.0)')\n",
    "plt.axhline(y=eta_min, color='g', linestyle='--', label='Minimum (0.1)')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Noise StdDev')\n",
    "plt.title('Cosine Annealing Curve for Noise (stddev)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspaces/RL_Agents/src/app', '/opt/conda/envs/rl_env/lib/python310.zip', '/opt/conda/envs/rl_env/lib/python3.10', '/opt/conda/envs/rl_env/lib/python3.10/lib-dynload', '', '/opt/conda/envs/rl_env/lib/python3.10/site-packages']\n",
      "MCP found at: /opt/conda/envs/rl_env/lib/python3.10/site-packages/mcp/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)  # Shows all directories Python checks for imports\n",
    "\n",
    "# Try to find mcp specifically\n",
    "try:\n",
    "    import mcp\n",
    "    print(f\"MCP found at: {mcp.__file__}\")\n",
    "except ImportError:\n",
    "    print(\"MCP not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CallToolRequest', 'ClientCapabilities', 'ClientNotification', 'ClientRequest', 'ClientResult', 'ClientSession', 'CompleteRequest', 'CreateMessageRequest', 'CreateMessageResult', 'ErrorData', 'GetPromptRequest', 'GetPromptResult', 'Implementation', 'IncludeContext', 'InitializeRequest', 'InitializeResult', 'InitializedNotification', 'JSONRPCError', 'JSONRPCRequest', 'JSONRPCResponse', 'ListPromptsRequest', 'ListPromptsResult', 'ListResourcesRequest', 'ListResourcesResult', 'ListToolsResult', 'LoggingLevel', 'LoggingMessageNotification', 'McpError', 'Notification', 'PingRequest', 'ProgressNotification', 'PromptsCapability', 'ReadResourceRequest', 'ReadResourceResult', 'Resource', 'ResourceUpdatedNotification', 'ResourcesCapability', 'RootsCapability', 'SamplingMessage', 'SamplingRole', 'ServerCapabilities', 'ServerNotification', 'ServerRequest', 'ServerResult', 'ServerSession', 'SetLevelRequest', 'StdioServerParameters', 'StopReason', 'SubscribeRequest', 'Tool', 'ToolsCapability', 'UnsubscribeRequest', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'client', 'server', 'shared', 'stdio_client', 'stdio_server', 'types']\n"
     ]
    }
   ],
   "source": [
    "import mcp\n",
    "print(dir(mcp))  # This will show all available attributes/modules in mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
