{"method": "grid", "project": "PPO-Test", "name": "TEst", "metric": {"name": "episode_reward", "goal": "maximize"}, "parameters": {"env": {"parameters": {"id": {"value": "Reacher-v5"}}}, "model_type": {"value": "PPO"}, "PPO": {"parameters": {"PPO_policy_learning_rate_constant": {"values": [1, 2, 3]}, "PPO_policy_learning_rate_exponent": {"values": [-4, -5]}, "PPO_value_learning_rate_constant": {"values": [1, 2, 3]}, "PPO_value_learning_rate_exponent": {"values": [-4, -5]}, "PPO_distribution": {"values": ["beta", "normal"]}, "PPO_discount": {"values": [0.99]}, "PPO_advantage": {"values": [0.95]}, "PPO_policy_clip": {"values": [0.1, 0.2, 0.3]}, "PPO_policy_grad_clip": {"values": [0.5, 1, "infinity"]}, "PPO_entropy": {"values": [0.001, 0.005, 0.01]}, "PPO_normalize_advantage": {"values": ["True"]}, "PPO_normalize_values": {"values": ["True", "False"]}, "PPO_normalize_values_clip": {"values": [1, 10, "infinity"]}, "PPO_device": {"value": "cuda"}, "PPO_policy_num_layers": {"value": 2}, "PPO_policy_activation": {"values": ["tanh"]}, "PPO_policy_hidden_kernel_initializer": {"values": ["default", "xavier_uniform", "kaiming_uniform"]}, "PPO_policy_output_kernel_initializer": {"values": ["default", "xavier_uniform", "kaiming_uniform"]}, "PPO_policy_optimizer": {"values": ["Adam"]}, "PPO_policy_optimizer_Adam_options": {"parameters": {"Adam_weight_decay": {"values": [0, 0.1]}}}, "PPO_value_num_layers": {"value": 2}, "PPO_value_activation": {"values": ["tanh"]}, "PPO_value_hidden_kernel_initializer": {"values": ["default", "xavier_uniform", "kaiming_uniform"]}, "PPO_value_output_kernel_initializer": {"values": ["default", "xavier_uniform", "kaiming_uniform"]}, "PPO_value_optimizer": {"values": ["Adam"]}, "PPO_value_optimizer_Adam_options": {"parameters": {"Adam_weight_decay": {"values": [0, 0.1]}}}, "PPO_policy_hidden_kernel_xavier_uniform": {"parameters": {"xavier_uniform_gain": {"values": [1, 2]}}}, "PPO_policy_hidden_kernel_kaiming_uniform": {"parameters": {"kaiming_uniform_mode": {"values": ["fan_in", "fan_out"]}}}, "PPO_policy_output_kernel_xavier_uniform": {"parameters": {"xavier_uniform_gain": {"values": [1, 2]}}}, "PPO_policy_output_kernel_kaiming_uniform": {"parameters": {"kaiming_uniform_mode": {"values": ["fan_in", "fan_out"]}}}, "PPO_value_hidden_kernel_xavier_uniform": {"parameters": {"xavier_uniform_gain": {"values": [1, 2]}}}, "PPO_value_hidden_kernel_kaiming_uniform": {"parameters": {"kaiming_uniform_mode": {"values": ["fan_in", "fan_out"]}}}, "PPO_value_output_kernel_xavier_uniform": {"parameters": {"xavier_uniform_gain": {"values": [1, 2]}}}, "PPO_value_output_kernel_kaiming_uniform": {"parameters": {"kaiming_uniform_mode": {"values": ["fan_in", "fan_out"]}}}, "policy_units_layer_1_PPO": {"values": [64, 128]}, "policy_units_layer_2_PPO": {"values": [64, 128]}, "value_units_layer_1_PPO": {"values": [64, 128]}, "value_units_layer_2_PPO": {"values": [64, 128]}, "PPO_save_dir": {"value": "ppo_sweep_test"}, "PPO_num_timesteps": {"value": 100000}, "PPO_trajectory_length": {"value": 2000}, "PPO_batch_size": {"value": 64}, "PPO_learning_epochs": {"value": 8}, "PPO_num_envs": {"value": 1}, "PPO_seed": {"value": 42}}}}}