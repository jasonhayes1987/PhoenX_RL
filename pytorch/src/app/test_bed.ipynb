{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch_utils\n",
    "from torch import distributions\n",
    "\n",
    "import gymnasium as gym\n",
    "import gymnasium_robotics as gym_robo\n",
    "import models\n",
    "import cnn_models\n",
    "import rl_agents\n",
    "import rl_callbacks\n",
    "import helper\n",
    "import gym_helper\n",
    "import wandb_support\n",
    "import wandb\n",
    "import gym_helper\n",
    "\n",
    "# from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.MjModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_robo.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Returns the default device for computations, GPU if available, otherwise CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_robo.register_robotics_envs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.registration.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key='758ac5ba01e12a3df504d2db2fec8ba4f391f7e6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2', max_episode_steps=100, render_mode='rgb_array')\n",
    "env = gym.wrappers.RecordVideo(env, 'test/', episode_trigger=lambda i: i%1==0)\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "    while not done:\n",
    "        obs, r, term, trunc, dict = env.step(env.action_space.sample())\n",
    "        if term or trunc:\n",
    "            done = True\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v2\")\n",
    "env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "\n",
    "# The following always has to hold:\n",
    "assert reward == env.compute_reward(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n",
    "assert truncated == env.compute_truncated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n",
    "assert terminated == env.compute_terminated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.compute_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(env, \"distance_threshold\"):\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env.get_wrapper_attr(\"distance_threshold\"):\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(env))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.01}, learning_rate=0.001, normalize_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.target_actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers,\n",
    "                            optimizer='Adam', optimizer_params={'weight_decay':0.01}, learning_rate=0.002, normalize_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 100000)\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.99,\n",
    "                            tau=0.005,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.target_critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.train(100, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [\n",
    "    (128, 'relu', \"kaiming normal\"),\n",
    "    (256, 'relu', \"kaiming normal\"),\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = models.PolicyModel(env=env, dense_layers=dense_layers, optimizer='Adam', learning_rate=0.001,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in policy_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = models.ValueModel(env, dense_layers=dense_layers, optimizer='Adam', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in value_model.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = rl_agents.ActorCritic(env,\n",
    "                                     policy_model,\n",
    "                                     value_model,\n",
    "                                     discount=0.99,\n",
    "                                     policy_trace_decay=0.5,\n",
    "                                     value_trace_decay=0.5,\n",
    "                                     callbacks=[rl_callbacks.WandbCallback('CartPole-v1-Actor-Critic')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic.train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [\n",
    "    (128, 'relu', {\n",
    "                    \"kaiming normal\": {\n",
    "                        \"a\":1.0,\n",
    "                        \"mode\":'fan_in'\n",
    "                    }\n",
    "                },\n",
    "    ),\n",
    "    # (256, 'relu', {\n",
    "    #                 \"kaiming_normal\": {\n",
    "    #                     \"a\":0.0,\n",
    "    #                     \"mode\":'fan_in'\n",
    "    #                 }\n",
    "    #             },\n",
    "    # )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [(128, 'relu', \"kaiming normal\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = models.ValueModel(env, dense_layers, 'Adam', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in value_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = models.PolicyModel(env, dense_layers, 'Adam', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in policy_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce = rl_agents.Reinforce(env, policy_model, value_model, 0.99, [rl_callbacks.WandbCallback('CartPole-v0_REINFORCE', chkpt_freq=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce.train(200, True, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG w/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layers = [\n",
    "    # {\n",
    "    #     \"batchnorm\":\n",
    "    #     {\n",
    "    #         \"num_features\":3\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 7,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_models.CNN(cnn_layers, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=cnn, dense_layers=dense_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=cnn, state_layers=state_layers, merged_layers=merged_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape=(1,))\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, mean=0.0, theta=0.15, sigma=0.01, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(\n",
    "    env,\n",
    "    actor,\n",
    "    critic,\n",
    "    discount=0.98,\n",
    "    tau=0.05,\n",
    "    action_epsilon=0.2,\n",
    "    replay_buffer=replay_buffer,\n",
    "    batch_size=128,\n",
    "    noise=noise,\n",
    "    callbacks=[rl_callbacks.WandbCallback(\"CarRacing-v2\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.train(1000, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Reacher-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieved_goal = gym_helper.reacher_achieved_goal(env)\n",
    "action = env.action_space.sample()\n",
    "env.step(action)\n",
    "print(f'observation: {env.get_wrapper_attr(\"_get_obs\")()}')\n",
    "print(f'distance to goal: {env.get_wrapper_attr(\"_get_obs\")()[8::]}')\n",
    "print(f'fingertip: {env.get_wrapper_attr(\"get_body_com\")(\"fingertip\")}')\n",
    "print(f'target: {env.get_wrapper_attr(\"get_body_com\")(\"target\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_achieved_goal = env.get_wrapper_attr(\"_get_obs\")()[8::]\n",
    "desired_goal = [0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func(env, action, achieved_goal, next_achieved_goal, desired_goal, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env,\n",
    "                          cnn_model=None,\n",
    "                          dense_layers=dense_layers,\n",
    "                          goal_shape=(3,),\n",
    "                          optimizer=\"Adam\",\n",
    "                          optimizer_params={'weight_decay':0.0},\n",
    "                          learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env,\n",
    "                            cnn_model=None,\n",
    "                            state_layers=state_layers,\n",
    "                            merged_layers=merged_layers,\n",
    "                            goal_shape=(3,),\n",
    "                            optimizer=\"Adam\",\n",
    "                            optimizer_params={'weight_decay':0.0},\n",
    "                            learning_rate=0.0001,\n",
    "                            normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape\n",
    "replay_buffer = helper.ReplayBuffer(env, 100000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape,\n",
    "#                        mean=0.0,\n",
    "#                        theta=0.05,\n",
    "#                        sigma=0.15,\n",
    "#                        dt=1.0, device='cuda')\n",
    "\n",
    "noise=helper.NormalNoise(shape=env.action_space.shape,\n",
    "                         mean = 0.0,\n",
    "                         stddev=0.05,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Reacher-v4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(ddpg_agent,\n",
    "                    strategy='future',\n",
    "                    num_goals=4,\n",
    "                    tolerance=0.001,\n",
    "                    desired_goal=desired_goal_func,\n",
    "                    achieved_goal=achieved_goal_func,\n",
    "                    reward_fn=reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(10, 50, 16, 40, True, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.goal_normalizer.running_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.agent.replay_buffer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.agent.state_normalizer.running_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER w/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layers = [\n",
    "    # {\n",
    "    #     \"batchnorm\":\n",
    "    #     {\n",
    "    #         \"num_features\":3\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 7,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "cnn = cnn_models.CNN(cnn_layers, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env,\n",
    "                          cnn_model=cnn,\n",
    "                          dense_layers=dense_layers,\n",
    "                          goal_shape=(1,),\n",
    "                          optimizer=\"Adam\",\n",
    "                          optimizer_params={'weight_decay':0.0},\n",
    "                          learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env,\n",
    "                            cnn_model=cnn,\n",
    "                            state_layers=state_layers,\n",
    "                            merged_layers=merged_layers,\n",
    "                            goal_shape=(1,),\n",
    "                            optimizer=\"Adam\",\n",
    "                            optimizer_params={'weight_decay':0.0},\n",
    "                            learning_rate=0.001,\n",
    "                            normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape\n",
    "replay_buffer = helper.ReplayBuffer(env, 100000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape,\n",
    "#                        mean=0.0,\n",
    "#                        theta=0.05,\n",
    "#                        sigma=0.15,\n",
    "#                        dt=1.0, device='cuda')\n",
    "\n",
    "noise=helper.NormalNoise(shape=env.action_space.shape,\n",
    "                         mean = 0.0,\n",
    "                         stddev=0.05,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('CarRacing-v2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(ddpg_agent,\n",
    "                    strategy='future',\n",
    "                    num_goals=4,\n",
    "                    tolerance=1,\n",
    "                    desired_goal=desired_goal_func,\n",
    "                    achieved_goal=achieved_goal_func,\n",
    "                    reward_fn=reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=20,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=20\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset environment\n",
    "state, _ = her.agent.env.reset()\n",
    "# instantiate empty lists to store current episode trajectory\n",
    "states, actions, next_states, dones, state_achieved_goals, \\\n",
    "next_state_achieved_goals, desired_goals = [], [], [], [], [], [], []\n",
    "# set desired goal\n",
    "desired_goal = her.desired_goal_func(her.agent.env)\n",
    "# set achieved goal\n",
    "state_achieved_goal = her.achieved_goal_func(her.agent.env)\n",
    "# add initial state and goals to local normalizer stats\n",
    "her.state_normalizer.update_local_stats(state)\n",
    "her.goal_normalizer.update_local_stats(desired_goal)\n",
    "her.goal_normalizer.update_local_stats(state_achieved_goal)\n",
    "# set done flag\n",
    "done = False\n",
    "# reset episode reward to 0\n",
    "episode_reward = 0\n",
    "# reset steps counter for the episode\n",
    "episode_steps = 0\n",
    "\n",
    "while not done:\n",
    "    # get normalized values for state and desired goal\n",
    "    state_norm = her.state_normalizer.normalize(state)\n",
    "    desired_goal_norm = her.goal_normalizer.normalize(desired_goal)\n",
    "    # get action\n",
    "    action = her.agent.get_action(state_norm, desired_goal_norm, grad=False)\n",
    "    # take action\n",
    "    next_state, reward, term, trunc, _ = her.agent.env.step(action)\n",
    "    # get next state achieved goal\n",
    "    next_state_achieved_goal = her.achieved_goal_func(her.agent.env)\n",
    "    # add next state and next state achieved goal to normalizers\n",
    "    her.state_normalizer.update_local_stats(next_state)\n",
    "    her.goal_normalizer.update_local_stats(next_state_achieved_goal)\n",
    "    # store trajectory in replay buffer (non normalized!)\n",
    "    her.agent.replay_buffer.add(state, action, reward, next_state, done,\\\n",
    "                                    state_achieved_goal, next_state_achieved_goal, desired_goal)\n",
    "    \n",
    "    # append step state, action, next state, and goals to respective lists\n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "    next_states.append(next_state)\n",
    "    dones.append(done)\n",
    "    state_achieved_goals.append(state_achieved_goal)\n",
    "    next_state_achieved_goals.append(next_state_achieved_goal)\n",
    "    desired_goals.append(desired_goal)\n",
    "\n",
    "    # add to episode reward and increment steps counter\n",
    "    episode_reward += reward\n",
    "    episode_steps += 1\n",
    "    # update state and state achieved goal\n",
    "    state = next_state\n",
    "    state_achieved_goal = next_state_achieved_goal\n",
    "    # update done flag\n",
    "    if term or trunc:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package episode states, actions, next states, and goals into trajectory tuple\n",
    "trajectory = (states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals = trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (s, a, ns, d, sag, nsag, dg) in enumerate(zip(states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)):\n",
    "    print(f'a={a}, d={d}, sag={sag}, nsag={nsag}, dg={dg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"future\"\n",
    "num_goals = 4\n",
    "\n",
    "# loop over each step in the trajectory to set new achieved goals, calculate new reward, and save to replay buffer\n",
    "for idx, (state, action, next_state, done, state_achieved_goal, next_state_achieved_goal, desired_goal) in enumerate(zip(states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)):\n",
    "\n",
    "    if strategy == \"final\":\n",
    "        new_desired_goal = next_state_achieved_goals[-1]\n",
    "        new_reward = her.reward_fn(state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "        print(f'transition: action={action}, reward={new_reward}, done={done}, state_achieved_goal={state_achieved_goal}, next_state_achieved_goal={next_state_achieved_goal}, desired_goal={new_desired_goal}')\n",
    "        her.agent.replay_buffer.add(state, action, new_reward, next_state, done, state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "\n",
    "    if strategy == 'future':\n",
    "        for i in range(num_goals):\n",
    "            if idx + i + 1 >= len(states):\n",
    "                break\n",
    "            goal_idx = np.random.randint(idx + 1, len(states))\n",
    "            new_desired_goal = next_state_achieved_goals[goal_idx]\n",
    "            new_reward = her.reward_fn(state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "            print(f'transition: action={action}, reward={new_reward}, done={done}, state_achieved_goal={state_achieved_goal}, next_state_achieved_goal={next_state_achieved_goal}, desired_goal={new_desired_goal}')\n",
    "            her.agent.replay_buffer.add(state, action, new_reward, next_state, done, state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a, r, ns, d, sag, nsag, dg = her.agent.replay_buffer.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f'{i}: a={a[i]}, r={r[i]}, d={d[i]}, sag={sag[i]}, nsag={nsag[i]}, dg={dg[i]} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.01}, learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 100000, (3,))\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.99,\n",
    "                            tau=0.005,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_goal_func(env):\n",
    "    return np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "def achieved_goal_func(env):\n",
    "    return env.get_wrapper_attr('_get_obs')()\n",
    "\n",
    "def reward_func(env):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='none',\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.target_critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(1,1,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.observation_space.sample()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.state_normalizer.normalize(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = her.desired_goal_func(her.agent.env)\n",
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.goal_normalizer.normalize(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_renders(folder_path):\n",
    "    # Iterate over the files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has a .mp4 or .meta.json extension\n",
    "        if filename.endswith(\".mp4\") or filename.endswith(\".meta.json\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Remove the file\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_renders(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/ddpg/renders/training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Fetch-Reach (Robotics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v2\", max_episode_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieved_goal_func(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_wrapper_attr(\"_get_obs\")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchReach-v2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='future',\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=50,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, action, rewards, next_states, dones, achieved_goals, next_achieved_goals, desired_goals = her.agent.replay_buffer.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.env.get_wrapper_attr(\"distance_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get success\n",
    "her.agent.env.get_wrapper_attr(\"_is_success\")(achieved_goal_func(her.agent.env), desired_goal_func(her.agent.env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.env.get_wrapper_attr(\"goal_distance\")(next_state_achieved_goal, desired_goal, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.agent.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(pusher_her.agent.env.get_wrapper_attr(\"get_body_com\")(\"goal\") - pusher_her.agent.env.get_wrapper_attr(\"get_body_com\")(\"object\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.agent.replay_buffer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pusher_her.agent.replay_buffer.desired_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST ENV\n",
    "env = gym.make(\"Pusher-v5\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.wrappers.RecordVideo(\n",
    "                    env,\n",
    "                    \"/renders/training\",\n",
    "                    episode_trigger=lambda x: True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "# take action\n",
    "    next_state, reward, term, trunc, _ = env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Fetch Push (Robitics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.3,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=128,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchPush-v2\")],\n",
    "                            save_dir=\"fetch_push/models/ddpg/\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='final',\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0,\n",
    "    save_dir=\"fetch_push/models/her/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=50,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MULTITHREADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.3,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=128,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchPush-v2\")],\n",
    "                            save_dir=\"fetch_push/models/ddpg/\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='final',\n",
    "    num_workers=4,\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0,\n",
    "    save_dir=\"fetch_push/models/her/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config_path = \"/workspaces/RL_Agents/pytorch/src/app/HER_Test/her/config.json\"\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = rl_agents.HER.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for callback in agent.agent.callbacks:\n",
    "    print(callback._sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cpu'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'assets/wandb_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    wandb_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'assets/sweep_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    sweep_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated configuration to a train config file\n",
    "os.makedirs('sweep', exist_ok=True)\n",
    "train_config_path = os.path.join(os.getcwd(), 'sweep/train_config.json')\n",
    "with open(train_config_path, 'w') as f:\n",
    "    json.dump(sweep_config, f)\n",
    "\n",
    "# Save and Set the sweep config path\n",
    "sweep_config_path = os.path.join(os.getcwd(), 'sweep/sweep_config.json')\n",
    "with open(sweep_config_path, 'w') as f:\n",
    "    json.dump(wandb_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['python', 'sweep.py']>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 189\n",
      "INFO:wandb.agents.pyagent:Starting sweep agent: entity=None, project=FetchReach-v2, count=5\n",
      "DEBUG:wandb.agents.pyagent:Agent._setup()\n",
      "DEBUG:wandb.agents.pyagent:Agent._register()\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 68\n",
      "DEBUG:wandb.agents.pyagent:agent_id = QWdlbnQ6aHhnNGFueWg=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 1bgdi8sq\n",
      "Sweep URL: https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/1bgdi8sq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 809\n",
      "DEBUG:wandb.agents.pyagent:Job received: Job(8skgtezh,{'HER_DDPG': {'value': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cpu', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}}, 'env': {'value': {'id': 'FetchReach-v2', 'max_episode_steps': 50}}, 'model_type': {'value': 'HER_DDPG'}})\n",
      "DEBUG:wandb.agents.pyagent:Spawning new thread for run 8skgtezh.\n",
      "wandb: Agent Starting Run: 8skgtezh with config:\n",
      "wandb: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cpu', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "wandb: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "wandb: \tmodel_type: HER_DDPG\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train config: {'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "Loaded sweep config: {'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cpu'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n",
      "setup wandb called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 782\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "wandb: Currently logged in as: jasonhayes1987. Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 15\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 987\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pypi.org:443\n",
      "DEBUG:urllib3.connectionpool:https://pypi.org:443 \"GET /pypi/wandb/json HTTP/1.1\" 200 87238\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "wandb: Tracking run with wandb version 0.17.1\n",
      "wandb: Run data is saved locally in /workspaces/RL_Agents/pytorch/src/app/wandb/run-20240608_031457-8skgtezh\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train-24\n",
      "wandb:  View project at https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb:  View sweep at https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/1bgdi8sq\n",
      "wandb:  View run at https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8skgtezh\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 592\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): storage.googleapis.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called in setup wandb\n",
      "load weights:False\n",
      "num_episodes:10\n",
      "render:False\n",
      "render freq:0\n",
      "save dir:HER_Test\n",
      "seed:42\n",
      "run number:None\n",
      "use mpi:True\n",
      "passed assert\n",
      "if wandb run fired\n",
      "{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}\n",
      "Environment created: <TimeLimit<OrderEnforcing<PassiveEnvChecker<MujocoFetchReachEnv<FetchReach-v2>>>>>\n",
      "if model type = HER_DDPG called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 47\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/8skgtezh/wandb-metadata.json?Expires=1717902904&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=XetBXVDefp5Vm1ot6CwPk3zlg5UO5wDdiTkrHc%2BQC5DnDe%2BcHNTg0%2BM2SNievayLMKSds7QQuTS8lRV1IGolPOG%2FkK2toQsuEbDt%2FKvLnIF1%2FVt32p9CpiW2KE77wi7qYQd%2FvLzuFOLo27KzemV%2BKwewK8d9NaXVYIFOzPnm6Ng46yS8WeHodXkvU0L9Zz%2FzW%2F0MlzD9TyOcJYlLfE5NcfYDCkRzsj1MY10l7ug0Il3WoT3AO%2BvkIIAQKz9gZWAQ7jo0nHtDWijIkYcB8Z1ZCGWpq%2FS6EGn0uB%2B34EzSqB1J0HFzq039pM7iCa2TudkEHGy4T%2FVr8PmmjL%2F1BaRUnQ%3D%3D HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "sweep use_mpi fired\n",
      "agent config path: HER_Test/her/config.json\n",
      "train config path: sweep/train_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/8skgtezh/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/8skgtezh/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Output:\n",
      "train_her_mpi fired\n",
      "mpi agent config loaded:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "mpi train config loaded:{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "mpi train agent fired\n",
      "mpi assert passed\n",
      "if agent passed in mpi\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "mpi agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "\n",
      "Standard Error:\n",
      "2024-06-08 03:15:06,536 - ERROR - An unexpected error occurred during training\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 68, in <module>\n",
      "    train_agent(agent_config, train_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "\n",
      "Subprocess failed with return code 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/8skgtezh/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 989\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 580\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 593\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 582\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 587\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 584\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/8skgtezh/config.yaml?Expires=1717902910&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=onQz%2BcY6gbx9fUfWbBTHOYEJ5i2PqMfAsDhZ7MpVBU4a7b1bf2l3QaRF%2F%2F4Wjhsd5RfRJrW5m%2B3MAmWmQqi43YYJNPoHuUlqXQTGQkKzoiZdJ8wL95RkAL0n4seRbdiMeDMnKOJ%2FzoSGoQ4NZ6xgCAUH7a86p3gWzY%2BvpvtHktawxaann%2FH7Q0HAzutvCesqkklDMSQB2abYkBGa4Kw6X8fjrcd58j%2FbE9ygpd1qDHp5Z70BAcLUqFj953IdPQE%2BkypTHO8uQshu9GRKo%2Bcp1wpKGum3UceJBJ96YsAfuXJOUJHwMbxwfBpl1olmVDIqluM7rmRTQf9YGQ9uTj8Aew%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/8skgtezh/conda-environment.yaml?Expires=1717902910&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=jdUqpJyQiV%2Fr13x3D1%2Bw69jBJc%2BhdbCZwwC9UvnkLuwjj1RRGfo9Fbx4guWVjxv2jbwUU9fT1VsiXkwglMOXe1BuqHAvN3ItVUCS5XO8TvZPitknLBnbE4c1y49i0Gci2Uf45H%2BkH%2BMM9kt8lNmfpkS9myq8iFpMxBVesjcnCjZ65WnvLoBaaZO8ZH%2B2sifqDTiAQjpWJl%2B%2BAxF76MfWqaBuaU9YGcDeoeqkKMhEIZfIQF0%2FkVVVgZc%2FudHhb3V0KPqVxvnGo2u0YrgXkNNx%2Bb%2F4MjIPiA1t519bzezyvO30%2F9p01O6%2Fme8PpqczFWVra9OrERj1oL3WL1IzwVo96Q%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/8skgtezh/output.log?Expires=1717902910&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=DlFSvo5GSbGLRgmlAJcwOgKlfhJW0BqSfL1QSJOP0NMWkcqbXCmRh9T%2FG8CxiTxsW82Q6KcoQ18qmbM5%2BYOBpuduEkXTHlA1rgr5H7rsNUhs8Bm8wd4rOjLfFaLIISmR%2FQ9p5Yxgfw50kIvcapzwGgEyIKfbC1J%2FA0IYAZ%2FitR1RzWBf1VOR3BN%2F0MdJdcO8eptK%2B5GDBHWRUbe1OXksK7ho2Cvf1MCEpi8L9%2FqnFCAn%2BZU4RwYColM5bcpaVZKsSsTKX%2B1YDt12PiQEaK70hpD1XVe8duUZ9egm%2B%2F61%2FWiUU2KQXE8kphIwQfj2hYy41fMCHT2AJvnFCR3MeLQzHA%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/8skgtezh/requirements.txt?Expires=1717902910&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=t0fHKHH2c2LNSbQssYytZ%2F%2FptrgHnfHg9BbeI8AKTTAOGqbuKvOJqVauZ2sFfYfHFXo%2F4hTKmDPQ%2B30%2BupGjWjOM%2BgXPIwn6YD1r%2FGqwaEx1JA3zWoHdDsU%2BsV29oZT1hoXT3tz%2BngNS3sZpbxM0n%2BSjssg5FhUwcKyoV5eoyQtDYlPLLrwxQWTyrUmfRt4GxjvJf%2BWQZYQrLqwAjWncvR4pe9tuI7ERAtO7TFvtnpeHrNSmSLJyt%2FRlmrE7tbNkKQALNRd4fhVAOsrtJnKMyS4qEtTxyOYpVun5f506EzIH3Bko7iI7WwrS%2FnjDEOukJ4in0BWk6A%2F5I9EZSdXnkQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/8skgtezh/wandb-summary.json?Expires=1717902910&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=EfdQDikWGfmJ%2FwA8bFp2NOglVToTYPDjqdWNfED123HOobcIdsByskTncFMegpI6DRV%2F7%2BkwbbZgBCLcov62oUraclyTq50Y%2B%2Bo7ktQwtizHZ599IQn%2B7cH8VNBFuLMct5utfm4Mtpxs%2FLTRoGaRM0aCQDoNYiJ7JGq2NqJT8F7AHs9D3MuTlWIYDFefG48xgpmH0wJUeOfjaoq%2BIVGXQFgPDDt4vHCFGkGskM74LWIRbY1dG2sw1VydBm6uBlny7kySgo%2FU1eFOu6BrfedalTbGSwWCpR1qfwosKKMxpljZusKggKH83P%2Bz203aGJGUUh%2BHdkxPxiTpTa5fgXE%2FIw%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/8skgtezh/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/8skgtezh/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/8skgtezh/file_stream HTTP/1.1\" 200 220\n",
      "wandb:                                                                                \n",
      "wandb:  View run train-24 at: https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8skgtezh\n",
      "wandb:  View project at: https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240608_031457-8skgtezh/logs\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "wandb: Agent Starting Run: rge1i36l with config:\n",
      "wandb: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cpu', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 5, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "wandb: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "wandb: \tmodel_type: HER_DDPG\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train config: {'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "Loaded sweep config: {'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cpu'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n",
      "setup wandb called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 782\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 15\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 988\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pypi.org:443\n",
      "DEBUG:urllib3.connectionpool:https://pypi.org:443 \"GET /pypi/wandb/json HTTP/1.1\" 200 87238\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "wandb: Tracking run with wandb version 0.17.1\n",
      "wandb: Run data is saved locally in /workspaces/RL_Agents/pytorch/src/app/wandb/run-20240608_031512-rge1i36l\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train-25\n",
      "wandb:  View project at https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb:  View sweep at https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/1bgdi8sq\n",
      "wandb:  View run at https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/rge1i36l\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 588\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): storage.googleapis.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called in setup wandb\n",
      "load weights:False\n",
      "num_episodes:10\n",
      "render:False\n",
      "render freq:0\n",
      "save dir:HER_Test\n",
      "seed:42\n",
      "run number:None\n",
      "use mpi:True\n",
      "passed assert\n",
      "if wandb run fired\n",
      "{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}\n",
      "Environment created: <TimeLimit<OrderEnforcing<PassiveEnvChecker<MujocoFetchReachEnv<FetchReach-v2>>>>>\n",
      "if model type = HER_DDPG called\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "sweep use_mpi fired\n",
      "agent config path: HER_Test/her/config.json\n",
      "train config path: sweep/train_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 47\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/rge1i36l/wandb-metadata.json?Expires=1717902920&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=BgJCu508lhsX%2BE27G%2BI%2Fq%2FvNMK4oFIHgxFuRou5OUElmrJFlRwF7B%2B4wBeQLeKN9epYLJ8FbZWTdG4%2Fj5rgvw6UCgE%2BnDm5DpfYZjEMlvhePQZAdnrzXL7bj1ryZqvNKx9JDdYcZxLOsRuulkaMfkQOTXJI6HCELNIuikPIP4%2FaDoEegSqF%2Fz9rbhSjJ4PmJwTKXetblcI3c6IuV0hbUocDycj%2BS82PGXzPFEpAE9hO7bnnaUs%2BzdlX1yolmRfSceu0etux1Yfv9oeqFunMT%2FH5s%2F5c3FpQTQnseX%2BbJ4JjVLPgaUo79Nh9UQ3eck0CJxQo0pXnU2cWMLm4iLXFyJQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/rge1i36l/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/rge1i36l/file_stream HTTP/1.1\" 200 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Output:\n",
      "train_her_mpi fired\n",
      "mpi agent config loaded:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "mpi train config loaded:{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "mpi train agent fired\n",
      "mpi assert passed\n",
      "if agent passed in mpi\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "mpi agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "\n",
      "Standard Error:\n",
      "2024-06-08 03:15:21,577 - ERROR - An unexpected error occurred during training\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 68, in <module>\n",
      "    train_agent(agent_config, train_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "\n",
      "Subprocess failed with return code 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/rge1i36l/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 994\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 578\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 587\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 578\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 586\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 581\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/rge1i36l/config.yaml?Expires=1717902924&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=PAH33m%2BhTgRWwSsBYDflpWsPCj%2BMGJqEU4imFnkANAuJB8r98o5avJ4STv7sjV3VuYfeWrCXkjeGabHRCX%2Fnnk5X%2FNVQ3q5ySJEarlD%2BtnBYz94VzjotNhPVLlS%2Bd5xf01nsiE%2FJAcNsdjVK0RDss4akcM0rqcqJfWA4c5htXF5HTklymuV8u6d1HyCPwS0gASmW2NpRQ9ZvjB7a9IYtT43wSMLBnFjywHzyQy74Rx0yJTcUvTlSgQdv3dZIAFIoRpVauJj6w8%2BZqN2H2Gvck4DVFynq6%2FMML5ouOGXWPoM26JllApCdt4Ux6d49FWRr7nulAju9LT5VT0%2FJGIMfOA%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/rge1i36l/conda-environment.yaml?Expires=1717902924&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=Q%2Bt9Vz4pZ%2FQrXzgYYp%2BhNbSz2NA5Bz1OI80NtzpZqqY2VkVbGygLsvB7vhNkKKlt1cd5IIDVe6lCmVzClVgVfi%2FWoDvZjiIfM%2Fn24PjTPXaTuOYgdaiMph5YR5VqY6n0Sq055XILaCR77cEODBD5vA%2FMhJrKugNYLxJu1xnMiqlWjZ1pa6YMdYOy4wYwm%2BGjOnwRHtFgNmFlIZY3%2FesI%2FXVNt0Mun0u4vS4qB8TAv976XFeL4sgGtXNf0vdT7yBnbF%2BSQjrLLNykmYhj6JJYpetNdWLsaVnR3w%2FmZX0zbHOP7VIdxqu5PXeRo%2FGkjgvUPxidePj0UEd9ppuls8rYlQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/rge1i36l/requirements.txt?Expires=1717902924&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=xAOwTJTX4RwUAVjgsd57WbQh0IEq85jejdJ4tSPgLK2ogy%2FUi0BpghZ3Hf1UdWjPYnBHbql9gw%2FDOfUYVMJSONCn6mKVgtA7xsS7p78BZoq3iCFk%2FXqMwwobBxO4DwCnoldzjWomLUkaWLoDTyGnlgXBV%2BNPOzzA12aQ0xexdkMUhOiFOnNqthJM45esmlaa4aKRsYuDGGde0SESyzVC3W9EU8p2Box7PXlKUAFAr7CoHIgugKeWD%2Bo60e7rb%2BkdbLpgg5tjxMdrJ1l%2Bx%2FSYXwfDBiUhqquSURDE6NirV7P7JkNDZXiCdi8U165RYy1SYkK5kOIid4bmjfmGuVidpQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/rge1i36l/wandb-summary.json?Expires=1717902924&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=Vp0RmycAEGtQjFmRNIHhpRtw8LHHmo%2FNhFWvqrjwTAS6s%2FrU8TSts%2BhoX2vipEDDQ%2Bw6bkvZaClnICknCYRlNOfRKdSZ1naRRpEZgSeGuAi0uJb3%2BTCd6k%2FJkPSPZdvp%2BzeBNvtCufhRPfhVJ%2F8yDT6U%2F2auapXDwSM1vZgwZFO1gjmfrJxO4Xjml5eXMQaBrqgRv%2BL09u9QhwEXfGgFObS70H%2FvI0SeuhIPQMp2c4weBqj5ti1UoYe6bBhRAZkrHqBfECv%2BZpIls1t1oRmoAZOR2dBLEgleczP3VlLe8dSxyaNBjFxPMajHppaSkmA7f8CDMfZiJk4mRzhRCUZmpg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/rge1i36l/output.log?Expires=1717902924&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=Pqx2brvya5p68%2B3qYwfy%2Fcm3Qhax%2BDDYrdm2BrIBuv4Q6SHCEcnLuiuJVujfDZpsi0icgSCzw77xZU9lRL32wp%2F9Wvt95t12AJQVbq6BDqFj5iXbwUhuosoTYCGtPfwj%2Fp47TU3mW81FM9XOzPoiZyUDek7jLIM9JO7sX2kWAQjDAgeWIFJu2s3tmnE2oUZCwb4o6tK0mzk1zKE0CgoWmB6EBSskKmgn5rR4KT0E57E1hrIMFPKzS6aE%2FhxjaurO%2Baetou7RJ%2BBZzqk6xx2v2dWxi9%2B09SQEh8cWgv%2Fx0yS4KYnAisFO8SX9AhDx6b%2FY1JKF5W4Kd6eYVOJeIdk2Eg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/rge1i36l/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/rge1i36l/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/rge1i36l/file_stream HTTP/1.1\" 200 220\n",
      "wandb:                                                                                \n",
      "wandb:  View run train-25 at: https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/rge1i36l\n",
      "wandb:  View project at: https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240608_031512-rge1i36l/logs\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 874\n",
      "wandb: Agent Starting Run: m4cghsa5 with config:\n",
      "wandb: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cpu', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 5, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "wandb: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "wandb: \tmodel_type: HER_DDPG\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train config: {'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "Loaded sweep config: {'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cpu'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n",
      "setup wandb called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 782\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 15\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 982\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pypi.org:443\n",
      "DEBUG:urllib3.connectionpool:https://pypi.org:443 \"GET /pypi/wandb/json HTTP/1.1\" 200 87238\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "wandb: Tracking run with wandb version 0.17.1\n",
      "wandb: Run data is saved locally in /workspaces/RL_Agents/pytorch/src/app/wandb/run-20240608_031528-m4cghsa5\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train-26\n",
      "wandb:  View project at https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb:  View sweep at https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/1bgdi8sq\n",
      "wandb:  View run at https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m4cghsa5\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 589\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called in setup wandb\n",
      "load weights:False\n",
      "num_episodes:10\n",
      "render:False\n",
      "render freq:0\n",
      "save dir:HER_Test\n",
      "seed:42\n",
      "run number:None\n",
      "use mpi:True\n",
      "passed assert\n",
      "if wandb run fired\n",
      "{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}\n",
      "Environment created: <TimeLimit<OrderEnforcing<PassiveEnvChecker<MujocoFetchReachEnv<FetchReach-v2>>>>>\n",
      "if model type = HER_DDPG called\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "sweep use_mpi fired\n",
      "agent config path: HER_Test/her/config.json\n",
      "train config path: sweep/train_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/m4cghsa5/wandb-metadata.json?Expires=1717902935&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=R%2BmML3Xi0H6pZJA8qcAuzu0gBjlC0xnWGat1aiomPrhjbUiA9%2Bpcxwg%2F8je7%2FKPXc7YVQJWNZpNeGzZ9bKrdy9rjk4prhkKXQonhFzIF%2BcCXfCAjboQN6JvU1SqYPW6iyyTqSsTiJHb5dd5AJxS5RHh3Rd47SX6wpKnCO1DbAVNnxVGWHzMbK0beqUuIQuKEgiZvL12TX0iwcP2mh0H1zz%2B7WM8y%2F5cmwFO1yoz8I%2FhgszyV%2FRuCM2b2Iygi5%2F58x3PqT3F7rDC74wz4hVrctQHT%2BIkNqCUTRMb5M9WL%2FDEBEevDE4DNr5idIf4uN13B1fwvTKrHAo1dHtuBE5Osyg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/m4cghsa5/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/m4cghsa5/file_stream HTTP/1.1\" 200 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Output:\n",
      "train_her_mpi fired\n",
      "mpi agent config loaded:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "mpi train config loaded:{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "mpi train agent fired\n",
      "mpi assert passed\n",
      "if agent passed in mpi\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "mpi agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "\n",
      "Standard Error:\n",
      "2024-06-08 03:15:37,040 - ERROR - An unexpected error occurred during training\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 68, in <module>\n",
      "    train_agent(agent_config, train_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "\n",
      "Subprocess failed with return code 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/m4cghsa5/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 987\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 582\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 587\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 584\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 590\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 582\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/m4cghsa5/config.yaml?Expires=1717902940&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=i3w9%2B%2Fb8hqX9mL7C0GR6WwsT0uBII6vjTj0mCUeX8zUN9uSAth5CIShikqwAQObdolYxH4UQBlMdAYwWo5n%2BXWpwi7liVZp9ibqrr%2B%2FYXD0lDCFBWKMVxKOw7t9oB8GtUliqWi7wZFjXCuQ%2B1o%2F24WGQw%2Fo9SAS99GFq2X6N%2Fd79EvbOC2sqSZtXlK4vTlhNMIbwKyhmnqB3X4BO3%2BEUpL6eSsSDKGSu98z1EVnIGDvoR5DXnhLe%2Brt6lTEekZHyNhWT8COtUUKkylzFAhagpTYlxPHU2Nxwt6LZXVH8yPHm09tLUu8UwbPz91TGdd4JWarZIUb%2FKNV5FZA24rxqHA%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/m4cghsa5/conda-environment.yaml?Expires=1717902940&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=PV4okxjCYZSz6sZqfn06GoySVsLpUMswsP9lYnCeesX7CTirJGJDGyGUU5gK3Iiaa5f6pCNySdBdPo69vWWtVN0M8ClsF3J6bZCQig%2B5NtD78p3IqCsmuGoaNKHLeom6xAJ5OvjClNrvp8TLPjD1AEU61vmay%2BGmv2iOegJKW2Gl0JCOX2VdTaY9Uu3cGOS9VYUfQbjGQrlNBZLgMaTTAe%2Ff%2FT%2FRGz%2BWMVB7gjjVn6ZpD%2FJ0U88nfq0kklB3m5MutxiQt7RUjaSQoPyd0x%2F5SJFLm8eVfDsBOiSotgShW3QnlhBJSZOBZdW2t6TzFf%2FNezsGY4hvGnHFnVczPu%2FpuA%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/m4cghsa5/requirements.txt?Expires=1717902940&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=IV%2BSPKE4gM2b%2Bc2xi%2B38LYnadG5lhhSs%2F0M56x9wBOauCD0clNrLr5l00Wf2nQRAfCuRu7I%2FsindR9R4M74qnDHlWWixS7iwj52hSZjCajqX3CgO%2FyCjJzsBOtLvZYpWTspeU180xL5wtsDwxZ1rQy43uzJVkXejqRhahFVsfEDCqeLtzv1GNA0mfYBgwsfM%2FQjhWl%2Ftd95Aox1RlZ%2BtonoVK%2BOV0kw2%2Fw5BOC%2FDIzdJrhq1FsvEizYJn3xTWFe%2Fk28bYc1CdXBzU2x3RyL%2FibEYDBCuQGbwmKkzazpLwPeYVSfDHHbsL9OF%2FxhOvNmR0qxaOxEbx%2FFtzAwbmoUIsQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/m4cghsa5/output.log?Expires=1717902940&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=QdVckc8%2Bf%2F68qMlxT7zL6Ae88gbgWfJD4ru0cJ%2BJUA9BWPLVlY%2FLJTqw4p5jSqrZG1Itt%2FV84DUEHOoQOOq9jxl1AIeu%2F8SLvi963msNKi4u5w1Yy1I37xeqHmIKjR8CdLBBwH9vTxkLoS7Vy5DZcC0U3xzO%2FYrWqdTF1LJSbXBO%2FwwcUlJlVWrOGy%2B6Ys9gtR4eUkBmtrhws7CL%2B4Q47z%2FO05D%2BE2HRmOOlmLyFL1F7PEmc6Zs6xXKokvebPF01eXNfYr0Xtbfulh16h%2FHa3v0WfCG5vjLAlAI%2FMes07feLMYpBiCYBrx3k4bwzgbjq7UMBkiYc088PvB2XN5wAcw%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/m4cghsa5/wandb-summary.json?Expires=1717902940&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=eEgWSZjy9JT5GkY43pCtjIcD8d5vW6AehAZNzwlD0f4Ko9Wf3cz7iCEb6Hs7fNrvqbzYJYxJXQ0v1Np8H27GkhMoUXQoNsASQPvEGidrGKtKovO2r5mI%2BY6rAHRYEJHSU5KgFRolzBplC0p3cREM63DUSN%2F14AxlC2cmgs3uPheUACfWgYKF1KWUPvgDjKU%2ByEfFiCTMJVVtqh0mvyWt21LSqAs29v3GKdRuMe9QYVy03K7IUhzgg%2B1JmyRZxUiToZchZnRhKQUcsqKpOcN2sur2jDU3%2FpP%2Fl6CCVZyO1h4AOdX7XBKOVwIyBJC7j0HBlE412NOiYw%2F8zTOsKOyJGg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/m4cghsa5/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/m4cghsa5/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/m4cghsa5/file_stream HTTP/1.1\" 200 220\n",
      "wandb:                                                                                \n",
      "wandb:  View run train-26 at: https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m4cghsa5\n",
      "wandb:  View project at: https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240608_031528-m4cghsa5/logs\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 884\n",
      "wandb: Agent Starting Run: h36lsmvq with config:\n",
      "wandb: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cpu', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 8, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "wandb: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "wandb: \tmodel_type: HER_DDPG\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train config: {'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "Loaded sweep config: {'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cpu'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n",
      "setup wandb called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 782\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 15\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 992\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pypi.org:443\n",
      "DEBUG:urllib3.connectionpool:https://pypi.org:443 \"GET /pypi/wandb/json HTTP/1.1\" 200 87238\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "wandb: Tracking run with wandb version 0.17.1\n",
      "wandb: Run data is saved locally in /workspaces/RL_Agents/pytorch/src/app/wandb/run-20240608_031543-h36lsmvq\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train-27\n",
      "wandb:  View project at https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb:  View sweep at https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/1bgdi8sq\n",
      "wandb:  View run at https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/h36lsmvq\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 585\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): storage.googleapis.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called in setup wandb\n",
      "load weights:False\n",
      "num_episodes:10\n",
      "render:False\n",
      "render freq:0\n",
      "save dir:HER_Test\n",
      "seed:42\n",
      "run number:None\n",
      "use mpi:True\n",
      "passed assert\n",
      "if wandb run fired\n",
      "{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}\n",
      "Environment created: <TimeLimit<OrderEnforcing<PassiveEnvChecker<MujocoFetchReachEnv<FetchReach-v2>>>>>\n",
      "if model type = HER_DDPG called\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 8, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "sweep use_mpi fired\n",
      "agent config path: HER_Test/her/config.json\n",
      "train config path: sweep/train_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 47\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/h36lsmvq/wandb-metadata.json?Expires=1717902951&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=THJwwAhOH5X6AP%2B5Sw8oGe0HK6tCaU%2BNxl3K6eI80CkwTPjjJmYTq4S9wMVyVv3n0lm%2FTcRy84Hzd136K5VufX7KFzj8%2FRXS%2F%2Bdvh%2F1bYoU%2F73q8u1J7wpaaHQKdbEpt9rRBqb3BGYYHcPvceXodhB50yQh6UKV9OsiYRA25SydYEcx59v6c2fYVnl4LKtB4tEGFe7qn3H70B4RL1Q60NI22VPBK4aARaztQeYI6g8k5YJTZFRl4TgDMuUVPK5qb6%2FhZZZm5Toz9Z%2F7wp8jaiu3yevGOMsAqwEJ0alGybty6tsFMMPLeIlSKyrANnLvhaXWs6UqBjuRwnz8UiIyfUw%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/h36lsmvq/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/h36lsmvq/file_stream HTTP/1.1\" 200 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Output:\n",
      "train_her_mpi fired\n",
      "mpi agent config loaded:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 8, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "mpi train config loaded:{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "mpi train agent fired\n",
      "mpi assert passed\n",
      "if agent passed in mpi\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "mpi agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 8, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 8, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "\n",
      "Standard Error:\n",
      "2024-06-08 03:15:52,647 - ERROR - An unexpected error occurred during training\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 68, in <module>\n",
      "    train_agent(agent_config, train_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "\n",
      "Subprocess failed with return code 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 999\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/h36lsmvq/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 599\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 578\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 580\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 574\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 581\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/h36lsmvq/conda-environment.yaml?Expires=1717902955&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=lcX%2ByCXzzPQ9Fex%2BgE%2FeNhx2IKQ4R%2FOZvSdBIFFU2EyTVlQ4VZc0piNvShvEZG1We%2FZ%2FpeejjhyjUsqNqyQmHNUxETJOCzjRb%2BFLUfJI5RQOdotNmt4ddIR8dPjq45%2FJQG%2BXSKncALaBao7mBqg6gVKiGnX4cSNVd2hXLLtXggnWZW%2BlV7YxTAPVV49Z1lA2M8K7wWqQ4WP%2FeAuAdRlIkqiT4%2FKtAVQMa%2FVDU%2BXknP7nBEOev6xS54H%2F9AfsrshJso0lSiVgEsfYmdMdnvdTimr1Y570CFgyhcnunIygIOl4H7hVS3M2eleL1t%2BTDVnSK05ZQJ6AGStCJ17M%2Fj2Hew%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/h36lsmvq/config.yaml?Expires=1717902955&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=uCrihka5z%2FwcbZlX1YfKAgHFhiNbqGlstpR2mGzfyn6%2BgLoXHO02Nz6CzFZKEHjvUHudgdBvaBb1ZhA8aeazlKG7pnNUD%2FxHkUS9x9WxVrDFEHXkBUE0FKsymF1UcJR1Oq0ZKGqAD6K6g2s59sJYgTmjjbOF7YuZpfcRFEQ8xQ%2B1kg1lmVFXsfKgFAxLacoB2ztp0909OysXgDVstJ%2BIxMKqZBo0zTBMc4JoVjjZ82byIivUn7b5WGiemE6pQKhv35NknNmdW4kSPsjSnFQ9kb6x5tVBRvqjKZwOAHSKp%2Bi7jdXFof%2BweGwVycYvotkX7BU%2FkRDEH98xIZtSx%2B%2BCyw%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/h36lsmvq/output.log?Expires=1717902955&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=lLBlCIc2HQ9yoRmd1FgvhUpYRI32UCmGhC9vTmJHJyBKNuaZte96r8Z5UQw%2BetdOeXi1RJxhokc9GfBb8zwQrlvspByJd7CJkW0icWTY6fDeovVGnjyMtj5cgGObL5qfjYXCunCqWi%2BxoYhvds1F6uQO%2BNhvZL6zCnUQQ3K5TEhvLYuACpX8d1edKr89LauGTy9h5Ex5RKLKy4kGL2ZblBI3gmuWcUs52lNgk8vbh5RWWp248YN1ft%2FKHqAmgUHU20B%2FXWhJZPWUY1%2FoTU2M26ghKadLWOWEKuaZO6ewWTZId2bJDFm73daLwXX76N7csvV2fKsNda%2BaXwnjHV7mLQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/h36lsmvq/requirements.txt?Expires=1717902955&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=tRtOc5lyuCm6epNxfL98Lk012%2B57yeRD7OV29jQAIqnR9xkaZl2npr%2B4aajELIEzLX5XRMZmaS44FpAp5B6DwKgTO%2FNrenvhm6XJeZzczld35cC0UwGedESrwXeAwwVYqi3p%2FVvX9vKXKtfxyuErK%2B2ovP2wynpJod7xADtc8bZYJh4T8t55lFPrNuWOVg9MsdjosoN4P7KHK90nHVllv8xzj7FMb0SweXqV2vJPIKd91URvdNTRG1UJ8IpzdkWKZXPoywZJmHfnzAywfy8z6O%2BARFBXc8cQMzO0aYczjogpbdAl0usCmq1HP2wfqaFdHEI4EJG%2BNeqo29%2B8WZfR1Q%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/h36lsmvq/wandb-summary.json?Expires=1717902955&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=B0KS6pJypkbiEoW0REkIHQRYi840%2BprfjEXSD8Rt1oUn9kTN6NtTZhlIHKfvh%2Bm4gVLvzzBH8gOkY%2FFUpikuWZNQEHuoU3CdaySYAtIaXHgTmH3VSnFgo4Y42%2F9A7lKsEHQCz6BsZDqcS7p5mg2ISzJoV7rDGbDzUZA%2FhgYyZPmjp93QTZ10lEIBkKsDJtGmZSzTPUWS63LBGQBI8%2FCzJZFCZQbKSBnRWw9QbpBCtWfpSYh%2FMSK5gl4n1LvQeJcqp7t5vMYhVnGICmxO8qpDRtnXNxTUfsuFv6AbEl1mnFmcPYPFMZjO0gDfLGLJSSJ3tsfcFyo7SjoM8BUai1RuBw%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/h36lsmvq/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/h36lsmvq/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/h36lsmvq/file_stream HTTP/1.1\" 200 220\n",
      "wandb:                                                                                \n",
      "wandb:  View run train-27 at: https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/h36lsmvq\n",
      "wandb:  View project at: https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240608_031543-h36lsmvq/logs\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): o151352.ingest.sentry.io:443\n",
      "DEBUG:urllib3.connectionpool:https://o151352.ingest.sentry.io:443 \"POST /api/4504800232407040/envelope/ HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 880\n",
      "wandb: Agent Starting Run: vfwp03bn with config:\n",
      "wandb: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cpu', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 5, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 128}\n",
      "wandb: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "wandb: \tmodel_type: HER_DDPG\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train config: {'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "Loaded sweep config: {'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cpu'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n",
      "setup wandb called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 782\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 15\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 965\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): pypi.org:443\n",
      "DEBUG:urllib3.connectionpool:https://pypi.org:443 \"GET /pypi/wandb/json HTTP/1.1\" 200 87238\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:git.cmd:Popen(['git', 'rev-parse', '--show-toplevel'], cwd=/workspaces/RL_Agents, stdin=None, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "wandb: Tracking run with wandb version 0.17.1\n",
      "wandb: Run data is saved locally in /workspaces/RL_Agents/pytorch/src/app/wandb/run-20240608_031559-vfwp03bn\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run train-28\n",
      "wandb:  View project at https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb:  View sweep at https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/1bgdi8sq\n",
      "wandb:  View run at https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vfwp03bn\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1879\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 590\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): storage.googleapis.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called in setup wandb\n",
      "load weights:False\n",
      "num_episodes:10\n",
      "render:False\n",
      "render freq:0\n",
      "save dir:HER_Test\n",
      "seed:42\n",
      "run number:None\n",
      "use mpi:True\n",
      "passed assert\n",
      "if wandb run fired\n",
      "{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}\n",
      "Environment created: <TimeLimit<OrderEnforcing<PassiveEnvChecker<MujocoFetchReachEnv<FetchReach-v2>>>>>\n",
      "if model type = HER_DDPG called\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "sweep use_mpi fired\n",
      "agent config path: HER_Test/her/config.json\n",
      "train config path: sweep/train_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/vfwp03bn/wandb-metadata.json?Expires=1717902966&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=Iyw4Yh2%2Beyap%2FHo5VFrT2faOHgLFvfBgAEefg8UncBw6A%2B15iGMrArCtdff6D72tffMzwihLSgmS0LU%2F4zXNwUkJmTv3NsWt45%2BV4dC%2FO49sETMB7W4izs%2FBxb8k55jNHHFlNRHEctuChFhnwdYMJ88m0WN6FbRR%2BpmiZFUTJupKdFx2ZGEWB9FM7C7X6fQdbeM5htAGwJff59sZy7NMcMvO4yNhoxHygBCdiEVWV1Gmp0%2F15YKsO8pvytMD7YRZl5KZD%2FHl71cHSp3O%2Beqze04rCru2Icz%2BrT7R%2F6dPDoES7ozjvaMTWrL0qPD10Jy0KHlXro%2F6tzJNDMXxV%2Bq9kg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 47\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/vfwp03bn/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/vfwp03bn/file_stream HTTP/1.1\" 200 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Output:\n",
      "train_her_mpi fired\n",
      "mpi agent config loaded:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "mpi train config loaded:{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': True, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n",
      "mpi train agent fired\n",
      "mpi assert passed\n",
      "if agent passed in mpi\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "mpi agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'merged_layers': [[64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}], [64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}]], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': [3], 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': [4], 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': None, 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 5, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cpu', 'save_dir': 'HER_Test/her/'}\n",
      "\n",
      "Standard Error:\n",
      "2024-06-08 03:16:08,303 - ERROR - An unexpected error occurred during training\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 68, in <module>\n",
      "    train_agent(agent_config, train_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/train_her_mpi.py\", line 46, in train_agent\n",
      "    agent.train(num_epochs, num_cycles, num_episodes, num_updates, render, render_freq, save_dir, run_number)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_agents.py\", line 2218, in train\n",
      "    callback.on_train_step_end(step=step_counter, logs=self.agent._train_step_config)\n",
      "  File \"/workspaces/RL_Agents/pytorch/src/app/rl_callbacks.py\", line 108, in on_train_step_end\n",
      "    wandb.log(logs, step=step)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "\n",
      "Subprocess failed with return code 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/vfwp03bn/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 975\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 575\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 592\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 570\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (3): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 578\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (4): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 579\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (5): storage.googleapis.com:443\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/vfwp03bn/config.yaml?Expires=1717902971&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=eqyQ5m%2FBT18uL%2BK3%2BqoSIKgjb5n4QlaqZgS0Ow1amgvg3aM5YwjAyl%2FyUlk%2BehfCr8cH5SaCLtGpM8p2HQlgfu9xMxqmcKiOqFaMhGajFY8QZmy97k3COgpmurWFCGt%2FVMF4uQuG5arDwBNML4GWPf0rYemZ9h4NQjVS3O9liy7UH5p39U%2FItp4KZNGoFs9rvW%2FxO2rf6k8PUUiuZ3eyOCt1JfdWEUYb1UQ2QVV9pDuzZtaUxdiS0q7rRKNZJhF95L50EIrjcYLXvNjPkmj2ZvKNlSQpu402mQg8F8i8VIzcfxusMm%2F7vNEAULDyBjkyxGacwBd5mOCBoQa2UBMJvg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/vfwp03bn/conda-environment.yaml?Expires=1717902971&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=p6HbFBb7YDV0zk9J%2FNkPATp2PB0lV3%2FioFy6Snal9Fpyq%2Bvqyoag4%2BFcN8XQzr9oXX6RpEnImvzC3ZAPzF%2FRMHAZSM3p62BnER7NRo4Y8Zad%2FCVMe1cs3WIyKX9Rb3w9WQ5ySLBPm5MGrmPN4zBTgL%2BFzpyfUvtUepXFfz5F%2BIbTcs0Qx7d%2FXNB5LFwaczCjtdizLeADRuoLrpnCsOB3Cu%2FYhU8%2FTErIZ7cgSpnYN%2B8tLUCnZ2teC0qE8MxCTZ%2Fd%2B6grF5zL7GaRXU58L9UHrHMh777jnZg3ObGqXzkE8Le1qlYbOr%2BItf2FTFCKmJ%2Bs8qms7bh3yhO6nfCO1O2pig%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/vfwp03bn/output.log?Expires=1717902971&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=t9ZtZo3m%2B6xLoN5tue5AsVaMXI9qQwkjsXhoJdTUbWXQ2e8QggnjJYFlLPsYlVI%2BOLgk6sOsaBEcrfN2CJxdl35kGUksWFDVp1FIKBMaldBOY99xycPjYWUZMotR0nadiN9KcW4QzWRidMY1BX6nI55043Moz6nh050oMBU5o7TOn2GyCK57pg7AcS3IY9F%2B7l40hCiyoGQ6miSR2pcIyRMpBhtazgnNZBcb4h0IA0oUlHFuaDjUZ9QS1439EVnMhRFuqL06NPvEAZxOKKopK3bwIolHW4GCfFTN%2BKYhhAnlTn31Y28h0k3UitOZb2SjFbn1%2Fv44IPQytKvrVsCuAQ%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/vfwp03bn/requirements.txt?Expires=1717902971&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=wVNY9ruZcMrp8UKgS0HESsKAtoZ%2FLkCsw%2F7cp44dvjPp8gtxkIBNtFIWI8Ofmuk65zo3LjUhKUI1NRZzm6ijueevZvsEmcWgmK%2F501fdcyLR46NVBZqKBof2gfpCKgY4A3qgFlGHPhsI93n4o%2BW5Wzn%2FUTtQ2l0InZXlE77qrxNe7IMleJM5Kz3crRMyRm7LelOSA77m6QWhUbDskzEU6qf5vExh6Ljj%2F1DdkGhkzAx999RKDXmP7oX4P0%2FlBLBttoTdYMj97S9WFt4iabnjcBido4CP96xijiqCDobisLPAnv6roIzNH92%2Bv4y5cEV3pLtQiEkmVmtAOVOyGsfIng%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://storage.googleapis.com:443 \"PUT /wandb-production.appspot.com/jasonhayes1987/FetchReach-v2/vfwp03bn/wandb-summary.json?Expires=1717902971&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=kj1xn5YwtFTcOTqPji8SB4cEeK7X5uVf4cTBYErH9uqhKSYMVfK70TDu1VaDDpkWZuScTqkMZegIM%2FXku3NGIX71dWebtJ7sA1JWcxgkge%2BmeLkUTt9z%2F8jrE697%2Bp2I5wcLwVOiXdGk7mIVU42cv6RDaslL7B2c0EbAbONJYR6FEh7AB0YmoTAJTgnIkHybgOmIes3%2Bd95pppMhhL3eFED1NsrettJ2oNBcq%2BrjWSYgdaodu4rv9BjzxbFYtBGjOEcAYb208YwUW7637ghFzyiikGDfZJshqqxMMattrJDhjCSuNNBY2EKc7c2D4fJIp0khc%2BpzL8THobqtYhDdIg%3D%3D HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/vfwp03bn/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/vfwp03bn/file_stream HTTP/1.1\" 200 216\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /files/jasonhayes1987/FetchReach-v2/vfwp03bn/file_stream HTTP/1.1\" 200 220\n",
      "wandb:                                                                                \n",
      "wandb:  View run train-28 at: https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vfwp03bn\n",
      "wandb:  View project at: https://wandb.ai/jasonhayes1987/FetchReach-v2\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240608_031559-vfwp03bn/logs\n"
     ]
    }
   ],
   "source": [
    "command = ['python', 'sweep.py']\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['WANDB_DISABLE_SERVICE'] = 'true'\n",
    "\n",
    "subprocess.Popen(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
