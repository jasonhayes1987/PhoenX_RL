{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch_utils\n",
    "from torch import distributions\n",
    "\n",
    "import gymnasium as gym\n",
    "import gymnasium_robotics as gym_robo\n",
    "import models\n",
    "import cnn_models\n",
    "import rl_agents\n",
    "import rl_callbacks\n",
    "import helper\n",
    "import gym_helper\n",
    "import wandb_support\n",
    "import wandb\n",
    "import gym_helper\n",
    "\n",
    "# from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.MjModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_robo.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Returns the default device for computations, GPU if available, otherwise CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_robo.register_robotics_envs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.registration.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key='758ac5ba01e12a3df504d2db2fec8ba4f391f7e6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2', max_episode_steps=100, render_mode='rgb_array')\n",
    "env = gym.wrappers.RecordVideo(env, 'test/', episode_trigger=lambda i: i%1==0)\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs, _ = env.reset()\n",
    "    while not done:\n",
    "        obs, r, term, trunc, dict = env.step(env.action_space.sample())\n",
    "        if term or trunc:\n",
    "            done = True\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v2\")\n",
    "env.reset()\n",
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "\n",
    "# The following always has to hold:\n",
    "assert reward == env.compute_reward(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n",
    "assert truncated == env.compute_truncated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)\n",
    "assert terminated == env.compute_terminated(obs[\"achieved_goal\"], obs[\"desired_goal\"], info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.compute_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(env, \"distance_threshold\"):\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env.get_wrapper_attr(\"distance_threshold\"):\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(env))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.01}, learning_rate=0.001, normalize_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.target_actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers,\n",
    "                            optimizer='Adam', optimizer_params={'weight_decay':0.01}, learning_rate=0.002, normalize_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 100000)\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.99,\n",
    "                            tau=0.005,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.target_critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.train(100, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [\n",
    "    (128, 'relu', \"kaiming normal\"),\n",
    "    (256, 'relu', \"kaiming normal\"),\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = models.PolicyModel(env=env, dense_layers=dense_layers, optimizer='Adam', learning_rate=0.001,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in policy_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = models.ValueModel(env, dense_layers=dense_layers, optimizer='Adam', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in value_model.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = rl_agents.ActorCritic(env,\n",
    "                                     policy_model,\n",
    "                                     value_model,\n",
    "                                     discount=0.99,\n",
    "                                     policy_trace_decay=0.5,\n",
    "                                     value_trace_decay=0.5,\n",
    "                                     callbacks=[rl_callbacks.WandbCallback('CartPole-v1-Actor-Critic')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic.train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [\n",
    "    (128, 'relu', {\n",
    "                    \"kaiming normal\": {\n",
    "                        \"a\":1.0,\n",
    "                        \"mode\":'fan_in'\n",
    "                    }\n",
    "                },\n",
    "    ),\n",
    "    # (256, 'relu', {\n",
    "    #                 \"kaiming_normal\": {\n",
    "    #                     \"a\":0.0,\n",
    "    #                     \"mode\":'fan_in'\n",
    "    #                 }\n",
    "    #             },\n",
    "    # )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [(128, 'relu', \"kaiming normal\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = models.ValueModel(env, dense_layers, 'Adam', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in value_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = models.PolicyModel(env, dense_layers, 'Adam', 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in policy_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce = rl_agents.Reinforce(env, policy_model, value_model, 0.99, [rl_callbacks.WandbCallback('CartPole-v0_REINFORCE', chkpt_freq=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce.train(200, True, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG w/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layers = [\n",
    "    # {\n",
    "    #     \"batchnorm\":\n",
    "    #     {\n",
    "    #         \"num_features\":3\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 7,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_models.CNN(cnn_layers, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=cnn, dense_layers=dense_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=cnn, state_layers=state_layers, merged_layers=merged_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape=(1,))\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, mean=0.0, theta=0.15, sigma=0.01, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(\n",
    "    env,\n",
    "    actor,\n",
    "    critic,\n",
    "    discount=0.98,\n",
    "    tau=0.05,\n",
    "    action_epsilon=0.2,\n",
    "    replay_buffer=replay_buffer,\n",
    "    batch_size=128,\n",
    "    noise=noise,\n",
    "    callbacks=[rl_callbacks.WandbCallback(\"CarRacing-v2\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.train(1000, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Reacher-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieved_goal = gym_helper.reacher_achieved_goal(env)\n",
    "action = env.action_space.sample()\n",
    "env.step(action)\n",
    "print(f'observation: {env.get_wrapper_attr(\"_get_obs\")()}')\n",
    "print(f'distance to goal: {env.get_wrapper_attr(\"_get_obs\")()[8::]}')\n",
    "print(f'fingertip: {env.get_wrapper_attr(\"get_body_com\")(\"fingertip\")}')\n",
    "print(f'target: {env.get_wrapper_attr(\"get_body_com\")(\"target\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_achieved_goal = env.get_wrapper_attr(\"_get_obs\")()[8::]\n",
    "desired_goal = [0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func(env, action, achieved_goal, next_achieved_goal, desired_goal, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env,\n",
    "                          cnn_model=None,\n",
    "                          dense_layers=dense_layers,\n",
    "                          goal_shape=(3,),\n",
    "                          optimizer=\"Adam\",\n",
    "                          optimizer_params={'weight_decay':0.0},\n",
    "                          learning_rate=0.0001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env,\n",
    "                            cnn_model=None,\n",
    "                            state_layers=state_layers,\n",
    "                            merged_layers=merged_layers,\n",
    "                            goal_shape=(3,),\n",
    "                            optimizer=\"Adam\",\n",
    "                            optimizer_params={'weight_decay':0.0},\n",
    "                            learning_rate=0.0001,\n",
    "                            normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape\n",
    "replay_buffer = helper.ReplayBuffer(env, 100000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape,\n",
    "#                        mean=0.0,\n",
    "#                        theta=0.05,\n",
    "#                        sigma=0.15,\n",
    "#                        dt=1.0, device='cuda')\n",
    "\n",
    "noise=helper.NormalNoise(shape=env.action_space.shape,\n",
    "                         mean = 0.0,\n",
    "                         stddev=0.05,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Reacher-v4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(ddpg_agent,\n",
    "                    strategy='future',\n",
    "                    num_goals=4,\n",
    "                    tolerance=0.001,\n",
    "                    desired_goal=desired_goal_func,\n",
    "                    achieved_goal=achieved_goal_func,\n",
    "                    reward_fn=reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(10, 50, 16, 40, True, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.goal_normalizer.running_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.agent.replay_buffer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.agent.state_normalizer.running_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_her.test(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER w/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layers = [\n",
    "    # {\n",
    "    #     \"batchnorm\":\n",
    "    #     {\n",
    "    #         \"num_features\":3\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 7,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 5,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"relu\":\n",
    "        {\n",
    "\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"batchnorm\":\n",
    "        {\n",
    "            \"num_features\":32\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"conv\":\n",
    "        {\n",
    "            \"out_channels\": 32,\n",
    "            \"kernel_size\": 3,\n",
    "            \"stride\": 3,\n",
    "            \"padding\": 'valid',\n",
    "            \"bias\": False,\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "cnn = cnn_models.CNN(cnn_layers, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env,\n",
    "                          cnn_model=cnn,\n",
    "                          dense_layers=dense_layers,\n",
    "                          goal_shape=(1,),\n",
    "                          optimizer=\"Adam\",\n",
    "                          optimizer_params={'weight_decay':0.0},\n",
    "                          learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        256,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env,\n",
    "                            cnn_model=cnn,\n",
    "                            state_layers=state_layers,\n",
    "                            merged_layers=merged_layers,\n",
    "                            goal_shape=(1,),\n",
    "                            optimizer=\"Adam\",\n",
    "                            optimizer_params={'weight_decay':0.0},\n",
    "                            learning_rate=0.001,\n",
    "                            normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape\n",
    "replay_buffer = helper.ReplayBuffer(env, 100000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape,\n",
    "#                        mean=0.0,\n",
    "#                        theta=0.05,\n",
    "#                        sigma=0.15,\n",
    "#                        dt=1.0, device='cuda')\n",
    "\n",
    "noise=helper.NormalNoise(shape=env.action_space.shape,\n",
    "                         mean = 0.0,\n",
    "                         stddev=0.05,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('CarRacing-v2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(ddpg_agent,\n",
    "                    strategy='future',\n",
    "                    num_goals=4,\n",
    "                    tolerance=1,\n",
    "                    desired_goal=desired_goal_func,\n",
    "                    achieved_goal=achieved_goal_func,\n",
    "                    reward_fn=reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.actor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=20,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=20\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset environment\n",
    "state, _ = her.agent.env.reset()\n",
    "# instantiate empty lists to store current episode trajectory\n",
    "states, actions, next_states, dones, state_achieved_goals, \\\n",
    "next_state_achieved_goals, desired_goals = [], [], [], [], [], [], []\n",
    "# set desired goal\n",
    "desired_goal = her.desired_goal_func(her.agent.env)\n",
    "# set achieved goal\n",
    "state_achieved_goal = her.achieved_goal_func(her.agent.env)\n",
    "# add initial state and goals to local normalizer stats\n",
    "her.state_normalizer.update_local_stats(state)\n",
    "her.goal_normalizer.update_local_stats(desired_goal)\n",
    "her.goal_normalizer.update_local_stats(state_achieved_goal)\n",
    "# set done flag\n",
    "done = False\n",
    "# reset episode reward to 0\n",
    "episode_reward = 0\n",
    "# reset steps counter for the episode\n",
    "episode_steps = 0\n",
    "\n",
    "while not done:\n",
    "    # get normalized values for state and desired goal\n",
    "    state_norm = her.state_normalizer.normalize(state)\n",
    "    desired_goal_norm = her.goal_normalizer.normalize(desired_goal)\n",
    "    # get action\n",
    "    action = her.agent.get_action(state_norm, desired_goal_norm, grad=False)\n",
    "    # take action\n",
    "    next_state, reward, term, trunc, _ = her.agent.env.step(action)\n",
    "    # get next state achieved goal\n",
    "    next_state_achieved_goal = her.achieved_goal_func(her.agent.env)\n",
    "    # add next state and next state achieved goal to normalizers\n",
    "    her.state_normalizer.update_local_stats(next_state)\n",
    "    her.goal_normalizer.update_local_stats(next_state_achieved_goal)\n",
    "    # store trajectory in replay buffer (non normalized!)\n",
    "    her.agent.replay_buffer.add(state, action, reward, next_state, done,\\\n",
    "                                    state_achieved_goal, next_state_achieved_goal, desired_goal)\n",
    "    \n",
    "    # append step state, action, next state, and goals to respective lists\n",
    "    states.append(state)\n",
    "    actions.append(action)\n",
    "    next_states.append(next_state)\n",
    "    dones.append(done)\n",
    "    state_achieved_goals.append(state_achieved_goal)\n",
    "    next_state_achieved_goals.append(next_state_achieved_goal)\n",
    "    desired_goals.append(desired_goal)\n",
    "\n",
    "    # add to episode reward and increment steps counter\n",
    "    episode_reward += reward\n",
    "    episode_steps += 1\n",
    "    # update state and state achieved goal\n",
    "    state = next_state\n",
    "    state_achieved_goal = next_state_achieved_goal\n",
    "    # update done flag\n",
    "    if term or trunc:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package episode states, actions, next states, and goals into trajectory tuple\n",
    "trajectory = (states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals = trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (s, a, ns, d, sag, nsag, dg) in enumerate(zip(states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)):\n",
    "    print(f'a={a}, d={d}, sag={sag}, nsag={nsag}, dg={dg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"future\"\n",
    "num_goals = 4\n",
    "\n",
    "# loop over each step in the trajectory to set new achieved goals, calculate new reward, and save to replay buffer\n",
    "for idx, (state, action, next_state, done, state_achieved_goal, next_state_achieved_goal, desired_goal) in enumerate(zip(states, actions, next_states, dones, state_achieved_goals, next_state_achieved_goals, desired_goals)):\n",
    "\n",
    "    if strategy == \"final\":\n",
    "        new_desired_goal = next_state_achieved_goals[-1]\n",
    "        new_reward = her.reward_fn(state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "        print(f'transition: action={action}, reward={new_reward}, done={done}, state_achieved_goal={state_achieved_goal}, next_state_achieved_goal={next_state_achieved_goal}, desired_goal={new_desired_goal}')\n",
    "        her.agent.replay_buffer.add(state, action, new_reward, next_state, done, state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "\n",
    "    if strategy == 'future':\n",
    "        for i in range(num_goals):\n",
    "            if idx + i + 1 >= len(states):\n",
    "                break\n",
    "            goal_idx = np.random.randint(idx + 1, len(states))\n",
    "            new_desired_goal = next_state_achieved_goals[goal_idx]\n",
    "            new_reward = her.reward_fn(state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "            print(f'transition: action={action}, reward={new_reward}, done={done}, state_achieved_goal={state_achieved_goal}, next_state_achieved_goal={next_state_achieved_goal}, desired_goal={new_desired_goal}')\n",
    "            her.agent.replay_buffer.add(state, action, new_reward, next_state, done, state_achieved_goal, next_state_achieved_goal, new_desired_goal)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a, r, ns, d, sag, nsag, dg = her.agent.replay_buffer.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f'{i}: a={a[i]}, r={r[i]}, d={d[i]}, sag={sag[i]}, nsag={nsag[i]}, dg={dg[i]} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        400,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        300,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"variance scaling\": {\n",
    "                \"scale\": 1.0,\n",
    "                \"mode\": \"fan_in\",\n",
    "                \"distribution\": \"uniform\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.01}, learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.001, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 100000, (3,))\n",
    "noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.99,\n",
    "                            tau=0.005,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback('Pendulum-v1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_goal_func(env):\n",
    "    return np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "def achieved_goal_func(env):\n",
    "    return env.get_wrapper_attr('_get_obs')()\n",
    "\n",
    "def reward_func(env):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='none',\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.target_critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(1,1,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.observation_space.sample()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.state_normalizer.normalize(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = her.desired_goal_func(her.agent.env)\n",
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.goal_normalizer.normalize(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_renders(folder_path):\n",
    "    # Iterate over the files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has a .mp4 or .meta.json extension\n",
    "        if filename.endswith(\".mp4\") or filename.endswith(\".meta.json\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Remove the file\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_renders(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/ddpg/renders/training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Fetch-Reach (Robotics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v2\", max_episode_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieved_goal_func(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_wrapper_attr(\"_get_obs\")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.2,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=256,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchReach-v2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent.critic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='future',\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=50,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, action, rewards, next_states, dones, achieved_goals, next_achieved_goals, desired_goals = her.agent.replay_buffer.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.env.get_wrapper_attr(\"distance_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get success\n",
    "her.agent.env.get_wrapper_attr(\"_is_success\")(achieved_goal_func(her.agent.env), desired_goal_func(her.agent.env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.agent.env.get_wrapper_attr(\"goal_distance\")(next_state_achieved_goal, desired_goal, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her = rl_agents.HER.load(\"/workspaces/RL_Agents/pytorch/src/app/assets/models/her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.agent.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(pusher_her.agent.env.get_wrapper_attr(\"get_body_com\")(\"goal\") - pusher_her.agent.env.get_wrapper_attr(\"get_body_com\")(\"object\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher_her.agent.replay_buffer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pusher_her.agent.replay_buffer.desired_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST ENV\n",
    "env = gym.make(\"Pusher-v5\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.wrappers.RecordVideo(\n",
    "                    env,\n",
    "                    \"/renders/training\",\n",
    "                    episode_trigger=lambda x: True,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "# take action\n",
    "    next_state, reward, term, trunc, _ = env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER Fetch Push (Robitics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.3,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=128,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchPush-v2\")],\n",
    "                            save_dir=\"fetch_push/models/ddpg/\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='final',\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0,\n",
    "    save_dir=\"fetch_push/models/her/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train(num_epochs=50,\n",
    "          num_cycles=50,\n",
    "          num_episodes=16,\n",
    "          num_updates=40,\n",
    "          render=True,\n",
    "          render_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MULTITHREADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchPush-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_goal_func, achieved_goal_func, reward_func = gym_helper.get_her_goal_functions(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_shape = desired_goal_func(env).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actor\n",
    "\n",
    "dense_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "actor = models.ActorModel(env, cnn_model=None, dense_layers=dense_layers, goal_shape=goal_shape, optimizer='Adam',\n",
    "                          optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build critic\n",
    "\n",
    "state_layers = [\n",
    "    \n",
    "]\n",
    "\n",
    "merged_layers = [\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "               \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        64,\n",
    "        \"relu\",\n",
    "        {\n",
    "            \"kaiming uniform\": {\n",
    "                \n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "critic = models.CriticModel(env=env, cnn_model=None, state_layers=state_layers, merged_layers=merged_layers, goal_shape=goal_shape, optimizer=\"Adam\", optimizer_params={'weight_decay':0.0}, learning_rate=0.00001, normalize_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = helper.ReplayBuffer(env, 1000000, goal_shape)\n",
    "# noise = helper.OUNoise(shape=env.action_space.shape, dt=1.0, device='cuda')\n",
    "noise = helper.NormalNoise(shape=env.action_space.shape, mean=0.0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_agent = rl_agents.DDPG(env=env,\n",
    "                            actor_model=actor,\n",
    "                            critic_model=critic,\n",
    "                            discount=0.98,\n",
    "                            tau=0.05,\n",
    "                            action_epsilon=0.3,\n",
    "                            replay_buffer=replay_buffer,\n",
    "                            batch_size=128,\n",
    "                            noise=noise,\n",
    "                            callbacks=[rl_callbacks.WandbCallback(\"FetchPush-v2\")],\n",
    "                            save_dir=\"fetch_push/models/ddpg/\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her = rl_agents.HER(\n",
    "    agent=ddpg_agent,\n",
    "    strategy='final',\n",
    "    num_workers=4,\n",
    "    tolerance=0.05,\n",
    "    num_goals=4,\n",
    "    desired_goal=desired_goal_func,\n",
    "    achieved_goal=achieved_goal_func,\n",
    "    reward_fn=reward_func,\n",
    "    normalizer_clip=5.0,\n",
    "    save_dir=\"fetch_push/models/her/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config_path = \"/workspaces/RL_Agents/pytorch/src/app/HER_Test/her/config.json\"\n",
    "with open(config_path, 'r') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = rl_agents.HER.load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for callback in agent.agent.callbacks:\n",
    "    print(callback._sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cuda'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.03]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64]}, 'actor_units_layer_2_HER_DDPG': {'values': [64]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'assets/wandb_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    wandb_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': False, 'num_workers': None, 'num_agents': None, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': None}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'assets/sweep_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    sweep_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated configuration to a train config file\n",
    "os.makedirs('sweep', exist_ok=True)\n",
    "train_config_path = os.path.join(os.getcwd(), 'sweep/train_config.json')\n",
    "with open(train_config_path, 'w') as f:\n",
    "    json.dump(sweep_config, f)\n",
    "\n",
    "# Save and Set the sweep config path\n",
    "sweep_config_path = os.path.join(os.getcwd(), 'sweep/sweep_config.json')\n",
    "with open(sweep_config_path, 'w') as f:\n",
    "    json.dump(wandb_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['python', 'sweep.py']\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['WANDB_DISABLE_SERVICE'] = 'true'\n",
    "\n",
    "subprocess.Popen(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable\n",
    "os.environ['WANDB_DISABLE_SERVICE'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'bayes', 'project': 'FetchReach-v2', 'name': 'Test', 'metric': {'name': 'episode_reward', 'goal': 'maximize'}, 'parameters': {'env': {'parameters': {'id': {'value': 'FetchReach-v2'}, 'max_episode_steps': {'value': 50}}}, 'model_type': {'values': ['HER_DDPG']}, 'HER_DDPG': {'parameters': {'HER_DDPG_actor_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_critic_learning_rate': {'values': [1e-05, 0.0001]}, 'HER_DDPG_goal_strategy': {'values': ['future']}, 'HER_DDPG_num_goals': {'min': 4, 'max': 8}, 'HER_DDPG_goal_tolerance': {'values': [0.05]}, 'HER_DDPG_discount': {'values': [0.9, 0.99]}, 'HER_DDPG_tau': {'values': [0.05]}, 'HER_DDPG_epsilon_greedy': {'values': [0.2, 0.3]}, 'HER_DDPG_normalizer_clip': {'values': [5]}, 'HER_DDPG_device': {'value': 'cuda'}, 'HER_DDPG_actor_num_cnn_layers': {'value': 0}, 'HER_DDPG_actor_num_layers': {'value': 2}, 'HER_DDPG_actor_activation': {'values': ['relu']}, 'HER_DDPG_actor_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_actor_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_actor_optimizer': {'values': ['Adam']}, 'HER_DDPG_actor_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_actor_normalize_layers': {'values': [False]}, 'HER_DDPG_actor_clamp_output': {'values': [0.04]}, 'HER_DDPG_critic_num_cnn_layers': {'value': 0}, 'HER_DDPG_critic_state_num_layers': {'value': 2}, 'HER_DDPG_critic_merged_num_layers': {'value': 2}, 'HER_DDPG_critic_activation': {'values': ['relu']}, 'HER_DDPG_critic_hidden_kernel_initializer': {'values': ['kaiming_uniform']}, 'HER_DDPG_critic_output_kernel_initializer': {'values': ['constant']}, 'HER_DDPG_critic_optimizer': {'values': ['Adam']}, 'HER_DDPG_critic_optimizer_Adam_options': {'parameters': {'Adam_weight_decay': {'values': [0]}}}, 'HER_DDPG_critic_normalize_layers': {'values': [False]}, 'HER_DDPG_replay_buffer_size': {'values': [100000]}, 'HER_DDPG_batch_size': {'values': [128, 256]}, 'HER_DDPG_noise': {'values': ['Normal']}, 'HER_DDPG_noise_Normal': {'parameters': {'mean': {'values': [0]}, 'stddev': {'values': [0.05]}}}, 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_actor_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'parameters': {'kaiming_uniform_mode': {'values': ['fan_in']}}}, 'HER_DDPG_critic_output_kernel_constant': {'parameters': {'constant_value': {'values': [0.003]}}}, 'actor_units_layer_1_HER_DDPG': {'values': [64, 128]}, 'actor_units_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_state_layer_2_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_1_HER_DDPG': {'values': [64, 128]}, 'critic_units_merged_layer_2_HER_DDPG': {'values': [64, 128]}, 'HER_DDPG_save_dir': {'value': 'HER_Test'}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'sweep/sweep_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    sweep_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_sweeps': 5, 'num_episodes': 10, 'seed': 42, 'use_mpi': False, 'num_workers': 1, 'num_agents': 1, 'num_epochs': 1, 'num_cycles': 1, 'num_updates': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your JSON configuration file\n",
    "config_file_path = 'sweep/train_config.json'\n",
    "\n",
    "# Read the JSON configuration file\n",
    "with open(config_file_path, 'r') as file:\n",
    "    train_config = json.load(file)\n",
    "\n",
    "# Print the configuration to verify it has been loaded correctly\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 189\n",
      "INFO:wandb.agents.pyagent:Starting sweep agent: entity=None, project=FetchReach-v2, count=5\n",
      "DEBUG:wandb.agents.pyagent:Agent._setup()\n",
      "DEBUG:wandb.agents.pyagent:Agent._register()\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 68\n",
      "DEBUG:wandb.agents.pyagent:agent_id = QWdlbnQ6ajh4dmtpczg=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 5vujbkhg\n",
      "Sweep URL: https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 808\n",
      "DEBUG:wandb.agents.pyagent:Job received: Job(lqtsr2zi,{'HER_DDPG': {'value': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 128}}, 'env': {'value': {'id': 'FetchReach-v2', 'max_episode_steps': 50}}, 'model_type': {'value': 'HER_DDPG'}})\n",
      "DEBUG:wandb.agents.pyagent:Spawning new thread for run lqtsr2zi.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lqtsr2zi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 128}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjasonhayes1987\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235406-lqtsr2zi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi' target=\"_blank\">hardy-sweep-1</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 128}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lqtsr2zi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-1</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235406-lqtsr2zi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lqtsr2zi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235412-lqtsr2zi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi' target=\"_blank\">train-43</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-43', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-43', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -50.0, avg episode time 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▇▅█▇██▇█▇▇█▇▇█▇▇▇█▇▄▇▁▇█▇▇▇████▇▇▇█▇███▅</td></tr><tr><td>action_1</td><td>▁▃▂▃▂▄▃▄▃▁▃▃▄█▂▄▂▂▂▇▂▃▂▃▂▄▃▂▃▂▃▃▄▃▃▇▂▃▂▁</td></tr><tr><td>action_2</td><td>▃▄▄▃▄▃▄▄▄▄▄▃▄▃▃▄▄▃▄▁▃█▃▃▄▃▄▄▃▄▃▄▃▄▄▆▄▄▄▂</td></tr><tr><td>action_3</td><td>▅█▅▆▆▅▆▅▅▅▅▅▆▆▅▆▆▅▅▁▅▅▆▅▆▆▅▅▆▅▆▅▅▅▅▇▅▅▆▁</td></tr><tr><td>actor_loss</td><td>▁▃▁▄▂▆▄▇▆█</td></tr><tr><td>actor_predictions</td><td>▄▄▄▄▄████▄▄▄▄▄▄▄▄▄▁▁▁▁▆▆▆▆▆▅▅▅▅▆▆▆▆▆▂▂▂▂</td></tr><tr><td>avg_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>best</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▆█▅▁▄█▂▇▇▇</td></tr><tr><td>critic_predictions</td><td>█████▄▄▄▄▅▅▅▅▄▄▄▄▄▄▄▄▄▅▅▅▅▅▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>█▁▁▁▁▁▂▂▃▂</td></tr><tr><td>goal_distance</td><td>▁▂▄▂▃▃▅▅▃▃▃▅▃▄▅▄▂▃▃▃▄▆▅▅▂▂▁▁▂▃▃▆▂▂▃▃▆▇██</td></tr><tr><td>noise_0</td><td>▃▄▆▅▅▆▃▆▃▃▆▄▅▄▂▁▃█▂▄▃▄▅▅▅▃▅▇▅▆▆▂▂▃▇▄▅▆▅▄</td></tr><tr><td>noise_1</td><td>▁▅▄▅▄█▅▇▄▁▄▆▇▅▃▆▃▃▃▅▂▅▁▄▄▆▆▃▄▄▅▄█▆▅▅▃▄▃▅</td></tr><tr><td>noise_2</td><td>▂▄▃▁▄▂▆▇▅▅▇▁▃▄▃▅▄▃▅▄▃▄▃▃▇▂▃▆▁▄▁▃▂██▄▄▄▆▄</td></tr><tr><td>noise_3</td><td>▂▄▅▆▇▅▆▄▅▄▁▅█▄▁▆▆▄▃▄▄▄▇▅▆▇▁▃▇▅▆▄▁▄▅▄▅▄█▄</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>█▂█▅▆▃▃▃▄▃▄▃▄▁▅▃▃▄▅▁▄▁▄▃▃▆▆▅▅▅▄▆▄▄▆▁▆▆▃▂</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>▃▃▃▃▃████▂▂▂▂▁▁▁▁▁▁▁▁▁▆▆▆▆▆▅▅▅▅▆▆▆▆▆▄▄▄▄</td></tr><tr><td>target_critic_predictions</td><td>█████▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃█████▃▃▃▃▁▁▁▁▁▃▃▃▃</td></tr><tr><td>tolerance count</td><td>▄▂▃█▃▄▂▁▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.12297</td></tr><tr><td>action_1</td><td>0.01649</td></tr><tr><td>action_2</td><td>0.07129</td></tr><tr><td>action_3</td><td>0.09968</td></tr><tr><td>actor_loss</td><td>-0.01392</td></tr><tr><td>actor_predictions</td><td>0.03265</td></tr><tr><td>avg_reward</td><td>-50.0</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.58729</td></tr><tr><td>critic_predictions</td><td>0.01558</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.14724</td></tr><tr><td>goal_distance</td><td>0.33437</td></tr><tr><td>noise_0</td><td>0.08297</td></tr><tr><td>noise_1</td><td>-0.02351</td></tr><tr><td>noise_2</td><td>0.03129</td></tr><tr><td>noise_3</td><td>0.05968</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00169</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.03388</td></tr><tr><td>target_critic_predictions</td><td>0.01629</td></tr><tr><td>tolerance count</td><td>94</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-43</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/lqtsr2zi</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235412-lqtsr2zi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bv4hqub1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 6, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235437-bv4hqub1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1' target=\"_blank\">ethereal-sweep-2</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 6, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 64}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bv4hqub1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-2</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235437-bv4hqub1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bv4hqub1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235444-bv4hqub1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1' target=\"_blank\">train-44</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-44', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 6, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-44', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 6, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -47.8, avg episode time 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▄▄▅▄▅█▄▂▄▅▃▁▅▆▄▄▅▂▄▅▅▅▂▄▄▄▅█▄▄▅▅▅▅▁▄▁▅▅▄</td></tr><tr><td>action_1</td><td>▄▄▄▄▄▅▄█▅▅▄▁▅█▅▅▄▅▅▅▄▂▇▅▅▄▅▄▅▅▄▄▅▅▅▅▂▄▅▅</td></tr><tr><td>action_2</td><td>▅▄▅▅▅▆▅▃▅▅▅▆▅█▅▅▅▇▅▅▅▆▆▅▅▄▅▃▅▅▅▄▅▅▃▅▁▅▅▅</td></tr><tr><td>action_3</td><td>▅▆▅▅▆▇▆█▆▆▇▂▆█▅▅▆▃▅▅▇▁▄▅▅▆▆▂▅▆▆▅▅▅▂▆▄▆▆▅</td></tr><tr><td>actor_loss</td><td>▇▁▅▅▂▅▆▆▇█</td></tr><tr><td>actor_predictions</td><td>█████████▅▅▅▅▆▆▆▆▆▁▁▁▁▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>avg_reward</td><td>▁▁█▆▅▅▄▄▃▃</td></tr><tr><td>best</td><td>█▁█▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>█▇▂▃▁▂▁▃█▂</td></tr><tr><td>critic_predictions</td><td>▂▂▂▂▂████▄▄▄▄▄▄▄▄▄▆▆▆▆▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁█▁▁▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▁▃▃▃▅█▅▃▄▃</td></tr><tr><td>goal_distance</td><td>▅▅▆▆▃▄▄▄▃▁▂▃▅▇▇█▄▅▅▄▅▆▅▄▅▆▆▇▆▆▆▅▅▆██▅▅▆▅</td></tr><tr><td>noise_0</td><td>▃▄▄▁▅▄▄▄▄▆▄▄▄▄▂▃▅▄▂▅▄▄▄▂▃▁▅▄▃▂▄▄█▅▄▃▄▅▅▃</td></tr><tr><td>noise_1</td><td>▂▆▅▂▄▆▆▆▅█▆▆▆▆▆▇▄▆█▆▆▆▆▅▅▁▅▆▄▆▄▂▅▅▆▆▆▄▆▆</td></tr><tr><td>noise_2</td><td>▄▅▃▆▄▅▅▅▆▆▅▅▆▅▃▇▆▅▄▇▅▅▅▅█▁▄▅▂▃▄▂▆▅▅▄▅▅▄▅</td></tr><tr><td>noise_3</td><td>▃▆▆▅▇▆▆▆██▆▆▇▆▅▁▆▆▆▅▆▆▆▅▆▆▇▆▆▇█▆▅▆▆▇▆██▅</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▃▁▃▃▃▁▁▁▃▄▁▂▃▁▂▂▄▂▅▃▁▁▁▄▅▄▃▁▃▃▃▄▃█▁▃▁▃▇▃</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>█████▃▃▃▃▄▄▄▄▅▅▅▅▅▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▃▃▃▃</td></tr><tr><td>target_critic_predictions</td><td>▁▁▁▁▁▅▅▅▅▅▅▅▅▆▆▆▆▆████▆▆▆▆▆▇▇▇▇█████▆▆▆▆</td></tr><tr><td>tolerance count</td><td>▂▅▇█▆▁▅█▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.05002</td></tr><tr><td>action_1</td><td>0.05584</td></tr><tr><td>action_2</td><td>-0.02524</td></tr><tr><td>action_3</td><td>0.06455</td></tr><tr><td>actor_loss</td><td>-0.01645</td></tr><tr><td>actor_predictions</td><td>0.01903</td></tr><tr><td>avg_reward</td><td>-47.8</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.55856</td></tr><tr><td>critic_predictions</td><td>0.01688</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.14594</td></tr><tr><td>goal_distance</td><td>0.19051</td></tr><tr><td>noise_0</td><td>0.02499</td></tr><tr><td>noise_1</td><td>0.0308</td></tr><tr><td>noise_2</td><td>-0.05028</td></tr><tr><td>noise_3</td><td>0.03952</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00184</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.01922</td></tr><tr><td>target_critic_predictions</td><td>0.01745</td></tr><tr><td>tolerance count</td><td>123</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-44</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/bv4hqub1</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235444-bv4hqub1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 068g31sc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 8, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 128}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235518-068g31sc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc' target=\"_blank\">happy-sweep-3</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 8, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 128}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:068g31sc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-3</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235518-068g31sc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:068g31sc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235524-068g31sc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc' target=\"_blank\">train-45</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-45', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 8, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-45', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 8, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.1, reward -50.0, avg reward -48.7, avg episode time 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▅▆▅▅▅▅▅▅▅▅▅▅▄▅▅▁▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅█▅▅▅▅</td></tr><tr><td>action_1</td><td>▄▃▄▄▄▄▄▂▄▄▄▄▅▄▄█▄▄▄▄▄▅▄▁▄▄▄▄▄▄▄▄▄▄▄▆▄▄▄▄</td></tr><tr><td>action_2</td><td>▄▁▅▄▅▅▅▆▅▅▅▅▂▅▅█▅▅▅▅▅▅▅▁▅▅▅▅▅▄▅▅▅▄▅▆▄▅▄▅</td></tr><tr><td>action_3</td><td>▁▇▂▂▂▂▃▄▁▂▂▂▄▂▂█▁▂▂▁▂▂▂▄▂▂▁▁▂▂▂▁▂▂▂▆▂▂▂▂</td></tr><tr><td>actor_loss</td><td>█▆▂▁▂▂▃▃▄▃</td></tr><tr><td>actor_predictions</td><td>█████▇▇▇▇▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>avg_reward</td><td>▁█▆▅▄▃▃▃▃▂</td></tr><tr><td>best</td><td>██▁▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▁▁▆▇▆▇█▇▆▅</td></tr><tr><td>critic_predictions</td><td>█████▅▅▅▅▆▆▆▆█████▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▃▇▇▅▆▄▃█▇▁</td></tr><tr><td>goal_distance</td><td>▅▆▇▇▃▃▂▁▅▄▃▃▃▃▅▅▅▅▇█▅▅▅▅▆▅▅▆▂▂▂▂▅▅▄▅▅▅▆▅</td></tr><tr><td>noise_0</td><td>▃▄▆▅▅▃▅▄▅▇▇▅▄▃▅▄▅▁▅▆▆▃▄▄▆▆▅▅▅▅▃▆█▅▂▄▂▆▄▆</td></tr><tr><td>noise_1</td><td>▁▄▄▅▄▇▃▄▅▄▁▃▄▅▇▄▅▆▅▄▆█▂▄▄▃▄▆▅▄▄▇▇▆▂▄▇▃▅▃</td></tr><tr><td>noise_2</td><td>▃▄▄▂▄▄▄▄▅▄▄▅▄▅▃▄▄▆▆▃▇▆▄▄▃▇▅▄▆▂▇█▅▁▆▄▃▄▃▆</td></tr><tr><td>noise_3</td><td>▂▄▅▆▄▄█▄▂▄▅▃▄▄▆▄▁▅▄▂▃▃▄▄▅▃▂▁▆▆▅▂▄▆▅▄▅▅▄▇</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▆▁▄▄▇▄▄▁▄▄▃▃▁▃▃▁▃▃▃▄▃▃▃▁▃▃█▂▂▅▄▅▃▃▅▂▃▃▄▄</td></tr><tr><td>success_rate</td><td>▁█▆▅▄▃▃▃▃▂</td></tr><tr><td>target_actor_predictions</td><td>▄▄▄▄▄▆▆▆▆▅▅▅▅█████▁▁▁▁▇▇▇▇▇▅▅▅▅▃▃▃▃▃▂▂▂▂</td></tr><tr><td>target_critic_predictions</td><td>▄▄▄▄▄▁▁▁▁▄▄▄▄█████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>tolerance count</td><td>▆▄▃▂▁▅▁█▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>-0.01119</td></tr><tr><td>action_1</td><td>-0.07564</td></tr><tr><td>action_2</td><td>-0.00648</td></tr><tr><td>action_3</td><td>0.08877</td></tr><tr><td>actor_loss</td><td>-0.01426</td></tr><tr><td>actor_predictions</td><td>0.02145</td></tr><tr><td>avg_reward</td><td>-48.7</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.43319</td></tr><tr><td>critic_predictions</td><td>0.01475</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.13791</td></tr><tr><td>goal_distance</td><td>0.22059</td></tr><tr><td>noise_0</td><td>-0.03731</td></tr><tr><td>noise_1</td><td>-0.10179</td></tr><tr><td>noise_2</td><td>-0.03257</td></tr><tr><td>noise_3</td><td>0.06265</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.0019</td></tr><tr><td>success_rate</td><td>0.1</td></tr><tr><td>target_actor_predictions</td><td>0.03091</td></tr><tr><td>target_critic_predictions</td><td>0.0155</td></tr><tr><td>tolerance count</td><td>271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-45</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/068g31sc</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235524-068g31sc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m7tvejdj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 7, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235549-m7tvejdj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj' target=\"_blank\">kind-sweep-4</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 7, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 64}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:m7tvejdj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-4</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235549-m7tvejdj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:m7tvejdj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235556-m7tvejdj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj' target=\"_blank\">train-46</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-46', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 7, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-46', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 7, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -49.8, avg episode time 0.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▄▂▄▄▅▄▂▄▂▄▆█▄▂▄▄▅▅▄▂▄▄▄▂▃▅▄▄█▁▄▄▄▄▃▅▅▁▅▄</td></tr><tr><td>action_1</td><td>▃█▄▃▄▄▇▄▅▄▅▃▃▂▄▄▄▄▄▃▄▄▄▁█▄▃▄▆▁▄▄▄▄▂▄▄█▂▄</td></tr><tr><td>action_2</td><td>▅▁▅▅▅▅▆▅█▅▇▆▅▆▅▅▅▅▅▇▅▅▅▆▆▅▅▅█▁▄▅▅▅▃▅▅▄█▅</td></tr><tr><td>action_3</td><td>▄▅▄▄▄▄▇▄▁▄▇█▄▃▄▄▄▄▄▂▄▅▄▃▅▄▄▄▃▂▄▅▄▅▁▄▄▃▅▄</td></tr><tr><td>actor_loss</td><td>▁▂▃▄▅▅▆▇▇█</td></tr><tr><td>actor_predictions</td><td>█████▇▇▇▇▄▄▄▄▄▄▄▄▄▃▃▃▃▄▄▄▄▄▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>avg_reward</td><td>▁▁▁▁█▇▆▅▅▅</td></tr><tr><td>best</td><td>█▁▁▁█▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▁▃▄▅█▅██▅█</td></tr><tr><td>critic_predictions</td><td>█████▇▇▇▇▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁█▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▂▇▁▇█▅▃▅▇▆</td></tr><tr><td>goal_distance</td><td>▃▅▅▅▁▂▅▅▄▅▇█▄▅▅▅▂▂▃▃▃▅▆▆▂▂▂▂▄▃▄▄▄▆▇▇▁▁▁▁</td></tr><tr><td>noise_0</td><td>▃▅▅▂▆▁▅▃▅▅▅▅▅▅▂▆█▇▄▅▄▄▆▅▅▇▆▂▅▅▃▁▅▅▅▆▇▅▅▃</td></tr><tr><td>noise_1</td><td>▁▅▄▁▃▄▅▅▅▆▅▅▂▅▇▆▅▆▅▅▃▄▄▅▅▄▂▆▅▅▄▄▃▆▅▄▆▅▅█</td></tr><tr><td>noise_2</td><td>▃▅▃▆▄▅▅▆▅▆▅▅▆▅█▄▆▃▆▅▅▆▃▅▅▆▆▃▅▅▁█▄▇▅▅▄▅▅▃</td></tr><tr><td>noise_3</td><td>▂▅▅▄▆▆▅▇▅▂▅▅▄▅▇▃▄▄▄▅▆█▆▅▅▃▅▅▅▅▅▇▇█▅▅▂▅▅▁</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▂▁▃▂█▃▁▃▁▂▁▁▃▁▂▂▄▃▂▁▃▂▃▁▁▂▂▂▁▁▄▂▃▂▁▂▃▁▁▂</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>█████▆▆▆▆▄▄▄▄▃▃▃▃▃▁▁▁▁▅▅▅▅▅▆▆▆▆▂▂▂▂▂▂▂▂▂</td></tr><tr><td>target_critic_predictions</td><td>█████▃▃▃▃▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>tolerance count</td><td>▆▄▁█▁▂▆▅▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.11517</td></tr><tr><td>action_1</td><td>0.03373</td></tr><tr><td>action_2</td><td>-0.07575</td></tr><tr><td>action_3</td><td>0.08271</td></tr><tr><td>actor_loss</td><td>-0.00653</td></tr><tr><td>actor_predictions</td><td>0.03139</td></tr><tr><td>avg_reward</td><td>-49.8</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.54653</td></tr><tr><td>critic_predictions</td><td>0.00822</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.16422</td></tr><tr><td>goal_distance</td><td>0.07673</td></tr><tr><td>noise_0</td><td>0.09012</td></tr><tr><td>noise_1</td><td>0.00869</td></tr><tr><td>noise_2</td><td>-0.1008</td></tr><tr><td>noise_3</td><td>0.05767</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00245</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.03215</td></tr><tr><td>target_critic_predictions</td><td>0.0138</td></tr><tr><td>tolerance count</td><td>220</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-46</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/m7tvejdj</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235556-m7tvejdj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mv81tpn3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 7, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235621-mv81tpn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3' target=\"_blank\">royal-sweep-5</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 7, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:47\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:mv81tpn3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-5</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235621-mv81tpn3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:mv81tpn3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235627-mv81tpn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3' target=\"_blank\">train-47</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-47', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 7, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-47', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 7, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -50.0, avg episode time 0.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▄▂▅▄▅▅▅▄▃▄█▇▅▄▅▅▄▄▅█▄▄▅▁▂▄▅▄▇▄▅▄▄▄▄▅▄▄▅▄</td></tr><tr><td>action_1</td><td>▄▆▄▅▄▅▄▅█▅█▅▄▅▅▄▅▅▄▇▅▅▅▅▆▄▄▅▁▅▄▄▅▅▅▄▄▇▄▅</td></tr><tr><td>action_2</td><td>▄█▄▄▅▅▄▅▄▅█▁▅▄▅▅▄▅▄▆▄▄▄▃▇▄▅▄▆▅▄▄▄▄▅▄▄▁▅▄</td></tr><tr><td>action_3</td><td>▄█▅▅▅▄▅▅▂▅▂▄▄▄▅▅▅▅▄▄▅▄▄▃▁▅▄▅▆▅▅▅▄▅▅▄▄▁▅▅</td></tr><tr><td>actor_loss</td><td>▅▁▃▂▃▄▅▆█▇</td></tr><tr><td>actor_predictions</td><td>█████▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▂▂▂</td></tr><tr><td>avg_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>best</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▁▄█▄▂▂▄▄▂▁</td></tr><tr><td>critic_predictions</td><td>▆▆▆▆▆████▆▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▄█▁▄▂▂▂▁▂▅</td></tr><tr><td>goal_distance</td><td>▃▄▄▅▅▅▆█▃▄▅█▆▅▆▇▄▃▃▅▂▁▂▅▄▅▅▄▄▅▅▄▃▂▃▄▅▄▄▄</td></tr><tr><td>noise_0</td><td>▃▅▇▆▆▇▆▅▅▁▅▅▇▃▆▇▅▂█▅▅▆█▅▅▆▇▄▅▆▆▄▅▂▄█▄▅▆▄</td></tr><tr><td>noise_1</td><td>▁▄▄▅▄▅▃▄▄▅▄▄▃█▇▂▆▆▃▄▇▆▄▄▄▄▃▆▄▅▄▃▅▄▇▃▂▄▃▅</td></tr><tr><td>noise_2</td><td>▂▄▄▁▄█▃▆▄▄▄▄▆▁▅▄▃▄▃▄▄▂▂▄▄▁▇▂▄▆▁▄▂▄▆▃▂▄▄▃</td></tr><tr><td>noise_3</td><td>▁▄▅▇█▂▅▆▄▄▄▄▂▂▅▅▅▅▄▄▅▂▁▄▄▅▃█▄▇▇▇▃▄▅▃▃▄▅▄</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▂▁▂▂█▃▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>█████▆▆▆▆▆▆▆▆▃▃▃▃▃▂▂▂▂▃▃▃▃▃▁▁▁▁▃▃▃▃▃▃▃▃▃</td></tr><tr><td>target_critic_predictions</td><td>▁▁▁▁▁▇▇▇▇▃▃▃▃█████▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>tolerance count</td><td>▄▂▂▆▃▁▄█▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.03176</td></tr><tr><td>action_1</td><td>-0.02883</td></tr><tr><td>action_2</td><td>0.03514</td></tr><tr><td>action_3</td><td>-0.02045</td></tr><tr><td>actor_loss</td><td>-0.00752</td></tr><tr><td>actor_predictions</td><td>0.02081</td></tr><tr><td>avg_reward</td><td>-50.0</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.51623</td></tr><tr><td>critic_predictions</td><td>0.00797</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.19495</td></tr><tr><td>goal_distance</td><td>0.1724</td></tr><tr><td>noise_0</td><td>0.00282</td></tr><tr><td>noise_1</td><td>-0.05777</td></tr><tr><td>noise_2</td><td>0.0062</td></tr><tr><td>noise_3</td><td>-0.04939</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00237</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.02163</td></tr><tr><td>target_critic_predictions</td><td>0.00829</td></tr><tr><td>tolerance count</td><td>268</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-47</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/mv81tpn3</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235627-mv81tpn3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 68\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 880\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 50l38brs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235649-50l38brs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs' target=\"_blank\">different-sweep-6</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:50l38brs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-sweep-6</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235649-50l38brs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:50l38brs). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235656-50l38brs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs' target=\"_blank\">train-48</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-48', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-48', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.1, reward -50.0, avg reward -48.8, avg episode time 0.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▅▁▅▅▅▅▅▅▅▅▅▅▅▂▅▅▅▆▅▁▅▅▅▅▅▅▅▆▅▆▅▅▅▅▅█▅▅▅▂</td></tr><tr><td>action_1</td><td>▇█▇▇▇█▇█▇▇▇▇█▁▇▇▇▇▇▇▇▄▇▇▇█▇▇▇▇▇▇█▇▇▁▇▇▇▆</td></tr><tr><td>action_2</td><td>▄▃▄▄▄▄▅▅▅▅▅▄▄▅▄▅▄▄▅▁▄█▄▄▅▄▄▅▄▅▄▄▄▅▅▄▄▄▅█</td></tr><tr><td>action_3</td><td>▆▇▇▇▇▆▇▆▇▇▆▇▇▃▆▇▇▆▆█▆▁▇▇▇▇▆▆▇▇▇▇▆▇▇▁▇▆▇▆</td></tr><tr><td>actor_loss</td><td>▁▂▃▄▅▅▆▇▇█</td></tr><tr><td>actor_predictions</td><td>█████▂▂▂▂▁▁▁▁▇▇▇▇▇▆▆▆▆▇▇▇▇▇▆▆▆▆▁▁▁▁▁▆▆▆▆</td></tr><tr><td>avg_reward</td><td>▁▁▁▁█▇▆▅▅▅</td></tr><tr><td>best</td><td>█▁▁▁█▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>█▃▃▃▂▂▄▂▅▁</td></tr><tr><td>critic_predictions</td><td>█████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁█▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▁▂▁▆█▃▂▂▃▅</td></tr><tr><td>goal_distance</td><td>▅▆▆▆▂▃▂▂▃▄▅▆▄▃▄▄▁▁▁▁▄▄▃▄▄▄▄▄▄▅▆█▄▃▃▃▃▃▂▂</td></tr><tr><td>noise_0</td><td>▃▄▆▅▅▆▃▆▃▃▆▄▅▄▂▁▃█▂▄▃▄▅▅▅▃▅▇▅▆▆▂▂▃▇▄▅▆▅▄</td></tr><tr><td>noise_1</td><td>▁▅▄▅▄█▅▇▄▁▄▆▇▅▃▆▃▃▃▅▂▅▁▄▄▆▆▃▄▄▅▄█▆▅▅▃▄▃▅</td></tr><tr><td>noise_2</td><td>▂▄▃▁▄▂▆▇▅▅▇▁▃▄▃▅▄▃▅▄▃▄▃▃▇▂▃▆▁▄▁▃▂██▄▄▄▆▄</td></tr><tr><td>noise_3</td><td>▂▄▅▆▇▅▆▄▅▄▁▅█▄▁▆▆▄▃▄▄▄▇▅▆▇▁▃▇▅▆▄▁▄▅▄▅▄█▄</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▃▁▃▆▄▃▃▃▄▂▂█▃▁▄▇▄▃▅▂▃▂▃▃▃▃▃▄▂▃▃▅▂▃▃▁▅▅▃▁</td></tr><tr><td>success_rate</td><td>▁▁▁▁█▇▆▅▅▅</td></tr><tr><td>target_actor_predictions</td><td>▄▄▄▄▄▁▁▁▁▁▁▁▁▆▆▆▆▆▄▄▄▄▃▃▃▃▃▆▆▆▆▄▄▄▄▄████</td></tr><tr><td>target_critic_predictions</td><td>█████▄▄▄▄▃▃▃▃▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃</td></tr><tr><td>tolerance count</td><td>▂█▃▇█▅▄▁▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.10135</td></tr><tr><td>action_1</td><td>-0.00514</td></tr><tr><td>action_2</td><td>0.04967</td></tr><tr><td>action_3</td><td>0.07806</td></tr><tr><td>actor_loss</td><td>-0.00479</td></tr><tr><td>actor_predictions</td><td>0.02049</td></tr><tr><td>avg_reward</td><td>-48.8</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.44292</td></tr><tr><td>critic_predictions</td><td>0.00556</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.17952</td></tr><tr><td>goal_distance</td><td>0.07307</td></tr><tr><td>noise_0</td><td>0.08297</td></tr><tr><td>noise_1</td><td>-0.02351</td></tr><tr><td>noise_2</td><td>0.03129</td></tr><tr><td>noise_3</td><td>0.05968</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00638</td></tr><tr><td>success_rate</td><td>0.1</td></tr><tr><td>target_actor_predictions</td><td>0.0222</td></tr><tr><td>target_critic_predictions</td><td>0.00836</td></tr><tr><td>tolerance count</td><td>118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-48</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/50l38brs</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235656-50l38brs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tyr2um8s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 128}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235720-tyr2um8s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s' target=\"_blank\">confused-sweep-7</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 4, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 64, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 128}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tyr2um8s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-7</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235720-tyr2um8s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tyr2um8s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235727-tyr2um8s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s' target=\"_blank\">train-49</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-49', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-49', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 4, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -49.5, avg episode time 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▅▂▅▄▅▅▅▅▅▅▁▅▅▄▅▅▄▄▅▁▇▁█▅▅▅▅▅▅▅▅▅▄▅▅▆▅▅▅▄</td></tr><tr><td>action_1</td><td>▄▁▄▄▄▄▄▅▄▅▃▅▄▅▅▄▅▄▅▅▁▇▅▄▄█▅▄▄▅▄▄▅▄▄▂▅▅▅▄</td></tr><tr><td>action_2</td><td>▄█▄▅▄▄▅▅▅▅▇▅▅▂▄▄▅▄▄▁▃▁▂▄▅▆▅▅▄▄▄▅▅▅▅▂▄▅▅▁</td></tr><tr><td>action_3</td><td>▄▁▅▄▅▅▅▅▄▅▄▅▄▆▅▄▅▅▄▃▅▅▁▄▅█▅▅▅▅▅▄▅▅▅▅▄▅▅▅</td></tr><tr><td>actor_loss</td><td>▂▄▅▁▄▄▇▇██</td></tr><tr><td>actor_predictions</td><td>▇▇▇▇▇████▅▅▅▅▃▃▃▃▃▃▃▃▃▅▅▅▅▅▄▄▄▄▃▃▃▃▃▁▁▁▁</td></tr><tr><td>avg_reward</td><td>▁▁▁▁▁█▇▆▆▅</td></tr><tr><td>best</td><td>█▁▁▁▁█▁▁▁▁</td></tr><tr><td>critic_loss</td><td>█▇▅▃▁▂▁▃▁▃</td></tr><tr><td>critic_predictions</td><td>█████▇▇▇▇▅▅▅▅▇▇▇▇▇▅▅▅▅▆▆▆▆▆▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁▁█▁▁▁▁</td></tr><tr><td>episode_time</td><td>▂▆▇▄█▁▄█▅▇</td></tr><tr><td>goal_distance</td><td>▂▄▅▆▄▅▆█▃▄▅▅▂▁▃▃▅▅▆▄▁▁▂▄▃▂▄▄▆▆▇█▃▂▂▁▄▅▄▅</td></tr><tr><td>noise_0</td><td>▄▅▆▃▇▂▅▃▇█▅█▇▅▄▇▂▁▆▅▅▅▅█▆▅▅▆▄▃▆▆▁▇▇▅▄▄▆▅</td></tr><tr><td>noise_1</td><td>▁▅▄▁▃▂▃█▄▅▅▆▄▅▆▄▅▂▆▅▅▅▅▄▂▅█▂▄▅▂▂▅▄▃▅█▆▆▅</td></tr><tr><td>noise_2</td><td>▂▄▂▅▂▁▆▅▄▄▄▆▆▄▂▂▆▃▃▄▄▄▄▂▅▄▃▄▂▁▃▃▄▄▅▄▂█▅▄</td></tr><tr><td>noise_3</td><td>▂▅▅▄▅▅▅▄▂▅▅█▂▅▄▃█▆▃▅▅▅▅▁▅▅▆▅▅▅▄▃█▅▆▅▁▅▅▅</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▃▁▄▅▅▄▃▃▄▅▁▃▃▂▅▄▄▄█▂▁▁▁▄▄▂▃▃▆▄▄▄▃▄▃▁▄▃▄▁</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>▆▆▆▆▆████▅▅▅▅▂▂▂▂▂▄▄▄▄▆▆▆▆▆▄▄▄▄▃▃▃▃▃▁▁▁▁</td></tr><tr><td>target_critic_predictions</td><td>▃▃▃▃▃▆▆▆▆▃▃▃▃█████▆▆▆▆█████▃▃▃▃▃▃▃▃▃▁▁▁▁</td></tr><tr><td>tolerance count</td><td>▁▂▂█▆▃▂▃▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.82539</td></tr><tr><td>action_1</td><td>0.5126</td></tr><tr><td>action_2</td><td>-0.36459</td></tr><tr><td>action_3</td><td>0.25492</td></tr><tr><td>actor_loss</td><td>-0.0075</td></tr><tr><td>actor_predictions</td><td>0.0199</td></tr><tr><td>avg_reward</td><td>-49.5</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.64148</td></tr><tr><td>critic_predictions</td><td>0.00793</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.15784</td></tr><tr><td>goal_distance</td><td>0.22601</td></tr><tr><td>noise_0</td><td>0.0</td></tr><tr><td>noise_1</td><td>0.0</td></tr><tr><td>noise_2</td><td>0.0</td></tr><tr><td>noise_3</td><td>0.0</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00097</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.02061</td></tr><tr><td>target_critic_predictions</td><td>0.00826</td></tr><tr><td>tolerance count</td><td>139</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-49</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/tyr2um8s</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235727-tyr2um8s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vas6epx2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 6, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235751-vas6epx2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2' target=\"_blank\">woven-sweep-8</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.2, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 6, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 128, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 64, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 64}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vas6epx2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-8</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235751-vas6epx2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:vas6epx2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235758-vas6epx2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2' target=\"_blank\">train-50</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-50', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 6, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.2, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-50', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 6, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -50.0, avg episode time 0.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▃█▄▄▄▅▆▃▄▄▄▄▄▄▄▄▃▁▄▄▄▂▄▄▃▄▄▄▃▃▄▄▃▄▄▄▃▄▄▄</td></tr><tr><td>action_1</td><td>▄▃▄▅▄▁█▄▅▅█▅▅▅▄▅▅▆▅▄▅█▄▄▄▄▅▅▅▅▄▅▅▅▃▅▅▅▅▄</td></tr><tr><td>action_2</td><td>▅█▅▄▅▅▇▁▅▅▆▅▅▅▅▅▅▃▅▅▄▁▅▅▅▅▄▅▅▅▅▅▅▅█▅▅▄▅▅</td></tr><tr><td>action_3</td><td>▄█▅▅▅▇▇▆▄▄▂▅▄▄▄▄▅▄▅▄▄▁▄▅▄▄▄▄▅▅▄▄▄▄▇▄▄▄▄▄</td></tr><tr><td>actor_loss</td><td>▁▁▂▃▄▅▆▇▇█</td></tr><tr><td>actor_predictions</td><td>█████▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>avg_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>best</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▁▆█▇▅▂▅▅▆▅</td></tr><tr><td>critic_predictions</td><td>█████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▁█▅▆▇▅▄▂▃█</td></tr><tr><td>goal_distance</td><td>▃▃▄▅▅▅▆▅▄▄▅▆▄▅▅▅▄█▇▆▁▃▂▂▁▁▂▅▅▅▅▅▄▅▃▃▄▄▄▃</td></tr><tr><td>noise_0</td><td>▄▆█▇▇▆▆▆▅▆▆▆▇▅▅▆▃▆▆▄▆▆▅█▃▆▆▅▄▁▇█▄▆▆▆▄▇▆▆</td></tr><tr><td>noise_1</td><td>▁▄▄▄▃▄▄▄▅▄▄▄▆▆▂▅▅▄▆▃▅▄▃▃▄▂█▆▄▅▂▇▄▅▄▆▅▇▆▂</td></tr><tr><td>noise_2</td><td>▃▄▄▂▄▄▄▄▅▇▄▅▃▆▆▄▄▄▄▄▃▄▇▆▄▃▁▃▄▄▅█▇▄▄▅▇▁▅▄</td></tr><tr><td>noise_3</td><td>▂▅▅▇█▅▅▅▃▂▅▆▃▄▂▁▅▅▆▄▃▅▄▇▃▄▄▄▆█▃▂▁▃▅▅▂▂▂▃</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▆▁▃▄▆▁▂▁▃▄▁▃▇▃▄▄▆▁█▄▄▂▄▃▄▄▃▃▄▆▃▃▅▃▁▃█▆▄▃</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>▃▃▃▃▃▂▂▂▂▃▃▃▃█████▄▄▄▄▁▁▁▁▁████▆▆▆▆▆▆▆▆▆</td></tr><tr><td>target_critic_predictions</td><td>▇▇▇▇▇▆▆▆▆▃▃▃▃▇▇▇▇▇▅▅▅▅▁▁▁▁▁▄▄▄▄█████▄▄▄▄</td></tr><tr><td>tolerance count</td><td>▅▁▄▃▆█▃▅▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.06827</td></tr><tr><td>action_1</td><td>-0.03902</td></tr><tr><td>action_2</td><td>0.01412</td></tr><tr><td>action_3</td><td>0.11714</td></tr><tr><td>actor_loss</td><td>-0.00467</td></tr><tr><td>actor_predictions</td><td>0.02375</td></tr><tr><td>avg_reward</td><td>-50.0</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.56727</td></tr><tr><td>critic_predictions</td><td>0.00555</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.1494</td></tr><tr><td>goal_distance</td><td>0.13579</td></tr><tr><td>noise_0</td><td>0.04155</td></tr><tr><td>noise_1</td><td>-0.06575</td></tr><tr><td>noise_2</td><td>-0.01262</td></tr><tr><td>noise_3</td><td>0.09041</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00161</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.03392</td></tr><tr><td>target_critic_predictions</td><td>0.00921</td></tr><tr><td>tolerance count</td><td>152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-50</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/vas6epx2</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235758-vas6epx2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ieer8bhd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 7, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 128}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235838-ieer8bhd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd' target=\"_blank\">polar-sweep-9</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 0.0001, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 256, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 1e-05, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.99, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 7, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 128, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 128, 'critic_units_state_layer_2_HER_DDPG': 128}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ieer8bhd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-9</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235838-ieer8bhd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ieer8bhd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235845-ieer8bhd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd' target=\"_blank\">train-51</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-51', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 7, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False}, 'discount': 0.99, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 256, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-51', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 7, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -35.0, avg reward -47.2, avg episode time 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▅▁▅▅▅▅▅▅▄▅▇▁▅█▅▅▅▅▅▁▅▅▅▆▁▅▅▅█▄▅▅▅▅▃▅▅▁▅▅</td></tr><tr><td>action_1</td><td>▅▁▆▆▆▆▆▆▆▆▂█▆▂▆▆▆▆▆▆▆▆▆▃▆▆▆▆▃▁▆▆▆▆▄▆▆▂▁▇</td></tr><tr><td>action_2</td><td>▅▃▅▅▅▅▂▅█▅▁▅▅█▅▅▅▅▅▇▅▅▅▆▃▅▅▅▄▅▄▅▅▅▃▅▅█▃▅</td></tr><tr><td>action_3</td><td>▄▅▅▄▅▅▃▅▆▄▇▃▄█▅▄▅▅▅▆▅▅▅▁▆▄▅▅▂▆▅▅▅▅█▅▄▂▇▄</td></tr><tr><td>actor_loss</td><td>▃▁▂▃▄▃▃▃▅█</td></tr><tr><td>actor_predictions</td><td>█████▇▇▇▇▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>avg_reward</td><td>▃▂▁▁▁▆▅▅▄█</td></tr><tr><td>best</td><td>█▁▁▁▁█▁▁▁█</td></tr><tr><td>critic_loss</td><td>▆▅▇▅▇█▆▄▄▁</td></tr><tr><td>critic_predictions</td><td>▇▇▇▇▇████▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁▁▁▁▁▇▁▁▁█</td></tr><tr><td>episode_time</td><td>▂▄▁█▅▁▄▂▁▃</td></tr><tr><td>goal_distance</td><td>▄▃▂▁▄▅▆█▄▃▄▅▆▆▇█▄▄▄▄▂▁▂▁▅▅▄▄▃▃▃▃▅▅▆▆▁▂▂▃</td></tr><tr><td>noise_0</td><td>▃▅▅▂▆▁▅▃▅▅▅▅▅▅▂▆█▇▄▅▄▄▆▅▅▇▆▂▅▅▃▁▅▅▅▆▇▅▅▃</td></tr><tr><td>noise_1</td><td>▁▅▄▁▃▄▅▅▅▆▅▅▂▅▇▆▅▆▅▅▃▄▄▅▅▄▂▆▅▅▄▄▃▆▅▄▆▅▅█</td></tr><tr><td>noise_2</td><td>▃▅▃▆▄▅▅▆▅▆▅▅▆▅█▄▆▃▆▅▅▆▃▅▅▆▆▃▅▅▁█▄▇▅▅▄▅▅▃</td></tr><tr><td>noise_3</td><td>▂▅▅▄▆▆▅▇▅▂▅▅▄▅▇▃▄▄▄▅▆█▆▅▅▃▅▅▅▅▅▇▇█▅▅▂▅▅▁</td></tr><tr><td>step_reward</td><td>▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>step_time</td><td>▄▁▆▄▄▃▁▄▁▃▁▁▃▂▄▄▄▃▃▁▃▃▃▁▁▃█▄▁▁▄▃▄▄▁▃▄▁▁▄</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>█████▅▅▅▅▃▃▃▃▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_critic_predictions</td><td>▁▁▁▁▁▅▅▅▅▃▃▃▃▂▂▂▂▂▄▄▄▄▄▄▄▄▄▇▇▇▇█████▅▅▅▅</td></tr><tr><td>tolerance count</td><td>▃▁▁▂▁▃█▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.10426</td></tr><tr><td>action_1</td><td>0.02282</td></tr><tr><td>action_2</td><td>-0.08666</td></tr><tr><td>action_3</td><td>0.07183</td></tr><tr><td>actor_loss</td><td>-0.01108</td></tr><tr><td>actor_predictions</td><td>0.01313</td></tr><tr><td>avg_reward</td><td>-47.2</td></tr><tr><td>best</td><td>True</td></tr><tr><td>critic_loss</td><td>0.53879</td></tr><tr><td>critic_predictions</td><td>0.01143</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-35.0</td></tr><tr><td>episode_time</td><td>0.15372</td></tr><tr><td>goal_distance</td><td>0.1414</td></tr><tr><td>noise_0</td><td>0.09012</td></tr><tr><td>noise_1</td><td>0.00869</td></tr><tr><td>noise_2</td><td>-0.1008</td></tr><tr><td>noise_3</td><td>0.05767</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00225</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.01962</td></tr><tr><td>target_critic_predictions</td><td>0.01198</td></tr><tr><td>tolerance count</td><td>132</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-51</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/ieer8bhd</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235845-ieer8bhd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8rxs5mrj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tHER_DDPG: {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 6, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenv: {'id': 'FetchReach-v2', 'max_episode_steps': 50}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: HER_DDPG\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 1882\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 371\n",
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235909-8rxs5mrj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj' target=\"_blank\">ethereal-sweep-10</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her model creation fired\n",
      "sweep not using mpi fired\n",
      "wandb config:{'HER_DDPG': {'HER_DDPG_actor_activation': 'relu', 'HER_DDPG_actor_clamp_output': 0.04, 'HER_DDPG_actor_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_actor_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_actor_learning_rate': 1e-05, 'HER_DDPG_actor_normalize_layers': False, 'HER_DDPG_actor_num_cnn_layers': 0, 'HER_DDPG_actor_num_layers': 2, 'HER_DDPG_actor_optimizer': 'Adam', 'HER_DDPG_actor_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_actor_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_actor_output_kernel_initializer': 'constant', 'HER_DDPG_batch_size': 128, 'HER_DDPG_critic_activation': 'relu', 'HER_DDPG_critic_hidden_kernel_initializer': 'kaiming_uniform', 'HER_DDPG_critic_hidden_kernel_kaiming_uniform': {'kaiming_uniform_mode': 'fan_in'}, 'HER_DDPG_critic_learning_rate': 0.0001, 'HER_DDPG_critic_merged_num_layers': 2, 'HER_DDPG_critic_normalize_layers': False, 'HER_DDPG_critic_num_cnn_layers': 0, 'HER_DDPG_critic_optimizer': 'Adam', 'HER_DDPG_critic_optimizer_Adam_options': {'Adam_weight_decay': 0}, 'HER_DDPG_critic_output_kernel_constant': {'constant_value': 0.003}, 'HER_DDPG_critic_output_kernel_initializer': 'constant', 'HER_DDPG_critic_state_num_layers': 2, 'HER_DDPG_device': 'cuda', 'HER_DDPG_discount': 0.9, 'HER_DDPG_epsilon_greedy': 0.3, 'HER_DDPG_goal_strategy': 'future', 'HER_DDPG_goal_tolerance': 0.05, 'HER_DDPG_noise': 'Normal', 'HER_DDPG_noise_Normal': {'mean': 0, 'stddev': 0.05}, 'HER_DDPG_normalizer_clip': 5, 'HER_DDPG_num_goals': 6, 'HER_DDPG_replay_buffer_size': 100000, 'HER_DDPG_save_dir': 'HER_Test', 'HER_DDPG_tau': 0.05, 'actor_units_layer_1_HER_DDPG': 128, 'actor_units_layer_2_HER_DDPG': 64, 'critic_units_merged_layer_1_HER_DDPG': 64, 'critic_units_merged_layer_2_HER_DDPG': 128, 'critic_units_state_layer_1_HER_DDPG': 64, 'critic_units_state_layer_2_HER_DDPG': 64}, 'env': {'id': 'FetchReach-v2', 'max_episode_steps': 50}, 'model_type': 'HER_DDPG'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 781\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 778\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 783\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 784\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run number:52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8rxs5mrj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-10</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235909-8rxs5mrj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8rxs5mrj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'cat-file', '--batch-check'], cwd=/workspaces/RL_Agents, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/RL_Agents/pytorch/src/app/wandb/run-20240610_235916-8rxs5mrj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj' target=\"_blank\">train-52</a></strong> to <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/sweeps/5vujbkhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb init called\n",
      "wandb run tag complete\n",
      "env spec: EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "save dir set:HER_Test\n",
      "if wandb run fired\n",
      "agent name: ddpg\n",
      "new save dir: HER_Test/her/ddpg/\n",
      "self._obs_space_shape: (10,)\n",
      "buffer size = 100000\n",
      "agent built:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-52', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 6, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n",
      "agent saved to HER_Test/her/\n",
      "agent config:{'agent_type': 'HER', 'agent': {'agent_type': 'DDPG', 'env': 'FetchReach-v2', 'actor_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 4, 'dense_layers': [(128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 1e-05, 'normalize_layers': False, 'clamp_output': 0.04}, 'critic_model': {'env': 'FetchReach-v2', 'cnn_model': None, 'num_layers': 8, 'state_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'merged_layers': [(64, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}}), (128, 'relu', {'kaiming_uniform': {'mode': 'fan_in'}})], 'output_layer_kernel': {'constant': {'val': 0.003}}, 'goal_shape': (3,), 'optimizer': 'Adam', 'optimizer_params': {'weight_decay': 0}, 'learning_rate': 0.0001, 'normalize_layers': False}, 'discount': 0.9, 'tau': 0.05, 'action_epsilon': 0.3, 'replay_buffer': None, 'batch_size': 128, 'noise': {'class_name': 'NormalNoise', 'config': {'shape': (4,), 'mean': 0.0, 'stddev': 0.05000000074505806}}, 'normalize_inputs': False, 'normalizer_clip': None, 'normalizer_eps': 0.01, 'callbacks': [{'class_name': 'WandbCallback', 'config': {'project_name': 'FetchReach-v2', 'run_name': 'train-52', 'chkpt_freq': 100, '_sweep': True}}], 'save_dir': 'HER_Test/her/ddpg/'}, 'strategy': 'future', 'tolerance': 0.05, 'num_goals': 6, 'desired_goal': 'fetch_reach_desired_goal', 'achieved_goal': 'fetch_reach_achieved_goal', 'reward_fn': 'fetch_reach_reward', 'normalizer_clip': 5, 'normalizer_eps': 0.01, 'replay_buffer_size': 100000, 'device': 'cuda', 'save_dir': 'HER_Test/her/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./HER_Test/her/ddpg)... Done. 0.0s\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 42\n",
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 cycle 1 episode 10, success percentage 0.0, reward -50.0, avg reward -49.2, avg episode time 0.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>▄▆▄▄▅▁▁▆▄▅▆▃▄▅▄▄▅▄▄▅▃▆▇▄▄▄▅▅▄▄▅▄▅▅▂▄█▅▅▄</td></tr><tr><td>action_1</td><td>▄▇▄▄▄▁▄▇▄▅▆▅▄▃▄▄▄▂▄▄▄▇▆▄▄▄▄█▄▄▄▄▄▄▅▄▃▄▄▄</td></tr><tr><td>action_2</td><td>▄█▄▄▄▁▇▄▄▄▃▁▄▅▄▄▄▁▄▄█▂█▄▅▄▄▇▄▄▄▄▄▄█▄▆▄▄▄</td></tr><tr><td>action_3</td><td>▄▆▅▅▅▁▃▆▅▅▆▅▅▅▅▄▅▆▅▅▇▄▁▅▅▅▅█▅▅▅▅▅▅▂▅▄▅▅▅</td></tr><tr><td>actor_loss</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>actor_predictions</td><td>█████▃▃▃▃▄▄▄▄▂▂▂▂▂▃▃▃▃▆▆▆▆▆▄▄▄▄█████▁▁▁▁</td></tr><tr><td>avg_reward</td><td>▁█▆▅▄▃▃▃▃▂</td></tr><tr><td>best</td><td>██▁▁▁▁▁▁▁▁</td></tr><tr><td>critic_loss</td><td>▄▁▄▄▃▃▃█▃█</td></tr><tr><td>critic_predictions</td><td>█████▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>episode</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>episode_reward</td><td>▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_time</td><td>▁▅▆█▃▂▂▂▂▇</td></tr><tr><td>goal_distance</td><td>▂▂▂▃▂▁▁▁▃▃▅▅▃▃▂▄▄▄▃▄▅▅▇█▃▃▄▆▆▄▃▅▄▅▇▅▅▅▇▇</td></tr><tr><td>noise_0</td><td>▃▄▄▁▅▄▄▄▄▆▄▄▄▄▂▃▅▄▂▅▄▄▄▂▃▁▅▄▃▂▄▄█▅▄▃▄▅▅▃</td></tr><tr><td>noise_1</td><td>▂▆▅▂▄▆▆▆▅█▆▆▆▆▆▇▄▆█▆▆▆▆▅▅▁▅▆▄▆▄▂▅▅▆▆▆▄▆▆</td></tr><tr><td>noise_2</td><td>▄▅▃▆▄▅▅▅▆▆▅▅▆▅▃▇▆▅▄▇▅▅▅▅█▁▄▅▂▃▄▂▆▅▅▄▅▅▄▅</td></tr><tr><td>noise_3</td><td>▃▆▆▅▇▆▆▆██▆▆▇▆▅▁▆▆▆▅▆▆▆▅▆▆▇▆▆▇█▆▅▆▆▇▆██▅</td></tr><tr><td>step_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>step_time</td><td>▄▁█▄▅▁▁▂▃▄▂▁▃▁▄▃▄▁▃▃▁▁▁▆▇▃▃▁▃▃▃▃▄▅▁▄▁▅█▄</td></tr><tr><td>success_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>target_actor_predictions</td><td>█████▁▁▁▁▅▅▅▅▁▁▁▁▁▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▄▄▄▄</td></tr><tr><td>target_critic_predictions</td><td>▄▄▄▄▄▁▁▁▁████▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄</td></tr><tr><td>tolerance count</td><td>▆▆█▄█▄▄▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>action_0</td><td>0.05074</td></tr><tr><td>action_1</td><td>0.05656</td></tr><tr><td>action_2</td><td>-0.02452</td></tr><tr><td>action_3</td><td>0.06527</td></tr><tr><td>actor_loss</td><td>-0.00949</td></tr><tr><td>actor_predictions</td><td>0.01782</td></tr><tr><td>avg_reward</td><td>-49.2</td></tr><tr><td>best</td><td>False</td></tr><tr><td>critic_loss</td><td>0.58157</td></tr><tr><td>critic_predictions</td><td>0.01042</td></tr><tr><td>episode</td><td>9</td></tr><tr><td>episode_reward</td><td>-50.0</td></tr><tr><td>episode_time</td><td>0.16618</td></tr><tr><td>goal_distance</td><td>0.27258</td></tr><tr><td>noise_0</td><td>0.02499</td></tr><tr><td>noise_1</td><td>0.0308</td></tr><tr><td>noise_2</td><td>-0.05028</td></tr><tr><td>noise_3</td><td>0.03952</td></tr><tr><td>step_reward</td><td>-1.0</td></tr><tr><td>step_time</td><td>0.00271</td></tr><tr><td>success_rate</td><td>0.0</td></tr><tr><td>target_actor_predictions</td><td>0.019</td></tr><tr><td>target_critic_predictions</td><td>0.01589</td></tr><tr><td>tolerance count</td><td>136</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-52</strong> at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2/runs/8rxs5mrj</a><br/> View project at: <a href='https://wandb.ai/jasonhayes1987/FetchReach-v2' target=\"_blank\">https://wandb.ai/jasonhayes1987/FetchReach-v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240610_235916-8rxs5mrj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash_callbacks import run_agent\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=sweep_config[\"project\"])\n",
    "# loop over num wandb agents\n",
    "num_agents = 2\n",
    "for agent in range(num_agents):\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FetchReach-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_spec = env.spec.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(gym.envs.registration.EnvSpec.from_json(env_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvSpec(id='FetchReach-v2', entry_point='gymnasium_robotics.envs.fetch.reach:MujocoFetchReachEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=50, order_enforce=True, disable_env_checker=False, kwargs={'reward_type': 'sparse'}, namespace=None, name='FetchReach', version=2, additional_wrappers=(), vector_entry_point=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_spec(env_spec_dict):\n",
    "    # Create a new EnvSpec instance using the dictionary\n",
    "    env_spec = gym.envs.registration.EnvSpec(**env_spec_dict)\n",
    "    return env_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EnvSpec.__init__() got an unexpected keyword argument 'namespace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_env_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mload_env_spec\u001b[0;34m(env_spec_dict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_env_spec\u001b[39m(env_spec_dict):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Create a new EnvSpec instance using the dictionary\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     env_spec \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEnvSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_spec_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_spec\n",
      "\u001b[0;31mTypeError\u001b[0m: EnvSpec.__init__() got an unexpected keyword argument 'namespace'"
     ]
    }
   ],
   "source": [
    "load_env_spec(env_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
